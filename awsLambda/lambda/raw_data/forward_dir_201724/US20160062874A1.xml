<?xml version="1.0" encoding="utf-8"?>
<!-- Copyright Â©2017 LexisNexis Univentio, The Netherlands. -->
<lexisnexis-patent-document schema-version="1.13" date-produced="20170602" file="US20160062874A1.xml" produced-by="LexisNexis-Univentio" lang="eng" date-inserted="20160303" time-inserted="075755" date-changed="20170602" time-changed="134228">
  <bibliographic-data lang="eng">
    <publication-reference publ-type="Application" publ-desc="Patent application (publication)">
      <document-id id="123667923">
        <country>US</country>
        <doc-number>20160062874</doc-number>
        <kind>A1</kind>
        <date>20160303</date>
      </document-id>
      <document-id data-format="original">
        <country>US</country>
        <doc-number>20160062874</doc-number>
        <kind>A1</kind>
        <date>20160303</date>
      </document-id>
      <document-id data-format="docdb" id="450068207">
        <doc-number>2016062874</doc-number>
      </document-id>
      <document-id data-format="epodoc">
        <doc-number>US2016062874</doc-number>
      </document-id>
    </publication-reference>
    <application-reference appl-type="utility">
      <document-id id="77591425">
        <country>US</country>
        <doc-number>14475507</doc-number>
        <date>20140902</date>
      </document-id>
      <document-id data-format="original">
        <country>US</country>
        <doc-number>14475507</doc-number>
        <date>20140902</date>
      </document-id>
      <document-id data-format="docdb" id="450068206">
        <doc-number>201414475507</doc-number>
      </document-id>
      <document-id data-format="epodoc">
        <doc-number>US201414475507</doc-number>
      </document-id>
    </application-reference>
    <application-series-code>14</application-series-code>
    <language-of-filing>eng</language-of-filing>
    <language-of-publication>eng</language-of-publication>
    <dates-of-public-availability date-changed="20160310">
      <unexamined-printed-without-grant>
        <date>20160303</date>
      </unexamined-printed-without-grant>
    </dates-of-public-availability>
    <classifications-ipcr date-changed="20161101">
      <classification-ipcr sequence="1">
        <text>G06F  11/36        20060101AFI20160303BHUS        </text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>11</main-group>
        <subgroup>36</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20160303</date>
        </action-date>
        <generating-office>
          <country>US</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G06F   9/44        20060101ALI20160303BHUS        </text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>9</main-group>
        <subgroup>44</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20160303</date>
        </action-date>
        <generating-office>
          <country>US</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
    </classifications-ipcr>
    <classifications-cpc date-changed="20161101">
      <classification-cpc sequence="1">
        <text>G06F  11/3636      20130101 FI20160303BHEP        </text>
        <cpc-version-indicator>
          <date>20130101</date>
        </cpc-version-indicator>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>11</main-group>
        <subgroup>3636</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20160303</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
    </classifications-cpc>
    <number-of-claims calculated="yes">20</number-of-claims>
    <invention-title id="title_eng" date-changed="20160303" lang="eng" format="original">DEBUG ARCHITECTURE FOR MULTITHREADED PROCESSORS</invention-title>
    <references-cited date-changed="20170418">
      <forward-citations name="fwdcit" date-changed="20170418" />
      <citation>
        <fwdcit num="1">
          <document-id>
            <country>US</country>
            <doc-number>20160224509</doc-number>
            <kind>A1</kind>
            <date>20160804</date>
          </document-id>
          <application-date>
            <date>20150519</date>
          </application-date>
        </fwdcit>
      </citation>
    </references-cited>
    <parties date-changed="20160303">
      <applicants>
        <applicant sequence="1" app-type="applicant" designation="us-only">
          <addressbook lang="eng">
            <orgname>Freescale Semiconductor, Inc.</orgname>
            <address>
              <city>Austin</city>
              <state>TX</state>
              <country>US</country>
            </address>
          </addressbook>
          <residence>
            <country>US</country>
          </residence>
        </applicant>
      </applicants>
      <inventors>
        <inventor sequence="1" designation="us-only">
          <addressbook lang="eng">
            <last-name>Brites</last-name>
            <first-name>Celso Fernando Veras</first-name>
            <address>
              <city>Campinas</city>
              <country>BR</country>
            </address>
          </addressbook>
        </inventor>
        <inventor sequence="2" designation="us-only">
          <addressbook lang="eng">
            <last-name>Prado</last-name>
            <first-name>Alex Rocha</first-name>
            <address>
              <city>Campinas</city>
              <country>BR</country>
            </address>
          </addressbook>
        </inventor>
      </inventors>
    </parties>
    <patent-family date-changed="20170530">
      <main-family family-id="180451405">
        <family-member>
          <document-id>
            <country>US</country>
            <doc-number>9665466</doc-number>
            <kind>B2</kind>
            <date>20170530</date>
          </document-id>
          <application-date>
            <date>20140902</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>US</country>
            <doc-number>20160062874</doc-number>
            <kind>A1</kind>
            <date>20160303</date>
          </document-id>
          <application-date>
            <date>20140902</date>
          </application-date>
        </family-member>
      </main-family>
      <complete-family family-id="180451404">
        <family-member>
          <document-id>
            <country>US</country>
            <doc-number>9665466</doc-number>
            <kind>B2</kind>
            <date>20170530</date>
          </document-id>
          <application-date>
            <date>20140902</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>US</country>
            <doc-number>20160062874</doc-number>
            <kind>A1</kind>
            <date>20160303</date>
          </document-id>
          <application-date>
            <date>20140902</date>
          </application-date>
        </family-member>
      </complete-family>
    </patent-family>
  </bibliographic-data>
  <abstract id="abstr_eng" date-changed="20160303" lang="eng" format="original">
    <p id="p-a-00001-en" num="0000">Debug architecture for multithreaded processors. In some embodiments, a method includes, in response to receiving a halt command, saving a context of a thread being executed by a processor core to a context memory distinct from the processor core; suspending execution of the thread; and initiating a debug of the thread using the context stored in the context memory. In other embodiments, an integrated circuit includes a processor core; a context management circuit coupled to the core; and a debug support circuit coupled to the context management circuit, the debug support circuit configured to send a halt request to the context management circuit and the context management circuit configured to, in response to having received the request, facilitate a debug operation by causing execution of a thread running on the core to be suspended and saving a context of the thread into a context memory distinct from the core.</p>
  </abstract>
  <legal-data date-changed="20170405">
    <legal-event sequence="1">
      <publication-date>
        <date>20140902</date>
      </publication-date>
      <event-code-1>AS</event-code-1>
      <legal-description>ASSIGNMENT</legal-description>
      <status-identifier>C</status-identifier>
      <docdb-publication-number> US  2016062874A1</docdb-publication-number>
      <docdb-application-id>450068206</docdb-application-id>
      <new-owner>FREESCALE SEMICONDUCTOR, INC., TEXAS</new-owner>
      <free-text-description>ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:BRITES, CELSO FERNANDO VERAS;PRADO, ALEX ROCHA;REEL/FRAME:033654/0156</free-text-description>
      <effective-date>
        <date>20140901</date>
      </effective-date>
    </legal-event>
    <legal-event sequence="2">
      <publication-date>
        <date>20141104</date>
      </publication-date>
      <event-code-1>AS</event-code-1>
      <legal-description>ASSIGNMENT</legal-description>
      <status-identifier>C</status-identifier>
      <docdb-publication-number> US  2016062874A1</docdb-publication-number>
      <docdb-application-id>450068206</docdb-application-id>
      <new-owner>CITIBANK, N.A., AS NOTES COLLATERAL AGENT, NEW YOR</new-owner>
      <free-text-description>SUPPLEMENT TO IP SECURITY AGREEMENT;ASSIGNOR:FREESCALE SEMICONDUCTOR, INC.;REEL/FRAME:034153/0027</free-text-description>
      <effective-date>
        <date>20141030</date>
      </effective-date>
    </legal-event>
    <legal-event sequence="3">
      <publication-date>
        <date>20141104</date>
      </publication-date>
      <event-code-1>AS</event-code-1>
      <legal-description>ASSIGNMENT</legal-description>
      <status-identifier>C</status-identifier>
      <docdb-publication-number> US  2016062874A1</docdb-publication-number>
      <docdb-application-id>450068206</docdb-application-id>
      <new-owner>CITIBANK, N.A., AS NOTES COLLATERAL AGENT, NEW YOR</new-owner>
      <free-text-description>SUPPLEMENT TO IP SECURITY AGREEMENT;ASSIGNOR:FREESCALE SEMICONDUCTOR, INC.;REEL/FRAME:034160/0370</free-text-description>
      <effective-date>
        <date>20141030</date>
      </effective-date>
    </legal-event>
    <legal-event sequence="4">
      <publication-date>
        <date>20141104</date>
      </publication-date>
      <event-code-1>AS</event-code-1>
      <legal-description>ASSIGNMENT</legal-description>
      <status-identifier>C</status-identifier>
      <docdb-publication-number> US  2016062874A1</docdb-publication-number>
      <docdb-application-id>450068206</docdb-application-id>
      <new-owner>CITIBANK, N.A., AS NOTES COLLATERAL AGENT, NEW YOR</new-owner>
      <free-text-description>SUPPLEMENT TO IP SECURITY AGREEMENT;ASSIGNOR:FREESCALE SEMICONDUCTOR, INC.;REEL/FRAME:034160/0351</free-text-description>
      <effective-date>
        <date>20141030</date>
      </effective-date>
    </legal-event>
    <legal-event sequence="5">
      <publication-date>
        <date>20151221</date>
      </publication-date>
      <event-code-1>AS</event-code-1>
      <legal-description>ASSIGNMENT</legal-description>
      <status-identifier>C</status-identifier>
      <docdb-publication-number> US  2016062874A1</docdb-publication-number>
      <docdb-application-id>450068206</docdb-application-id>
      <new-owner>FREESCALE SEMICONDUCTOR, INC., TEXAS</new-owner>
      <free-text-description>PATENT RELEASE;ASSIGNOR:CITIBANK, N.A., AS COLLATERAL AGENT;REEL/FRAME:037357/0921</free-text-description>
      <effective-date>
        <date>20151207</date>
      </effective-date>
    </legal-event>
    <legal-event sequence="6">
      <publication-date>
        <date>20160107</date>
      </publication-date>
      <event-code-1>AS</event-code-1>
      <legal-description>ASSIGNMENT</legal-description>
      <status-identifier>C</status-identifier>
      <docdb-publication-number> US  2016062874A1</docdb-publication-number>
      <docdb-application-id>450068206</docdb-application-id>
      <new-owner>MORGAN STANLEY SENIOR FUNDING, INC., MARYLAND</new-owner>
      <free-text-description>ASSIGNMENT AND ASSUMPTION OF SECURITY INTEREST IN PATENTS;ASSIGNOR:CITIBANK, N.A.;REEL/FRAME:037458/0502</free-text-description>
      <effective-date>
        <date>20151207</date>
      </effective-date>
    </legal-event>
    <legal-event sequence="7">
      <publication-date>
        <date>20160107</date>
      </publication-date>
      <event-code-1>AS</event-code-1>
      <legal-description>ASSIGNMENT</legal-description>
      <status-identifier>C</status-identifier>
      <docdb-publication-number> US  2016062874A1</docdb-publication-number>
      <docdb-application-id>450068206</docdb-application-id>
      <new-owner>MORGAN STANLEY SENIOR FUNDING, INC., MARYLAND</new-owner>
      <free-text-description>ASSIGNMENT AND ASSUMPTION OF SECURITY INTEREST IN PATENTS;ASSIGNOR:CITIBANK, N.A.;REEL/FRAME:037458/0460</free-text-description>
      <effective-date>
        <date>20151207</date>
      </effective-date>
    </legal-event>
    <legal-event sequence="8">
      <publication-date>
        <date>20160616</date>
      </publication-date>
      <event-code-1>AS</event-code-1>
      <legal-description>ASSIGNMENT</legal-description>
      <status-identifier>C</status-identifier>
      <docdb-publication-number> US  2016062874A1</docdb-publication-number>
      <docdb-application-id>450068206</docdb-application-id>
      <new-owner>MORGAN STANLEY SENIOR FUNDING, INC., MARYLAND</new-owner>
      <free-text-description>SUPPLEMENT TO THE SECURITY AGREEMENT;ASSIGNOR:FREESCALE SEMICONDUCTOR, INC.;REEL/FRAME:039138/0001</free-text-description>
      <effective-date>
        <date>20160525</date>
      </effective-date>
    </legal-event>
    <legal-event sequence="9">
      <publication-date>
        <date>20160921</date>
      </publication-date>
      <event-code-1>AS</event-code-1>
      <legal-description>ASSIGNMENT</legal-description>
      <status-identifier>C</status-identifier>
      <docdb-publication-number> US  2016062874A1</docdb-publication-number>
      <docdb-application-id>450068206</docdb-application-id>
      <new-owner>NXP, B.V., F/K/A FREESCALE SEMICONDUCTOR, INC., NE</new-owner>
      <free-text-description>RELEASE BY SECURED PARTY;ASSIGNOR:MORGAN STANLEY SENIOR FUNDING, INC.;REEL/FRAME:040925/0001</free-text-description>
      <effective-date>
        <date>20160912</date>
      </effective-date>
    </legal-event>
    <legal-event sequence="10">
      <publication-date>
        <date>20161107</date>
      </publication-date>
      <event-code-1>AS</event-code-1>
      <legal-description>ASSIGNMENT</legal-description>
      <status-identifier>C</status-identifier>
      <docdb-publication-number> US  2016062874A1</docdb-publication-number>
      <docdb-application-id>450068206</docdb-application-id>
      <new-owner>NXP B.V., NETHERLANDS</new-owner>
      <free-text-description>RELEASE BY SECURED PARTY;ASSIGNOR:MORGAN STANLEY SENIOR FUNDING, INC.;REEL/FRAME:040928/0001</free-text-description>
      <effective-date>
        <date>20160622</date>
      </effective-date>
    </legal-event>
    <legal-event sequence="11">
      <publication-date>
        <date>20161116</date>
      </publication-date>
      <event-code-1>AS</event-code-1>
      <legal-description>ASSIGNMENT</legal-description>
      <status-identifier>C</status-identifier>
      <docdb-publication-number> US  2016062874A1</docdb-publication-number>
      <docdb-application-id>450068206</docdb-application-id>
      <new-owner>NXP USA, INC., TEXAS</new-owner>
      <free-text-description>CHANGE OF NAME;ASSIGNOR:FREESCALE SEMICONDUCTOR INC.;REEL/FRAME:040626/0683</free-text-description>
      <effective-date>
        <date>20161107</date>
      </effective-date>
    </legal-event>
    <legal-event sequence="12">
      <publication-date>
        <date>20170112</date>
      </publication-date>
      <event-code-1>AS</event-code-1>
      <legal-description>ASSIGNMENT</legal-description>
      <status-identifier>N</status-identifier>
      <docdb-publication-number> US  2016062874A1</docdb-publication-number>
      <docdb-application-id>450068206</docdb-application-id>
      <new-owner>NXP USA, INC., TEXAS</new-owner>
      <free-text-description>CORRECTIVE ASSIGNMENT TO CORRECT THE NATURE OF CONVEYANCE PREVIOUSLY RECORDED AT REEL: 040626 FRAME: 0683. ASSIGNOR(S) HEREBY CONFIRMS THE MERGER AND CHANGE OF NAME EFFECTIVE NOVEMBER 7, 2016;ASSIGNORS:NXP SEMICONDUCTORS USA, INC. (MERGED INTO);FREESCALE SEMICONDUCTOR, INC. (UNDER);SIGNING DATES FROM 20161104 TO 20161107;REEL/FRAME:041414/0883</free-text-description>
    </legal-event>
    <legal-event sequence="13">
      <publication-date>
        <date>20170112</date>
      </publication-date>
      <event-code-1>AS</event-code-1>
      <legal-description>ASSIGNMENT</legal-description>
      <status-identifier>C</status-identifier>
      <docdb-publication-number> US  2016062874A1</docdb-publication-number>
      <docdb-application-id>450068206</docdb-application-id>
      <new-owner>NXP USA, INC., TEXAS</new-owner>
      <free-text-description>CORRECTIVE ASSIGNMENT TO CORRECT THE NATURE OF CONVEYANCE PREVIOUSLY RECORDED AT REEL: 040626 FRAME: 0683. ASSIGNOR(S) HEREBY CONFIRMS THE MERGER AND CHANGE OF NAME;ASSIGNOR:FREESCALE SEMICONDUCTOR INC.;REEL/FRAME:041414/0883</free-text-description>
      <effective-date>
        <date>20161107</date>
      </effective-date>
    </legal-event>
  </legal-data>
  <description id="descr_eng" lang="eng" format="original" date-changed="20160303">
    <summary>
      <heading id="h-00001-en" level="1">FIELD</heading>
      <p id="p-00001-en" num="0001">This disclosure relates generally to processors, and more specifically, to systems and methods for a debug architecture for multithreaded processors.</p>
      <heading id="h-00002-en" level="1">BACKGROUND</heading>
      <p id="p-00002-en" num="0002">Processors are electronic circuits capable of executing one or more sequences of instructions, tasks, or threads. In a conventional processor, operations are executed in series. As such, if an operation takes a long time to complete (e.g., if its completion depends upon the result of an external event), a subsequent operation still has to wait in a queue. The wait occurs even when execution of the subsequent operation is independent from that of the preceding operation, and regardless of whether the processor is otherwise available during that time.</p>
      <p id="p-00003-en" num="0003">The concept of multithreading or multitasking was developed, at least in part, to improve the use of available computing resources. Generally speaking, a multithreading or multitasking processor includes hardware support for switching between different instructions, tasks, or threads more efficiently than conventional processors.</p>
      <p id="p-00004-en" num="0004">As a processor operates, errors may occur. And, in the event of a processing error, techniques exist to capture state information of the processor at the time of the error. Such information may include, for instance, register values, pointers, program counters, condition codes, and the like. Once captured, a debugging tool may then be used to analyze that information. As the inventors hereof have recognized, even in the case of a multithreading processor, however, debug operations necessary to capture state information can still cause the multithreading processor to halt the execution of other instructions or threads.</p>
    </summary>
    <description-of-drawings>
      <heading id="h-00003-en" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
      <p id="p-00005-en" num="0005">The present invention(s) is/are illustrated by way of example and is/are not limited by the accompanying figures, in which like references indicate similar elements. Elements in the figures are illustrated for simplicity and clarity and have not necessarily been drawn to scale.</p>
      <p id="p-00006-en" num="0006">
        <figref>FIG. 1</figref> is a block diagram of a processor according to some embodiments.</p>
      <p id="p-00007-en" num="0007">
        <figref>FIG. 2</figref> is a block diagram of a temporal multithreading circuit according to some embodiments.</p>
      <p id="p-00008-en" num="0008">
        <figref>FIG. 3</figref> is a flowchart of a method of temporal multithreading according to some embodiments.</p>
      <p id="p-00009-en" num="0009">
        <figref>FIG. 4</figref> is a table illustrating an example of temporal multithreading with four pipeline stages, according to some embodiments.</p>
      <p id="p-00010-en" num="0010">
        <figref>FIG. 5</figref> is a block diagram of an example of a debug architecture for multithreaded processors according to some embodiments.</p>
      <p id="p-00011-en" num="0011">
        <figref>FIG. 6</figref> is a flowchart of a method for performing a debug procedure for multithreaded processors, according to some embodiments.</p>
    </description-of-drawings>
    <detailed-desc>
      <heading id="h-00004-en" level="1">DETAILED DESCRIPTION</heading>
      <p id="p-00012-en" num="0012">Embodiments disclosed herein are directed to a debug architecture for multithreaded processors. In some implementations, these systems and methods may be applicable to various types of microcontrollers, controllers, microprocessors, processors, central processing units (CPUs), programmable devices, etc., which are generically referred to herein as âprocessors.â In general, a processor may be configured to perform a wide variety of operationsâand may take a variety of formsâdepending upon its particular application (e.g., automotive, communications, computing and storage, consumer electronics, energy, industrial, medical, military and aerospace, etc.). Accordingly, as will be understood by a person of ordinary skill in the art in light of this disclosure, the processor(s) described below are provided only for sake of illustration, and numerous variations are contemplated.</p>
      <p id="p-00013-en" num="0013">In various implementations, systems and methods described herein may be used to provide debug support logic with access to information manipulated by a processor's one or more cores, with multiple threads and/or automatic context switch features, and without interfering with the processor's pipeline. As such, these systems and methods may allow having one or more threads in debug mode while others continue to execute. In some cases, not being affected by the debug access logic, the pipeline logic may be made simpler, smaller, and faster.</p>
      <p id="p-00014-en" num="0014">A debug architecture as described herein may be configured to support processor cores with context switching, where the context is stored in a memory or secondary register file. For example, such a system may include: (a) one or more processor cores (including pipeline and registers/flags), (b) context storage (memory or register file) used to store thread contexts with suspended execution, (c) a context unit responsible for executing save/restore of context to/from the context storage from/into the processor state registers/flags, and (d) a debug support unit.</p>
      <p id="p-00015-en" num="0015">The foregoing debug architecture may context switch between multiple application threads, saving and restoring them from the context storage. The context unit may execute a context switch upon a request from dedicated scheduling hardware, a software request, or a halt command from the debug support unit or the processor itself. Halt requests may make the context unit suspend the execution of the running thread and save its context into the context storage, as it does in a thread preemption operation. However, in this case, the halted thread may only be put back into normal execution upon a request from the debug unit. This halting process may be performed with multiple threads, so that a plurality of them can be halted in a given time. The threads in halt state may have their contexts accessed by the debug unit through the arbitration of the context unit. The processor cores can continue executing code from other threads not halted, context switches being performed as usual.</p>
      <p id="p-00016-en" num="0016">In some embodiments, systems and methods for a debug architecture described herein may leverage hardware context memory and switch mechanism used in conventional multithreading applications to implement hardware debug support features. The same mechanism(s) used to save/restore thread context to/from context storage may provide debug features such as breakpoint, single-step, register/flag examining and modification.</p>
      <p id="p-00017-en" num="0017">Turning to <figref>FIG. 1</figref>, a block diagram of processor <b>100</b> is depicted according to some embodiments. As shown, processing block <b>101</b> includes at least one core <b>102</b>, which may be configured to execute programs, interrupt handlers, etc. In various embodiments, core <b>102</b> may include any suitable 8, 16, 32, 64, 128-bit, etc. processing core capable of implementing any of a number of different instruction set architectures (ISAs), such as the x86, POWERPCÂ®, ARMÂ®, SPARCÂ®, or MIPSÂ® ISAs, etc. In additional or alternative implementations, core <b>102</b> may be a graphics-processing unit (GPU) or other dedicated graphics-rendering device. Processing block <b>101</b> also includes memory management unit (MMU) <b>103</b>, which may in turn include one or more translation look-aside buffers (TLBs) or the like, and which may be configured to translate logical addresses into physical addresses. Port controller <b>104</b> is coupled to processing block <b>101</b> and may allow a user to test processor <b>100</b>, perform debugging operations, program one or more aspects of processor <b>100</b>, etc. Examples of port controller <b>104</b> may include a Joint Test Action Group (JTAG) controller and/or a Nexus controller. Internal bus <b>105</b> couples system memory <b>106</b> and Direct Memory Access (DMA) circuit or module <b>107</b> to processing block <b>101</b>. In various embodiments, internal bus <b>105</b> may be configured to coordinate traffic between processing block <b>101</b>, system memory <b>106</b>, and DMA <b>107</b>.</p>
      <p id="p-00018-en" num="0018">System memory <b>106</b> may include any tangible or non-transitory memory element, circuit, or device, which, in some cases, may be integrated within processor <b>100</b> as one chip. For example, system memory <b>106</b> may include registers, Static Random Access Memory (SRAM), Magnetoresistive RAM (MRAM), Nonvolatile RAM (NVRAM, such as âflashâ memory), and/or Dynamic RAM (DRAM) such as synchronous DRAM (SDRAM), double data rate (e.g., DDR, DDR2, DDR3, etc.) SDRAM, read only memory (ROM), erasable ROM (EROM), erasable programmable ROM (EPROM), electrically erasable programmable ROM (EEPROM), etc. In some cases, memory <b>106</b> may also include one or more memory modules to which the memory devices are mounted, such as single inline memory modules (SIMMs), dual inline memory modules (DIMMs), etc. DMA <b>107</b> includes a programmable data transfer circuit configured to effect certain memory operations (e.g., on behalf of modules <b>109</b>-<b>111</b>) without intervention from processing block <b>101</b>.</p>
      <p id="p-00019-en" num="0019">Input/output (I/O) bus <b>108</b> is coupled to internal bus <b>105</b> (e.g., via a bus interface) as well as communication module(s) <b>109</b>, sensor module(s) <b>110</b>, and control module(s) <b>111</b>. In some embodiments, I/O bus <b>108</b> may be configured to coordinate I/O traffic and to perform any protocol, timing, and/or other data transformations to convert data signals from one component (e.g., sensor module(s) <b>110</b>) into a format suitable for use by another component (e.g., processing block <b>101</b>). Communication module(s) <b>109</b> may include, for example, a Controller Area Network (CAN) controller, a serial, Ethernet, or USB controller, a wireless communication module, etc. Sensor module(s) <b>110</b> and control module(s) <b>111</b> may include circuitry configured to allow processor <b>100</b> to interface with any suitable sensor or actuator (not shown).</p>
      <p id="p-00020-en" num="0020">Embodiments of processor <b>100</b> may include, but are not limited to, application specific integrated circuit (ASICs), system-on-chip (SoC) circuits, digital signal processor (DSPs), processors, microprocessors, controllers, microcontrollers, or the like. As previously noted, different implementations of processor <b>100</b> may take different forms, and may support various levels of integration. For example, in some applications, DMA <b>107</b> may be absent or replaced with custom-designed memory access circuitry. In other applications, internal bus <b>105</b> may be combined with I/O bus <b>108</b>. In yet other applications, one or more other blocks shown in <figref>FIG. 1</figref> (e.g., modules <b>109</b>-<b>111</b>) may be combined into processing block <b>101</b>. In various embodiments, processor <b>100</b> may be a âmulti-coreâ processor having two or more cores (e.g., dual-core, quad-core, etc.) and/or two or more processing blocks <b>101</b>. It is noted that elements such as clocks, timers, etc., which are otherwise ordinarily found within processor <b>100</b>, have been omitted from the discussion of <figref>FIG. 1</figref> for simplicity of explanation.</p>
      <p id="p-00021-en" num="0021">In some embodiments, processor <b>100</b> may be employed in real-time, embedded applications (e.g., engine or motor control, intelligent timers, etc.) that benefit from the efficient use of processor <b>100</b>'s processing resources. Additionally or alternatively, processor <b>100</b> may be deployed in energy-scarce environments (e.g., in battery or solar-powered devices, etc.) that also benefit from a more efficient use of processing resources. Accordingly, processor <b>100</b> may be fitted with elements, circuits, or modules configured to implement one or more temporal multithreading techniques, as described in more detail in connection with <figref>FIGS. 2-4</figref>.</p>
      <p id="p-00022-en" num="0022">At this point it is appropriate to note that the term âthread,â as used herein, generally refers to a unit of processing, and that the term âmultithreadingâ refers to the ability of a processor (e.g., processor <b>100</b>) to switch between different threads, thereby attempting to increase its utilization. In some environments, âunits of processingâ may be referred to as âtasksâ or simply as a âprocesses,â and therefore it should be understood that one or more of the techniques described herein may also be applicable to âmultitaskingâ or âmultiprocessing.â When switching between threads, a processor may also switch between corresponding âcontexts.â Generally speaking, a âthread contextâ is a set of data or variables used by a given thread that, if saved or otherwise preserved, allows the thread to be interruptedâe.g., so that a different thread may be executedâand then continued at a later time (specific data or variables making up a thread context may depend upon the type of processor, application, thread, etc.). As also used herein, the term âpipeliningâ generally refers to a processor's ability to divide each instruction into a particular sequence of operations or stages (e.g., fetch, decode, etc.) and to execute each stage separately. In some cases, distinct electrical circuits and/or portions of the same processor core (e.g., core <b>102</b> in <figref>FIG. 1</figref>) may be involved in implementing each pipelining stage. Thus, for example, a single processor core may be capable of executing a fetch operation of a first instruction, a decode operation of a second instruction, and an execute operation of a third instruction all concurrently or simultaneously (e.g., during a same clock cycle).</p>
      <p id="p-00023-en" num="0023">There are two distinct types of multithreadingâtemporal and simultaneous. In âsimultaneous multithreading,â instructions from more than one thread execute in any given pipeline stage at the same time. In âtemporal multithreading,â however, a single thread of instructions is executed in a given pipeline stage at a given time.</p>
      <p id="p-00024-en" num="0024">Turning now to <figref>FIG. 2</figref>, a block diagram of temporal multithreading circuit <b>200</b> is depicted. As illustrated, context memory CTXMEM <b>203</b> is coupled to context read/write controller <b>201</b>, which in turn is coupled to multithreading control engine <b>210</b>. Context read/write controller <b>201</b> and multithreading control engine <b>210</b> are both operably coupled to first context register set or bank CTX<b>1</b><b>204</b> and to second context register set or bank CTX<b>2</b><b>205</b>. Multithreading control engine <b>210</b> is operably coupled to each of a plurality of pipeline stages P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b>, as well as external thread control <b>202</b>. In some embodiments, elements <b>201</b>, <b>202</b>, and <b>204</b>-<b>210</b> of circuit <b>200</b> may be implemented within core <b>102</b> of processor <b>100</b>, shown in <figref>FIG. 1</figref>. Accordingly, in the case of a multi-core implementation, each of elements <b>201</b>, <b>202</b>, and <b>204</b>-<b>210</b> of circuit <b>200</b> may be repeated within each respective core (so that each such core may perform one or more of the operations described below independently of each other). Context memory CTXMEM <b>203</b> may reside outside of core <b>102</b> and, in a multi-core implementation, it may be operably coupled to and/or shared among the plurality of cores.</p>
      <p id="p-00025-en" num="0025">In operation, context memory CTXMEM <b>203</b> may be configured to store a plurality of thread contexts under control of context read/write controller <b>201</b>. For example, context read/write controller <b>201</b> may retrieve a thread context from CTXMEM <b>203</b> and store it in one of register sets or banks CTX<b>1</b><b>204</b> or CTX<b>2</b><b>205</b>, each of which including registers that define a processor's programming model (e.g., pc, sp, r0, . . . , rn, etc.). After the thread context is retrieved and stored in one of register sets CTX<b>1</b><b>204</b> or CTX<b>2</b><b>205</b>, pipeline stages P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b> may be capable of executing a given thread based on that thread context. For instance, in some embodiments, first pipeline stage P<b>1</b><b>206</b> may perform a âfetchâ operation, second pipeline stage P<b>2</b><b>207</b> may perform a âdecodeâ operation, third pipeline stage P<b>3</b><b>208</b> may perform an âexecuteâ operation, and fourth pipeline stage P<b>4</b><b>209</b> may perform a âwrite-backâ operation. In other embodiments, however, other number of pipeline stages (e.g., 3, 5, 6, etc.) may be used, and different operations may be associated with each stage.</p>
      <p id="p-00026-en" num="0026">When a thread's execution is complete or otherwise halted (e.g., upon actual completion of the thread, triggering of an interrupt, etc.), context read/write controller <b>201</b> may retrieve an updated thread context from a respective one of register sets CTX<b>1</b><b>204</b> or CTX<b>2</b><b>205</b>, and it may store the updated context in context memory CTXMEM <b>203</b>. In various implementations, context memory CTXMEM <b>203</b> may be separate from system memory <b>106</b> and/or it may be dedicated exclusively to the storage of thread contexts and/or it may be accessible by software.</p>
      <p id="p-00027-en" num="0027">In some embodiments, multithreading control engine <b>210</b> may be configured to control the transit or flow of thread contexts between context memory CTXMEM <b>203</b> and register sets CTX<b>1</b><b>204</b>/CTX<b>2</b><b>205</b> in response to a signal, command, or indication received from external thread control <b>202</b>. Examples of external thread control <b>202</b> may include sources or events (i.e., context switch events) such as, for instance, hardware or software schedulers, timer overflows, completion of external memory operations, completion of analog to digital conversions, logic level changes on a sensor's input, data received via a communication interface, entering of a sleep or power-saving mode, etc. Multithreading control engine <b>210</b> may also be configured to receive messages or instructions (e.g., read and write instructions) from pipeline stages P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b>, and to direct each instruction to an appropriate one of register sets CTX<b>1</b><b>204</b> or CTX<b>2</b><b>205</b>. Accordingly, pipeline stages P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b> may issue instructions that are context-agnosticâi.e., each pipeline stage may execute instructions without knowing which thread is being executedâbecause multithreading control engine <b>210</b> may be in charge of directing those instructions to an appropriate one between register sets CTX<b>1</b><b>204</b>/CTX<b>2</b><b>205</b> at an appropriate time.</p>
      <p id="p-00028-en" num="0028">For example, during execution of a first thread, multithreading control engine <b>210</b> may direct all instructions received from each pipeline stages P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b> to first register set CTX<b>1</b><b>204</b>, and first register set CTX<b>1</b><b>204</b> may be configured to store a first thread context corresponding to the first thread. In response to a command received from external thread control <b>202</b> to switch execution to a second thread, multithreading control engine <b>210</b> may cause context read/write controller <b>201</b> to retrieve a second thread context (corresponding to the second thread) from context memory CTXMEM <b>203</b>, and to store that second thread context in second register set CTX<b>2</b><b>205</b>. In some cases, this retrieve and store operation may occur without interruption of the first thread, which continues to execute based on the contents of first register set CTX<b>1</b><b>204</b>. Then, multithreading control engine <b>210</b> may direct an instruction from first pipeline stage P<b>1</b><b>206</b> to second register set CTX<b>2</b><b>205</b> to thereby begin execution of the second thread. Moreover, instructions already in the pipeline may continue to execute after the second thread has begun. For instance, multithreading control engine <b>210</b> may direct an instruction from second pipeline state P<b>2</b><b>207</b> to first register set CTX<b>1</b><b>204</b> to continue execution of the first thread. These, as well as other operations, are described in more detail below with respect to <figref>FIGS. 3 and 4</figref>.</p>
      <p id="p-00029-en" num="0029">In some embodiments, the modules or blocks shown in <figref>FIG. 2</figref> may represent processing circuitry and/or sets of software routines, logic functions, and/or data structures that, when executed by the processing circuitry, perform specified operations. Although these modules are shown as distinct blocks, in other embodiments at least some of the operations performed by these blocks may be combined in to fewer blocks. For example, in some cases, context read/write controller <b>201</b> may be combined with multithreading control engine <b>210</b>. Conversely, any given one of modules <b>201</b>-<b>210</b> may be implemented such that its operations are divided among two or more blocks. Although shown with a particular configuration, in other embodiments these various modules or blocks may be rearranged in other suitable ways.</p>
      <p id="p-00030-en" num="0030">
        <figref>FIG. 3</figref> is a flowchart of a method of temporal multithreading. In some embodiments, method <b>300</b> may be performed at least in part, by temporal multithreading circuit <b>200</b> of <figref>FIG. 2</figref> within core <b>102</b> of processor <b>100</b> in <figref>FIG. 1</figref>. At block <b>301</b>, a plurality of pipeline stages P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b> execute a first thread T<b>0</b> based on thread context data and/or variables stored in a first register set CTX<b>1</b><b>204</b>. At block <b>302</b>, method <b>300</b> determines whether to switch to the execution of a second thread T<b>1</b>. For example, as noted above, external thread control <b>202</b> may transmit a command specifically requesting the thread or context switch to T<b>1</b>. If not, control returns to block <b>302</b>. Otherwise control passes to block <b>303</b>.</p>
      <p id="p-00031-en" num="0031">At block <b>303</b>, method <b>300</b> reads thread context data and/or variables associated with second thread T<b>1</b> from context memory from CTXMEM <b>203</b>, and stores it in second register set CTX<b>2</b><b>205</b>. The process of block <b>303</b> may occur under control of temporal multithreading circuit <b>200</b> and without interfering with the execution of first thread T<b>0</b> between pipeline stages P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b> and first register set CTX<b>1</b><b>204</b>. In other words, while context read/write controller <b>201</b> retrieves T<b>1</b>'s thread context from context memory CTXMEM <b>203</b> and stores it in second register set CTX<b>2</b><b>205</b>, temporal multithreading circuit <b>210</b> may continue to direct or send one or more instructions from pipeline stages P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b> to first register set CTX<b>1</b><b>204</b>.</p>
      <p id="p-00032-en" num="0032">At block <b>304</b>, method <b>300</b> may switch each of the plurality of pipeline stages P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b> to execute second thread T<b>1</b> based on the thread context data and/or variables newly stored in second register set CTX<b>2</b><b>205</b>. To achieve this, temporal multithreading circuit <b>200</b> may direct, send, or transmit instructions received from each of pipeline stages P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b> to second register set CTX<b>2</b><b>205</b>âi.e., instead of first register set CTX<b>1</b><b>204</b>. Moreover, the process of block <b>304</b> may be implemented such that each pipeline stage is switched from T<b>0</b> to T<b>1</b> one at a time (e.g., first P<b>1</b><b>206</b>, then P<b>2</b><b>207</b>, followed by P<b>3</b><b>208</b>, and finally P<b>4</b><b>209</b>). Pipeline stages that have not switched to the second thread T<b>1</b> during this process may continue to have one or more instructions directed to first register set CT<b>1</b><b>204</b> (independently and/or in the absence of a command to resume and/or continue execution of the first thread T<b>0</b>).</p>
      <p id="p-00033-en" num="0033">For example, a first instruction received from first pipeline stage P<b>1</b><b>206</b> may be directed to second register set CTX<b>2</b><b>205</b>, and a second instruction received from second pipeline stage P<b>2</b><b>207</b> concurrently with or following (e.g., immediately following) the first instruction may be directed to first register set CTX<b>1</b><b>204</b>. Then, in a subsequent clock cycle(s), a third instruction received from second pipeline stage P<b>2</b><b>207</b> may be directed to second register set CTX<b>2</b><b>205</b>, and a fourth instruction received from third pipeline stage P<b>3</b><b>208</b> concurrently with or following (e.g., immediately following) the third instruction may be directed to first register set CTX<b>1</b><b>204</b>. The process may then continue in a cascaded manner until all pipeline stages have switched to the execution of second thread T<b>1</b>âi.e., until all instructions are directed to second register set CTX<b>2</b><b>205</b>.</p>
      <p id="p-00034-en" num="0034">At block <b>305</b>, method <b>300</b> determines whether all pipeline stages have switched to the execution of second thread T<b>1</b>. It not, control returns to block <b>304</b>. Otherwise, control passes to block <b>306</b>. At block <b>306</b>, method <b>300</b> saves the last updated version of the first thread context data and/or variables, still stored in first register set CTX<b>1</b><b>204</b>, to context memory CTXMEM <b>203</b>. Similarly as explained above, the process of block <b>306</b> may occur without interfering with the execution of the second thread T<b>1</b> between P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b> and second register set CTX<b>2</b><b>205</b>.</p>
      <p id="p-00035-en" num="0035">It should be understood that, in several applications, method <b>300</b> may be repeated to support subsequent thread context switches. For example, after block <b>306</b> and in response to another command to switch to execution to another thread, method <b>300</b> may determine whether the other thread is the same as T<b>0</b>, in which case there is no need to retrieve the corresponding thread context from context memory CTXMEM <b>203</b> (it is still available in first register set CTX<b>1</b><b>204</b>). Then, method <b>300</b> may switch the execution of each pipeline stage P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b>, one at a time, back to first register set CTX<b>1</b><b>204</b>. For example, first pipeline stage P<b>1</b><b>206</b> may have an instruction directed to first register set CTX<b>1</b><b>204</b> to resume execution of T<b>0</b>, while second pipeline stage P<b>2</b><b>207</b> may have a subsequent instruction directed to second register set CTX<b>2</b><b>205</b> to continue execution of T<b>1</b>âand so on, until all pipeline stages P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b> have switched back to T<b>0</b>.</p>
      <p id="p-00036-en" num="0036">On the other hand, in the more general case where the other thread is in fact a third thread (T<b>2</b>) that is different from T<b>0</b> (and T<b>1</b>), a corresponding thread context may be retrieved from context memory CTXMEM <b>203</b> and stored in first register set CTX<b>1</b><b>204</b>, thus replacing the thread context of first thread T<b>0</b> previously residing in CTX<b>1</b><b>204</b>, and without interrupting execution of second thread T<b>1</b> between pipeline stages P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b> and second register set CTX<b>2</b><b>205</b>. Again, method <b>300</b> may switch the execution of each pipeline stage P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b>, one at a time, to first register set CTX<b>1</b><b>204</b>. For example, first pipeline stage P<b>1</b><b>206</b> may have an instruction directed to first register set CTX<b>1</b><b>204</b> to initiate execution of third thread T<b>2</b>, while second pipeline stage P<b>2</b><b>207</b> has a subsequent instruction directed to second register set CTX<b>2</b><b>205</b> to continue execution of second thread T<b>1</b>âand so on, until all stages have switched to T<b>2</b>.</p>
      <p id="p-00037-en" num="0037">To further illustrate method <b>300</b>, <figref>FIG. 4</figref> depicts table <b>400</b> showing an example of temporal multithreading with four pipeline stages according to some embodiments. Each column in table <b>400</b> represents one or more clock cycles, and has retained a number that corresponds to a respective block in method <b>300</b> for ease of explanation. At column <b>301</b>, all pipeline stages P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b> are shown executing first thread T<b>0</b> based upon a corresponding thread context stored in first register set CTX<b>1</b><b>204</b>. Second register set CTX<b>2</b><b>205</b> is empty and/or its initial state may not be relevant. Block <b>302</b> of <figref>FIG. 3</figref> is illustrated in table <b>400</b> as taking place between columns <b>301</b> and <b>303</b>, when external thread control <b>202</b> transmits a command to multithreading control engine <b>210</b> requesting a switch from first thread T<b>0</b> to second thread T<b>1</b>.</p>
      <p id="p-00038-en" num="0038">Sometime after having received the context switch command (e.g., after one or more clock cycle(s)), column <b>303</b> shows that a thread context corresponding to second thread T<b>1</b> has been stored in second register set CTX<b>2</b><b>205</b>, while pipeline stages P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b> are still executing first thread T<b>0</b> based on the thread context stored in first register set CTX<b>1</b><b>204</b>. In other words, as noted above, the thread context of second thread T<b>1</b> may be retrieved from context memory CTXMEM <b>203</b> and stored in second register set CTX<b>2</b><b>205</b> without interfering with the execution of first thread T<b>0</b>.</p>
      <p id="p-00039-en" num="0039">Columns <b>304</b> show each of pipeline stages P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b> being sequentially switched from T<b>0</b> to T<b>1</b> in a cascaded fashion under control of multithreading control engine <b>210</b>. Specifically, at a first clock cycle(s) within columns <b>304</b>, only first pipeline stage P<b>1</b><b>206</b> has its instruction(s) directed to second register set CTX<b>2</b><b>205</b>, but subsequent pipeline stages P<b>2</b>-P<b>4</b><b>207</b>-<b>209</b> still have their instructions directed to first register set CTX<b>1</b><b>204</b> by multithreading control engine <b>210</b>. This may occur without there having been an explicit command or request that pipeline stages P<b>2</b>-P<b>4</b> continue execution of first thread T<b>0</b>. Because this example involves four pipeline stages, it may take four clock cycles for all pipeline stages to complete their transitions to second thread T<b>1</b>. This is shown in column <b>305</b>, where all of P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b> are executing second thread T<b>1</b> based on the thread context stored in second register set CTX<b>2</b><b>205</b>. Here it should be noted that, during at least a portion of the context switching operation, both first and second thread T<b>0</b> and T<b>1</b> are being executed simultaneously, concurrently, or in parallel under control of multithreading control engine <b>210</b>. As such, neither of T<b>0</b> or T<b>1</b>'s execution is interrupted by the switching operation, which in many cases may result in the more effective use of processor resources.</p>
      <p id="p-00040-en" num="0040">Still referring to <figref>FIG. 4</figref>, context memory CTXMEM <b>203</b> is shown in table <b>400</b> as storing a plurality of thread contexts T<b>0</b>-TN at all times. However, context memory CTXMEM <b>203</b> does not have the most up-to-date version of all thread contexts all the time. For example, context memory CTXMEM <b>203</b> does not have the latest context corresponding to first thread T<b>0</b> while T<b>0</b> is being executed by one or more of pipeline stages P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b> (i.e., during the clock cycles shown between column <b>301</b> and the next-to-last column in <b>304</b>). But at column <b>305</b> first thread T<b>0</b> is no longer being executed by any pipeline stage. Therefore, block <b>306</b> is also represented in table <b>400</b> as illustrating multithreading control engine <b>210</b>'s command to context read/write controller <b>201</b> to retrieve the updated thread context for T<b>0</b> from first register set CTX<b>1</b><b>204</b> and to store it in context memory CTXMEM <b>203</b>. Similarly, context memory CTXMEM <b>203</b> does not have the most up-to-date version of second thread T<b>1</b> while T<b>1</b> is being executed by one or more of pipeline stages P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b>âi.e., during the clock cycles shown in columns <b>304</b>. After a subsequent context switching operation (not shown), an updated version of T<b>1</b> may also be stored in context memory CTXMEM <b>203</b>.</p>
      <p id="p-00041-en" num="0041">As described above, in some embodiments, some of the systems and methods described herein may provide a processor configured to executes many threads, via hardware-switching, and using only two context register sets. Other embodiments may include more context register sets. Moreover, the processor uses two thread contexts during at least one or more of the same clock cyclesâi.e., concurrently, simultaneously, or in parallel. Accordingly, pipeline stages within such a processor may therefore remain busy, even during context switch operations, thus improving its utilization and efficiency. A separate memory (e.g., context memory CTXMEM <b>203</b>) may be used for context saving, and it may be invisible to the programming or software model, thus not interfering with its execution.</p>
      <p id="p-00042-en" num="0042">In some cases, a large number of thread contexts may be stored in a dedicated context memory at a small design or silicon cost (e.g., RAM has a relatively small footprint and/or power requirements), thus reducing the need for relatively more expensive components (e.g., in an embodiment, only two register sets CTX<b>1</b><b>204</b> and CTX<b>2</b><b>205</b> may be employed, which generally have a large footprint and/or power requirements per context compared to context memory CTXMEM <b>203</b>), as well as reducing the costs of running two or more threads. Moreover, a pair of register sets CTX<b>1</b><b>204</b> and CTX<b>2</b><b>205</b> may be both accessed by the execution pipeline stages P<b>1</b>-P<b>4</b><b>206</b>-<b>209</b> concurrently, simultaneously, or in parallel during at least a portion of the context switching operation, and both may be either source or target for context save/restore operation(s). As a person of ordinary skill in the art will recognize in light of this disclosure, these and other features may enable a more efficient use of processor resources and/or electrical power.</p>
      <p id="p-00043-en" num="0043">
        <figref>FIG. 5</figref> is a block diagram of an example of debug architecture <b>500</b> for multithreaded processors. In some embodiments, architecture <b>500</b> may be implemented in connection with processor <b>100</b> of <figref>FIG. 1</figref> and temporal multithreading circuit <b>200</b> of <figref>FIG. 1</figref>. Particularly, content storage block <b>503</b> may be used to implement context memory CTXMEM <b>203</b> outside of processor cores <b>102</b>A-N. Context management block <b>501</b> may include, for instance, context read/write controller <b>201</b> and/or multithreading control engine <b>210</b>. In operation, processor core(s) <b>102</b>A-N may be configured to execute one or more threads simultaneously or concurrently, and each core may be capable of switching between two or more such threads or processes.</p>
      <p id="p-00044-en" num="0044">In <figref>FIG. 5</figref>, debug support block <b>502</b> is coupled to context management block <b>501</b>, which in turn is coupled to processor core(s) <b>102</b>A-N, context storage block <b>503</b>, and hardware scheduler block <b>504</b>. Generally, debug support block <b>502</b> may be configured to send halt and go requests or commands to context management block <b>501</b> in order to initiate and/or terminate a debug process. The debug process may be triggered, for example, under control or hardware scheduler block <b>504</b> and/or in response to a command from software (e.g., a breakpoint) under execution by the processor core(s) <b>102</b>A-N. Debug support block <b>502</b> may also access content storage block <b>503</b> via context management block <b>501</b> via a context access bus or the like.</p>
      <p id="p-00045-en" num="0045">Processor core(s) <b>102</b>A-N may be configured to perform context save and restore transactions with context storage <b>503</b> through context management block <b>501</b> via a save/restore bus. Processor core(s) <b>102</b>A-N may also receive and/or transmit context switch and/or halt requests to or from context management block <b>501</b>. Hardware scheduler <b>504</b> may be configured to issue context switch requests to context management block <b>501</b>.</p>
      <p id="p-00046-en" num="0046">Operation of debug architecture <b>500</b> may be explained with reference to <figref>FIG. 6</figref>. Specifically, <figref>FIG. 6</figref> is a flowchart of method <b>600</b> for performing a debug procedure in multithreaded processors. In some embodiments, method <b>600</b> may be performed, at least in part, using debug architecture <b>500</b>. At block <b>601</b>, method <b>600</b> includes sending a halt request from debug support block <b>502</b> to context management block <b>501</b>. The halt request or command may be received, for example, in response to a command from hardware scheduler <b>504</b> or in response to a command from debug software under execution by processor core(s) <b>102</b>A-N.</p>
      <p id="p-00047-en" num="0047">At block <b>602</b>, in response to receiving a halt command, context management block <b>501</b> may cause a given one of processor cores <b>102</b>A-N to save the context of a thread onto context storage block <b>503</b>, and may suspend execution of that thread. At block <b>603</b>, a debug operation is performed based upon the context stored in context storage <b>503</b>, and without there having to be access to internal components of processor core(s) <b>102</b>A-N (e.g., registers, etc.). At block <b>604</b>, debug support block <b>502</b> determines whether the debug process is finished. If not control returns to block <b>603</b>.</p>
      <p id="p-00048-en" num="0048">If the debug process is finished, then at block <b>605</b> debug support block <b>502</b> sends a go request or command to context management block <b>501</b>, which at block <b>606</b> allows processor core(s) <b>102</b>A-N to resume execution of the suspended thread, for example, by loading the context of the thread from context storage block <b>503</b> back onto internal registers of processor core(s) <b>102</b>A-N.</p>
      <p id="p-00049-en" num="0049">In some embodiments, processor core(s) <b>102</b>A-N may be configured to execute a second thread at least in part while the execution of a first thread is suspended. The second thread may be executed using a second context stored in the context memory prior to receipt of the go command. Moreover, two or more debug operations may be performed concurrently for two different threads. For example, in response to receiving a second halt command, the second context may be stored in the context memory, execution of the second thread may be suspended, and a debug of the second thread may be executed at least in part concurrently with the debug of the first thread using the second contextâthat is, the second halt command may be issued prior to issuance of the first thread's go command.</p>
      <p id="p-00050-en" num="0050">Also, in some cases, in response to receiving a context switch command from hardware scheduler <b>504</b>, for example, and after having received the halt command, context management block <b>501</b> prioritizes execution of the context switch command over execution of the halt command.</p>
      <p id="p-00051-en" num="0051">As explained herein, in an illustrative, non-limited embodiment, an integrated circuit may include a processor core; a context management circuit operably coupled to the processor core; and a debug support circuit operably coupled to the context management circuit, where the debug support circuit is configured to send a halt request to the context management circuit, and where the context management circuit is configured to, in response to having received the halt request, facilitate a debug operation by causing execution of a thread running on the processor core to be suspended and saving a context of the thread into a context memory distinct from the processor core.</p>
      <p id="p-00052-en" num="0052">For example, the halt request may be issued in response to a command from a scheduling circuit operably coupled to the context management circuit. Additionally or alternatively, the halt request may be issued in response to a command from software under execution by the processor core. Moreover, the processor core may be configured to execute a second thread at least in part while the execution of the thread is suspended.</p>
      <p id="p-00053-en" num="0053">The debug support circuit may be further configured to issue a go request, and where the context management circuit is configured to allow the processor core to resume execution of the thread using the context in response to having received the go request.</p>
      <p id="p-00054-en" num="0054">The debug support circuit may be configured to issue a second halt request to the context management circuit, and the context management circuit may be configured to, in response to having received the second halt request, facilitate a second debug operation by causing execution of a second thread running on the processor core to be suspended and saving a context of the second thread into the context memory. The second debug operation may occur at least in part concurrently with the debug operation. The context management circuit may be configured to receive a context switch command after having received the halt request, and the context management circuit may be configured to prioritize execution of the context switch command over execution of the halt request.</p>
      <p id="p-00055-en" num="0055">In another illustrative, non-limiting embodiment, a method may include, in response to receiving a halt command, saving a context of a thread being executed by a processor core to a context memory distinct from the processor core; suspending execution of the thread; and initiating a debug of the thread using the context stored in the context memory. The method may further include executing a second thread at least in part while the execution of the thread is suspended.</p>
      <p id="p-00056-en" num="0056">In response to receiving a go command, the method may include loading the context of the thread from the context memory onto the processor core, and resuming execution of the thread. The method may also include executing a second thread using a second context stored in the context memory prior to receipt of the go command. The method may further include, in response to receiving a second halt command, saving a second context of a second thread being executed by the processor in the context memory; suspending execution of the second thread; and initiating a debug of the second thread at least in part concurrently with the debug of the thread using the second context stored in the context memory. The method may also include receiving a context switch command after having received the halt command, and prioritizing execution of the context switch command over execution of the halt command.</p>
      <p id="p-00057-en" num="0057">In yet another illustrative, non-limiting embodiment, a debug support circuit may include a logic unit; and a memory coupled to the logic unit, the memory having program instructions stored thereon that, upon execution by the logic unit, cause the debug support circuit to: transmit a first command to a context management circuit, where the context management circuit is coupled to a processor, and where the context management circuit is configured to cause execution of a thread running on the processor to be suspended and save a context of the thread into a context memory distinct from the processor in response to the first command; determine that the a debug operation has been completed with respect to the thread; and transmit a second command to the context management circuit, where the context management circuit is configured to allow the processor to resume execution of the thread in the context memory in response to the second command.</p>
      <p id="p-00058-en" num="0058">The first and second commands may be transmitted in response to a command from a hardware circuit coupled to the context management circuit. Additionally or alternatively, the first and second commands may be transmitted in response to a command from software executed by the processor. The processor may be configured to execute a second thread at least in part while the execution of the thread is suspended.</p>
      <p id="p-00059-en" num="0059">The program instructions, upon execution by the logic unit, may further cause the debug support circuit to transmit a third command to the context management circuit, where the context management circuit is configured to, in response to having received the third command, cause execution of a second thread running on the processor to be suspended and save a context of the second thread into the context memory; determine that a second debug operation has been completed with respect to the second thread; and transmit a fourth command to the context management circuit, where the context management circuit is configured to allow the processor to resume execution of the second thread in response to the fourth command. Also, the third command may be transmitted prior to transmission of the second command and while execution of the thread is suspended.</p>
      <p id="p-00060-en" num="0060">In some embodiments, the blocks shown in <figref>FIGS. 1</figref>, <b>2</b>, and <b>5</b> may represent processing circuitry and/or sets of software routines, logic functions, and/or data structures that, when executed by the processing circuitry, perform specified operations. Although these modules are shown as distinct logical blocks, in other embodiments at least some of the operations performed by these modules may be combined in to fewer blocks. Conversely, any given one block may be implemented such that its operations are divided among two or more logical blocks. Although shown with a particular configuration, in other embodiments these various modules or blocks may be rearranged in other suitable ways.</p>
      <p id="p-00061-en" num="0061">It should be understood that the various operations explained herein, particularly in connection with <figref>FIGS. 3</figref>, <b>4</b>, and <b>6</b>, may be implemented in software executed by processing circuitry, hardware, or a combination thereof. The order in which each operation of a given method is performed may be changed, and various elements of the systems illustrated herein may be added, reordered, combined, omitted, modified, etc. It is intended that the invention(s) described herein embrace all such modifications and changes and, accordingly, the above description should be regarded in an illustrative rather than a restrictive sense.</p>
      <p id="p-00062-en" num="0062">Although the invention(s) is/are described herein with reference to specific embodiments, various modifications and changes can be made without departing from the scope of the present invention(s), as set forth in the claims below. Accordingly, the specification and figures are to be regarded in an illustrative rather than a restrictive sense, and all such modifications are intended to be included within the scope of the present invention(s). Any benefits, advantages, or solutions to problems that are described herein with regard to specific embodiments are not intended to be construed as a critical, required, or essential feature or element of any or all the claims.</p>
      <p id="p-00063-en" num="0063">Unless stated otherwise, terms such as âfirstâ and âsecondâ are used to arbitrarily distinguish between the elements such terms describe. Thus, these terms are not necessarily intended to indicate temporal or other prioritization of such elements. The term âcoupledâ is defined as connected, although not necessarily directly, and not necessarily mechanically. The terms âaâ and âanâ are defined as one or more unless stated otherwise. The terms âcompriseâ and any form of comprise, such as âcomprisesâ and âcomprisingâ), âhaveâ (and any form of have, such as âhasâ and âhavingâ), âincludeâ (and any form of include, such as âincludesâ and âincludingâ) and âcontainâ (and any form of contain, such as âcontainsâ and âcontainingâ) are open-ended linking verbs. As a result, a system, device, or apparatus that âcomprises,â âhas,â âincludesâ or âcontainsâ one or more elements possesses those one or more elements but is not limited to possessing only those one or more elements. Similarly, a method or process that âcomprises,â âhas,â âincludesâ or âcontainsâ one or more operations possesses those one or more operations but is not limited to possessing only those one or more operations.</p>
    </detailed-desc>
  </description>
  <claims id="claims_eng" lang="eng" format="original" date-changed="20160303">
    <claim num="1" id="clm-00001-en">
      <claim-text>
        <b>1</b>. An integrated circuit, comprising:
<claim-text>a processor core;</claim-text><claim-text>a context management circuit operably coupled to the processor core; and</claim-text><claim-text>a debug support circuit operably coupled to the context management circuit, wherein the debug support circuit is configured to send a halt request to the context management circuit, and wherein the context management circuit is configured to, in response to having received the halt request, facilitate a debug operation by causing execution of a thread running on the processor core to be suspended and saving a context of the thread into a context memory distinct from the processor core.</claim-text></claim-text>
    </claim>
    <claim num="2" id="clm-00002-en">
      <claim-text>
        <b>2</b>. The integrated circuit of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, wherein the halt request is issued in response to a command from a scheduling circuit operably coupled to the context management circuit.</claim-text>
    </claim>
    <claim num="3" id="clm-00003-en">
      <claim-text>
        <b>3</b>. The integrated circuit of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, wherein the halt request is issued in response to a command from software under execution by the processor core.</claim-text>
    </claim>
    <claim num="4" id="clm-00004-en">
      <claim-text>
        <b>4</b>. The integrated circuit of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, wherein the processor core is configured to execute a second thread at least in part while the execution of the thread is suspended.</claim-text>
    </claim>
    <claim num="5" id="clm-00005-en">
      <claim-text>
        <b>5</b>. The integrated circuit of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, wherein the debug support circuit is further configured to issue a go request, and wherein the context management circuit is configured to allow the processor core to resume execution of the thread using the context in response to having received the go request.</claim-text>
    </claim>
    <claim num="6" id="clm-00006-en">
      <claim-text>
        <b>6</b>. The integrated circuit of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, wherein the debug support circuit is configured to issue a second halt request to the context management circuit, and wherein the context management circuit is configured to, in response to having received the second halt request, facilitate a second debug operation by causing execution of a second thread running on the processor core to be suspended and saving a context of the second thread into the context memory.</claim-text>
    </claim>
    <claim num="7" id="clm-00007-en">
      <claim-text>
        <b>7</b>. The integrated circuit of <claim-ref idref="clm-00006-en">claim 6</claim-ref>, wherein the second debug operation occurs at least in part concurrently with the debug operation.</claim-text>
    </claim>
    <claim num="8" id="clm-00008-en">
      <claim-text>
        <b>8</b>. The integrated circuit of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, wherein the context management circuit is configured to receive a context switch command after having received the halt request, and wherein the context management circuit is configured to prioritize execution of the context switch command over execution of the halt request.</claim-text>
    </claim>
    <claim num="9" id="clm-00009-en">
      <claim-text>
        <b>9</b>. A method, comprising:
<claim-text>in response to receiving a halt command, saving a context of a thread being executed by a processor core to a context memory distinct from the processor core;</claim-text><claim-text>suspending execution of the thread; and</claim-text><claim-text>initiating a debug of the thread using the context stored in the context memory.</claim-text></claim-text>
    </claim>
    <claim num="10" id="clm-00010-en">
      <claim-text>
        <b>10</b>. The method of <claim-ref idref="clm-00009-en">claim 9</claim-ref>, further comprising executing a second thread at least in part while the execution of the thread is suspended.</claim-text>
    </claim>
    <claim num="11" id="clm-00011-en">
      <claim-text>
        <b>11</b>. The method of <claim-ref idref="clm-00009-en">claim 9</claim-ref>, further comprising:
<claim-text>in response to receiving a go command, loading the context of the thread from the context memory onto the processor core; and</claim-text><claim-text>resuming execution of the thread.</claim-text></claim-text>
    </claim>
    <claim num="12" id="clm-00012-en">
      <claim-text>
        <b>12</b>. The method of <claim-ref idref="clm-00011-en">claim 11</claim-ref>, further comprising executing a second thread using a second context stored in the context memory prior to receipt of the go command.</claim-text>
    </claim>
    <claim num="13" id="clm-00013-en">
      <claim-text>
        <b>13</b>. The method of <claim-ref idref="clm-00012-en">claim 12</claim-ref>, further comprising:
<claim-text>in response to receiving a second halt command, saving a second context of a second thread being executed by the processor in the context memory;</claim-text><claim-text>suspending execution of the second thread; and</claim-text><claim-text>initiating a debug of the second thread at least in part concurrently with the debug of the thread using the second context stored in the context memory.</claim-text></claim-text>
    </claim>
    <claim num="14" id="clm-00014-en">
      <claim-text>
        <b>14</b>. The method of <claim-ref idref="clm-00013-en">claim 13</claim-ref>, further comprising:
<claim-text>receiving a context switch command after having received the halt command, and prioritizing execution of the context switch command over execution of the halt command.</claim-text></claim-text>
    </claim>
    <claim num="15" id="clm-00015-en">
      <claim-text>
        <b>15</b>. A debug support circuit, comprising:
<claim-text>a logic unit; and</claim-text><claim-text>a memory coupled to the logic unit, the memory having program instructions stored thereon that, upon execution by the logic unit, cause the debug support circuit to:
<claim-text>transmit a first command to a context management circuit, wherein the context management circuit is coupled to a processor, and wherein the context management circuit is configured to cause execution of a thread running on the processor to be suspended and save a context of the thread into a context memory distinct from the processor in response to the first command;</claim-text><claim-text>determine that the a debug operation has been completed with respect to the thread; and</claim-text><claim-text>transmit a second command to the context management circuit,</claim-text></claim-text><claim-text>wherein the context management circuit is configured to allow the processor to resume execution of the thread in the context memory in response to the second command.</claim-text></claim-text>
    </claim>
    <claim num="16" id="clm-00016-en">
      <claim-text>
        <b>16</b>. The debug support circuit of <claim-ref idref="clm-00015-en">claim 15</claim-ref>, wherein the first and second commands are transmitted in response to a command from a hardware circuit coupled to the context management circuit.</claim-text>
    </claim>
    <claim num="17" id="clm-00017-en">
      <claim-text>
        <b>17</b>. The debug support circuit of <claim-ref idref="clm-00015-en">claim 15</claim-ref>, wherein the first and second commands are transmitted in response to a command from software executed by the processor.</claim-text>
    </claim>
    <claim num="18" id="clm-00018-en">
      <claim-text>
        <b>18</b>. The debug support circuit of <claim-ref idref="clm-00015-en">claim 15</claim-ref>, wherein the processor is configured to execute a second thread at least in part while the execution of the thread is suspended.</claim-text>
    </claim>
    <claim num="19" id="clm-00019-en">
      <claim-text>
        <b>19</b>. The debug support circuit of <claim-ref idref="clm-00015-en">claim 15</claim-ref>, wherein the program instructions, upon execution by the logic unit, cause the debug support circuit to:
<claim-text>transmit a third command to the context management circuit, wherein the context management circuit is configured to, in response to having received the third command, cause execution of a second thread running on the processor to be suspended and save a context of the second thread into the context memory;</claim-text><claim-text>determine that a second debug operation has been completed with respect to the second thread; and</claim-text><claim-text>transmit a fourth command to the context management circuit, wherein the context management circuit is configured to allow the processor to resume execution of the second thread in response to the fourth command.</claim-text></claim-text>
    </claim>
    <claim num="20" id="clm-00020-en">
      <claim-text>
        <b>20</b>. The debug support circuit of <claim-ref idref="clm-00019-en">claim 19</claim-ref>, wherein the third command is transmitted prior to transmission of the second command and while execution of the thread is suspended. </claim-text>
    </claim>
  </claims>
  <drawings id="drawings" format="original">
    <figure num="1">
      <img he="N/A" wi="N/A" file="US20160062874A1_00001.PNG" alt="clipped image" img-content="drawing" img-format="png" original="US20160062874A1-20160303-D00000.TIF" />
    </figure>
    <figure num="2">
      <img he="N/A" wi="N/A" file="US20160062874A1_00002.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20160062874A1-20160303-D00001.TIF" />
    </figure>
    <figure num="3">
      <img he="N/A" wi="N/A" file="US20160062874A1_00003.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20160062874A1-20160303-D00002.TIF" />
    </figure>
    <figure num="4">
      <img he="N/A" wi="N/A" file="US20160062874A1_00004.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20160062874A1-20160303-D00003.TIF" />
    </figure>
    <figure num="5">
      <img he="N/A" wi="N/A" file="US20160062874A1_00005.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20160062874A1-20160303-D00004.TIF" />
    </figure>
    <figure num="6">
      <img he="N/A" wi="N/A" file="US20160062874A1_00006.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20160062874A1-20160303-D00005.TIF" />
    </figure>
    <figure num="7">
      <img he="N/A" wi="N/A" file="US20160062874A1_00007.PNG" alt="thumbnail image" img-content="drawing" img-format="png" original="US20160062874A1-20160303-D00000.TIF" />
    </figure>
  </drawings>
  <image file="US20160062874A1.PDF" type="pdf" size="512702" pages="14" />
</lexisnexis-patent-document>