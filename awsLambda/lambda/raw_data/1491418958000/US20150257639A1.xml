<?xml version="1.0" encoding="utf-8"?>
<!-- Copyright ©2016 LexisNexis Univentio, The Netherlands. -->
<lexisnexis-patent-document schema-version="1.13" date-produced="20160127" file="US20150257639A1.xml" produced-by="LexisNexis-Univentio" lang="eng" date-inserted="20150917" time-inserted="030135" date-changed="20151002" time-changed="033552">
  <bibliographic-data lang="eng">
    <publication-reference publ-type="Application" publ-desc="Patent Application Publication">
      <document-id id="121314855">
        <country>US</country>
        <doc-number>20150257639</doc-number>
        <kind>A1</kind>
        <date>20150917</date>
      </document-id>
    </publication-reference>
    <application-reference appl-type="utility">
      <document-id>
        <country>US</country>
        <doc-number>14597213</doc-number>
        <date>20150114</date>
      </document-id>
    </application-reference>
    <application-series-code>14</application-series-code>
    <language-of-filing>eng</language-of-filing>
    <language-of-publication>eng</language-of-publication>
    <priority-claims date-changed="20150917">
      <priority-claim sequence="1" kind="national">
        <country>CL</country>
        <doc-number>005942014</doc-number>
        <date>20140312</date>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability date-changed="20150924">
      <unexamined-printed-without-grant>
        <date>20150917</date>
      </unexamined-printed-without-grant>
    </dates-of-public-availability>
    <classifications-ipcr date-changed="20150924">
      <classification-ipcr sequence="1">
        <text>A61B   3/00        20060101AFI20150917BHUS        </text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>3</main-group>
        <subgroup>00</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150917</date>
        </action-date>
        <generating-office>
          <country>US</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>A61B   3/11        20060101ALI20150917BHUS        </text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>3</main-group>
        <subgroup>11</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150917</date>
        </action-date>
        <generating-office>
          <country>US</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>A61B   3/14        20060101ALI20150917BHUS        </text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>3</main-group>
        <subgroup>14</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150917</date>
        </action-date>
        <generating-office>
          <country>US</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
    </classifications-ipcr>
    <classifications-cpc date-changed="20150924">
      <classification-cpc sequence="1">
        <text>A61B   3/0025      20130101 FI20150917BHEP        </text>
        <cpc-version-indicator>
          <date>20130101</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>3</main-group>
        <subgroup>0025</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150917</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
      <classification-cpc sequence="2">
        <text>A61B   3/112       20130101 LI20150917BHEP        </text>
        <cpc-version-indicator>
          <date>20130101</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>3</main-group>
        <subgroup>112</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150917</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
      <classification-cpc sequence="3">
        <text>A61B   3/14        20130101 LI20150917BHEP        </text>
        <cpc-version-indicator>
          <date>20130101</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>3</main-group>
        <subgroup>14</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150917</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
    </classifications-cpc>
    <number-of-claims calculated="yes">20</number-of-claims>
    <invention-title id="title_eng" date-changed="20150917" lang="eng" format="original">SYSTEM AND DEVICE FOR PRELIMINARY DIAGNOSIS OF OCULAR DISEASES</invention-title>
    <parties date-changed="20150917">
      <applicants>
        <applicant sequence="1" app-type="applicant" designation="us-only">
          <addressbook lang="eng">
            <orgname>EYECARE S.A.</orgname>
            <address>
              <city>Santiago</city>
              <country>CL</country>
            </address>
          </addressbook>
          <residence>
            <country>CL</country>
          </residence>
        </applicant>
      </applicants>
      <inventors>
        <inventor sequence="1" designation="us-only">
          <addressbook lang="eng">
            <last-name>Manquez Hatta</last-name>
            <first-name>Maria Eliana</first-name>
            <address>
              <city>Santiago</city>
              <country>CL</country>
            </address>
          </addressbook>
        </inventor>
        <inventor sequence="2" designation="us-only">
          <addressbook lang="eng">
            <last-name>Lobos Sucarrat</last-name>
            <first-name>Humberto</first-name>
            <address>
              <city>Santiago</city>
              <country>CL</country>
            </address>
          </addressbook>
        </inventor>
      </inventors>
    </parties>
    <patent-family date-changed="20150917">
      <main-family family-id="173667904">
        <family-member>
          <document-id>
            <country>US</country>
            <doc-number>20150257639</doc-number>
            <kind>A1</kind>
            <date>20150917</date>
          </document-id>
          <application-date>
            <date>20150114</date>
          </application-date>
        </family-member>
      </main-family>
      <complete-family family-id="173667901">
        <family-member>
          <document-id>
            <country>US</country>
            <doc-number>20150257639</doc-number>
            <kind>A1</kind>
            <date>20150917</date>
          </document-id>
          <application-date>
            <date>20150114</date>
          </application-date>
        </family-member>
      </complete-family>
    </patent-family>
  </bibliographic-data>
  <abstract id="abstr_eng" date-changed="20150917" lang="eng" format="original">
    <p id="p-a-00001-en" num="0000">A system for preliminary diagnosis of ocular diseases is proposed, in which from capturing a plurality of images of the eyes of a person, a final image, corrected by processing the images by a computer application, is obtained. The already mentioned application calculates the percentage of the colors composing the pupillary reflex of each eye, and compares the results with previous reference pictures obtained from normal cases and clinical cases of ocular diseases.</p>
  </abstract>
  <legal-data date-changed="20151002">
    <legal-event sequence="1">
      <publication-date>
        <date>20150115</date>
      </publication-date>
      <event-code-1>AS</event-code-1>
      <legal-description>ASSIGNMENT</legal-description>
      <status-identifier>N</status-identifier>
      <docdb-publication-number> US  2015257639A1</docdb-publication-number>
      <docdb-application-id>444510958</docdb-application-id>
      <new-owner>EYECARE S. A., CHILE</new-owner>
      <free-text-description>ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:MANQUEZ HATTA, MARIA ELIANA;SUCARRAT, HUMBERTO LOBOS;REEL/FRAME:034730/0534</free-text-description>
      <effective-date>
        <date>20141230</date>
      </effective-date>
    </legal-event>
  </legal-data>
  <description id="descr_eng" lang="eng" format="original" date-changed="20150917">
    <summary>
      <heading id="h-00001-en" level="1">BACKGROUND</heading>
      <p id="p-00001-en" num="0001">1. Field of the Invention</p>
      <p id="p-00002-en" num="0002">The present invention relates to the field of ophthalmology, and particularly provides a system and a configured device for preliminary diagnosis of ocular diseases, which is based on imaging of the eyes and on the diagnosis of ocular disorders, on the basis of the processing of these images and the reflection values of the retina and/or the pupil that they provide.</p>
      <p id="p-00003-en" num="0003">2. Description of Related Art</p>
      <p id="p-00004-en" num="0004">An estimate based on the National Health Survey (ENS 2007) indicates that at least 1.5% to 2.6% of the Chilean population has some visual impairment, of this percentage is estimated that at least ¼ of them has chronic defects classified as blindness. The world situation is not so different, and this reveals that there are at least 12 million children under the age of 10, which is the age group of preventive control, suffer from visual impairment due to refractive error (myopia, strabismus or astigmatism) in addition there are more severe cases like ocular cancer that affects 1 in 12,000 live births, which is usually seen in children up to 5 years old. All of these conditions and others, in most cases can be corrected without major complications with a preventive diagnosis and effective treatment in infants from birth to about 5 years old, preventing these disorders getting worse with time and treatment being too expensive, ineffective or simply being too late to be implemented.</p>
      <p id="p-00005-en" num="0005">Most of these problems could be detected at an early age, but require continuous medical supervision and examinations which are carried out with high-cost instruments that also require the presence of specialists to use them.</p>
      <p id="p-00006-en" num="0006">For the group of infants (0-5 years) which is the control group and primary diagnosis, there are two key problems in performing these tests: it is difficult to make that infants focus their gaze intently to any device that performs the test and also the ophthalmologist or pediatrician has only fraction of a second to capture the image before the pupil shrinks in response to the bright flash light. These problems lead to pediatricians are unable to detect ocular problems early, and therefore cannot effectively take preventive measures before the problem getting worse.</p>
      <p id="p-00007-en" num="0007">The red pupillary reflex is fairly well understood by ophthalmologists and pediatric specialists worldwide, and has been used as a diagnostic instrument around the world since the 60s. Normally, the light reaches the retina and a portion of it is reflected off the pupil by the choroid or posterior uvea, which is a layer of small vessels and pigmented cells located near the retina. The reflected light, seen from a coaxial instrument to the optical plane of the eye, normally present a reddish color, due to the color of blood and pigments of the cells, so this color can vary from shiny reddish or yellowish in people with light pigmentation to a more grayish red or dark pigmentation in people with dark pigmentation. In 1962, Bruckner (Bruckner R. Exakte Strabismus diagnostic bei 1/2-3 jahrigen Kindern mit einem einfachen Verfahren, dem “Durchleuchtungstest.” Ophthalmologica 1962; 144: 184-98) described abnormalities in the pupillary reflex as well as in quality, intensity, symmetry or presence of abnormal figures, therefore, pupilar red color test is also known as Bruckner test. Another similar test is the Hirschberg test, which uses the corneal reflex to detect misalignment of the eyes, which enables to diagnose some degree of strabismus (Wheeler, M. “Objective Strabismometry in Young Children.” Trans Am Ophthalmol Soc 1942; 40:. 547-564). In summary, these tests are used to detect misalignment of the eyes (strabismus), different sizes of the eyes (anisometropy), abnormal growths in the eye (tumors), opacity (cataract) and any abnormalities in the light refraction (myopia, hyperopia, astigmatism).</p>
      <p id="p-00008-en" num="0008">The evaluation of the pupillary and corneal reflexes is a medical procedure that can be performed with an ophthalmoscope, an instrument invented by Francis A. Welch and William Noah Allyn in 1915 and used since the last century. Today, his company Welch Allyn, has products that follow this line as Pan Optic™. There are also photographic screening type portable devices for the evaluation of pupilar red color as Plusoptix (Patent application No. WO9966829) or Spot™ Photoscreener (Patent Application No. EP2676441A2), but the cost ranges between USD 100 to 500, they weigh about 1 kg and also require experience in interpreting the observed images.</p>
      <p id="p-00009-en" num="0009">With regard to state of the art, concerning computer applications for the prompt diagnosis of ocular diseases, the application No. FR2876570 A1 by Mawas, presents a process to obtain a picture with a camera and remit it in negative to a specialist ophthalmologist via email, in order to detect strabismus (Hirschberg test); however, this lacks the processing of the image, the immediately preliminary diagnosis and its application to mobile devices. The patent application No. US2013235346 A1 by Huang, points to a smart device application to obtain a set of pictures, at two specified working distances, and four orientations to run of photo-refraction tests, Bruckner and Hirschberg test, but requires masks that function like outlines on the screen, where the patient's face is fixed to obtain working distances, and there is no subsequent processing of images for a higher quality image.</p>
      <p id="p-00010-en" num="0010">The present invention is a practical and reliable solution for rapid diagnosis of ocular problems, which allows a preliminary examination only with the use of smart phones or tablet type devices, currently used by millions of people worldwide. The application can be run by parents, paramedics, pediatricians and ophthalmologists without the need for a more complex instrument or experience in the use of these, and effectively allows conducting a test to detect ocular problems. This application prototype was tested in 100 infants, from which 3 children with problems were detected, and which were referred to specialists who positively found ocular problems. The system allows to conduct a preliminary medical test regarding to the pupillary reflex (pupillary red color test or Bruckner test) and corneal reflex (Hirschberg test).</p>
      <heading id="h-00002-en" level="1">SUMMARY OF THE INVENTION</heading>
      <p id="p-00011-en" num="0011">The present invention relates to a system for the preliminary diagnosis of ocular diseases, said system comprising: <ul id="ul-00001-en" list-style="none"><li><ul id="ul-00002-en" list-style="none"><li>a device for capturing images or a camera;</li><li>a device generating light or a flash;</li><li>a screen for displaying the image;</li><li>a memory for storing data</li><li>a computational application stored in the memory that executes the process of capturing a plurality of images of the eyes of an individual, and a final corrected image obtained through the processing of said plurality of images, by performing a post-processing of the final image corrected by calculating the percentage of the colors that compose the pupillary reflex of each eye and comparing it with the values obtained for previous clinical cases;</li><li>and a processor functionally attached to the camera, the flash, the screen and the memory, such that runs the application.</li></ul></li></ul></p>
      <p id="p-00012-en" num="0018">In the system of the invention, the memory further includes images for the comparison of the final corrected image with previously diagnosed clinical cases, with ocular diseases.</p>
      <p id="p-00013-en" num="0019">The system can be implemented by using a computational device, a smart phone, or any device with connection to a camera, either an internal camera or a webcam and a system of a lighting device, of a built-in flash type.</p>
      <p id="p-00014-en" num="0020">The present invention also includes an “ex vivo” method for the preliminary diagnosis of ocular diseases, comprising the steps of: <ul id="ul-00003-en" list-style="none"><li><ul id="ul-00004-en" list-style="none"><li>focusing the image of the individual's eyes, using a camera and a screen of a computing device;</li><li>eliminating ambient lighting; in case a light is on in the room, the light is turned off, and if there is natural light, closing the windows or curtains to decrease it;</li><li>capturing a plurality of images of the individual's eyes with said camera, using the flash;</li><li>processing the plurality of images, by using a computational application in order to obtain a final corrected image of the individual's eyes;</li><li>displaying the said final corrected image on the screen and visually comparing it with clinical cases previously diagnosed with ocular diseases.</li></ul></li></ul></p>
      <p id="p-00015-en" num="0026">For the processing of the plurality of images, in order to obtain a final corrected image, the computational application includes the following steps: <ul id="ul-00005-en" list-style="none"><li><ul id="ul-00006-en" list-style="none"><li>i. making a first selection of images from the plurality of images;</li><li>ii. obtaining an approximation of the area of the individual's face in each image of the said first selection;</li><li>iii. aligning the mentioned first selection of images, from the edge detection by its spatial translation in each image of the said first selection;</li><li>iv. determining the area of the two eyes in each image of the said first selection;</li><li>v. obtaining a determined location of the center of the two eyes from each image of the said first selection;</li><li>vi. making a second selection of images, from said first selection, to select a single image of the individual's eyes with greater sharpness;</li><li>vii. processing that said single image to obtain a final corrected image with greater focus;</li><li>viii. cutting the eyes of the individual from that final corrected image, from the determined location of the centers and calculating the area of the two eyes; and</li><li>ix. post-processing the final corrected image, to detect the percentage of the colors that compose the pupillary reflex.</li></ul></li></ul></p>
      <p id="p-00016-en" num="0036">The computational application makes the said first selection from the plurality of images obtained by the camera, discriminating on the luminance of the pixels and selecting in said first selection between 1 and 60 images, preferably, between the best 10 images.</p>
      <p id="p-00017-en" num="0037">The computational application obtains the approximation of the individual's face, detecting it in a first image captured from the said first selection, and then cutting the area of all the later images to the first image for further processing.</p>
      <p id="p-00018-en" num="0038">On the other hand, for aligning the said first selection of the plurality of images, the computational application finds the edges in the first image captured from said first selection, and searches these edges in the later images, to calculate the translation of these images with respect to said first image. Then, it calculates the location of the centers of the pupil of each eye for each image, removing outliers and averaging the position of said centers obtained to get the best determined location of the centers.</p>
      <p id="p-00019-en" num="0039">The computational application makes a second selection with respect to the sharpness of each image of said first selection, obtaining a value which is representative of the sharpness of each image and selecting the one image with greater sharpness, which is corrected in order to obtain the final corrected image with greater focus, using the area of each eye and the determined location of the centers.</p>
      <p id="p-00020-en" num="0040">Finally, the computational application performing a post-processing of the final corrected image, by calculating the percentage of the colors that compose the pupillary reflex of each eye, selecting the red, white, orange and yellow colors.</p>
      <p id="p-00021-en" num="0041">In this process, the following three cases are defined: <ul id="ul-00007-en" list-style="none"><li><ul id="ul-00008-en" list-style="none"><li>If the red color is in a range greater than 50% of the pixels that compose the area of the pupil, in any of the eyes of the final processed image, the image is considered most likely of a normal eye.</li><li>If the red color is in a range greater than 50% of the pixels that compose the area of the pupil, while the yellow and/or orange percentages correspond to a higher range of 10% of the pixels that compose the area of the in one of the eyes of the final processed image, the eye probably presents a type of refractive defect.</li><li>If the red color is in a range lower than 50% of the pixels that compose the area of the iris and the pupil, while white corresponds to a percentage higher than 40% in any of the eyes of the final processed image the diagnosis corresponds to a suspicion for organic and/or structural disease.</li></ul></li></ul></p>
      <p id="p-00022-en" num="0045">Clinical cases that are previously diagnosed and used as reference for comparison of the images that the system of invention produce, consist of a set of three or more images previously obtained by the computing device, which represent normal cases, clinical cases of refractive defects and other ocular diseases.</p>
      <p id="p-00023-en" num="0046">Within the cases of refractive defects of the group that can be diagnosed with the system of the invention, we can found hyperopia, astigmatism and myopia; and it is also possible to make a fast screening of other ocular diseases, such as organic diseases and ocular functional diseases, Including tumors, malformations, strabismus, cataracts, etc.</p>
    </summary>
    <description-of-drawings>
      <heading id="h-00003-en" level="1">DESCRIPTION OF THE DRAWINGS</heading>
      <p id="p-00024-en" num="0047">The novel features believed characteristic of the application are set forth in the appended claims. However, the application itself, as well as a preferred mode of use, and further objectives and advantages thereof, will best be understood by reference to the following detailed description when read in conjunction with the accompanying drawings, wherein:</p>
      <p id="p-00025-en" num="0048">
        <figref>FIG. 1</figref> is a front and rear view of a smart phone, according to the invention.</p>
      <p id="p-00026-en" num="0049">
        <figref>FIG. 2</figref> is an example of using the device while the individual's eyes are focused, in this case, infant eyes.</p>
      <p id="p-00027-en" num="0050">
        <figref>FIG. 3</figref> is a screenshot of the application, running on a device according to the invention.</p>
      <p id="p-00028-en" num="0051">
        <figref>FIG. 4</figref> is an example of a diagnosis type, obtained from the device, according to the invention, of the normal pupillary reflex.</p>
      <p id="p-00029-en" num="0052">
        <figref>FIG. 5</figref> is an example of a diagnosis type, of a pupillary reflex with refractive ocular problems.</p>
      <p id="p-00030-en" num="0053">
        <figref>FIG. 6</figref> is an example of a diagnosis type, of a pupillary reflex with serious ocular problems.</p>
      <p id="p-00031-en" num="0054">
        <figref>FIGS. 7A and 7B</figref> are a comparison of an image obtained by an electronic device according to the invention (<figref>FIG. 7A</figref>), compared to the final image processed by the application in the same computing device (<figref>FIG. 7B</figref>).</p>
    </description-of-drawings>
    <detailed-desc>
      <p id="p-00032-en" num="0055">While the system and method of the present application is susceptible to various modifications and alternative forms, specific embodiments thereof have been shown by way of example in the drawings and are herein described in detail. It should be understood, however, that the description herein of specific embodiments is not intended to limit the application to the particular embodiment disclosed, but on the contrary, the intention is to cover all modifications, equivalents, and alternatives falling within the spirit and scope of the process of the present application as defined by the appended claims.</p>
      <heading id="h-00004-en" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT</heading>
      <p id="p-00033-en" num="0056">Illustrative embodiments of the preferred embodiment are described below. In the interest of clarity, not all features of an actual implementation are described in this specification. It will of course be appreciated that in the development of any such actual embodiment, numerous implementation-specific decisions must be made to achieve the developer's specific goals, such as compliance with system-related and business-related constraints, which will vary from one implementation to another. Moreover, it will be appreciated that such a development effort might be complex and time-consuming but would nevertheless be a routine undertaking for those of ordinary skill in the art having the benefit of this disclosure.</p>
      <p id="p-00034-en" num="0057">In the specification, reference may be made to the spatial relationships between various components and to the spatial orientation of various aspects of components as the devices are depicted in the attached drawings. However, as will be recognized by those skilled in the art after a complete reading of the present application, the devices, members, apparatuses, etc. described herein may be positioned in any desired orientation. Thus, the use of terms to describe a spatial relationship between various components or to describe the spatial orientation of aspects of such components should be understood to describe a relative relationship between the components or a spatial orientation of aspects of such components, respectively, as the device described herein may be oriented in any desired direction.</p>
      <p id="p-00035-en" num="0058">The present invention relates essentially to a system and method employing a computational application that can be executed on mobile devices and related devices, which allows obtaining a preliminary examination of ocular conditions, using the pupillary and corneal reflexes obtained from a photograph of the eyes.</p>
      <p id="p-00036-en" num="0059">Unlike the old cameras of the non-digital age, digital cameras and mobile devices, like current smartphones or tablets, are programmed with a temporary setup between camera and flash, in such a way to avoid the reflection of the red pupil in the pictures that are obtained with them. However, is not well known that this reflex has important information about ocular diseases, and can be used for their detection as a preliminary screening using the invention.</p>
      <p id="p-00037-en" num="0060">Since mobile devices are currently used by millions of people around the world, the purpose of the present invention is to provide an application easy to use to the general population, without requiring the utilization of complex ophthalmic instruments, and which recreates the effect of old cameras that can capture the reddish reflex of the eyes, but also includes a processing of the obtained image, so this reflection to be sharper and more focused.</p>
      <p id="p-00038-en" num="0061">The present invention, therefore, is a useful tool for the early and preliminary detection of ocular diseases, which are then confirmed by specialists. Furthermore, this computational application has been particularly useful for avoiding problems associated to perform ocular examinations in infants, since through it is not necessary to sleep them, keep them focused, or subjected to long ocular examinations, is not necessary to dilate their pupils by using pharmacological drops, with the consequent disadvantages that they usually produce. The present invention can perform this examination by simply lowering the ambient lighting before taking the pictures of the eye, using the flash. Infants are the group of greatest need for continuous ocular controls, because at this age they can develop many of the ocular problems that could have on their lives as adults, which often fail to be detected early.</p>
      <p id="p-00039-en" num="0062">The computational application of the present invention can be installed in any electronic device. A non-limiting example of a smartphone, according to the invention, is an iPhone 4S®, marketed by Apple Inc., and shown in <figref>FIG. 1</figref>. This smartphone has a camera for capturing images (lens <b>1</b>), a device generating light or flash <b>2</b>, a screen that allows displaying images <b>3</b> and serve to focus on the individual, a memory that stores the application and images, and a processor that runs the application to obtain the final images.</p>
      <p id="p-00040-en" num="0063">In <figref>FIG. 2</figref>, is represented how the camera of the device in question is activated, the output of the camera is shown on screen <b>3</b>. The focus point is marked with respect to the individual's eyes <b>4</b> touching the screen <b>5</b>, in order to proceed, subsequently, to lower the amount of ambient lighting. The pupil dilates naturally being in low light, so, at this moment, the taking of a plurality of images is activated, using the application.</p>
      <p id="p-00041-en" num="0064">
        <figref>FIG. 3</figref>, which is a graphical representation of a screenshot of the application, shows the button for the initiation of taking a plurality of images <b>6</b>, a setting button <b>7</b> and a button to display the images obtained <b>8</b>.</p>
      <p id="p-00042-en" num="0065">To begin capturing pictures, the application turns on the flash light <b>2</b>, but the pictures will begin to be processed when the application estimates that what is being captured is already under the influence of light from the flash. The application estimates the amount of light contained in each image, transforming these to Y′UV color space, which represent a luminance component Y′ and two chrominance components UV. The application calculates the average of the component Y′, which represents the luminance of the pixel. Then, calculating the luminance before starting and during the frames, the application discriminates from which frame to start capturing, as it is known from this frame, that the flash <b>2</b> is affecting the captured image.</p>
      <p id="p-00043-en" num="0066">Frames containing no flash light <b>2</b> are discarded. The application performs it by removing an arbitrary number of frames captured since the flash <b>2</b> started to work, so then be able to capture ten images to be used in the process.</p>
      <p id="p-00044-en" num="0067">The capture of the first image of the process is different from the others, since in this frame the approximate area of the individual's face is detected using an appropriate “haar cascade”, which is a process that captures the best section of the individual's face, and this section is cropped, obtaining the image to be used; this minimizes the amount of information to be processed by the application. In order to obtain the rest of the images, the same detected area is cropped, obtaining images of the same size as the first. Notably, the first frames pictures since the flash <b>2</b> has an effect, where the greatest effect on the retina reflex occurs, because at that time the pupil is dilated by the little pre-flash light. For this reason, the number of used frames does not exceed ten.</p>
      <p id="p-00045-en" num="0068">By completing the capture of the ten images, a camera stabilization process is performed, which helps to reduce camera shake or movement of the person in the sequence. To achieve this, first the position of the prominent edges of the image (“good features to track”) is detected. These same points are then searched in the next image frame by calculating the “optical flow”. After obtaining the points of the first image in the following one, the calculation of the translational suffered by the following image, regarding its predecessor, is performed. For this, the average of the motion vectors of all the prominent edges of this is calculated by transferring the image by that amount. This allows the eyes to be always in the same position in all the taken pictures, so it is possible, as will be explained later, to perform the detection of the important features, using not one, but several pictures.</p>
      <p id="p-00046-en" num="0069">With the images already aligned the area enclosed by each eye of each of the images is calculated, using a “cascade haar” both for the right eye and the left eye. Afterwards, using the image gradients the center of the pupil of each eye is obtained in each image. After, the images where all the features could not be detected are discarded.</p>
      <p id="p-00047-en" num="0070">At this time, a set of positions of centers and a set of areas where the eyes are, are available. With this, it is possible to calculate a position that represents better the eye center. To do this, first all outliers from the set of centers are eliminated and then position of all of them are averaged. A similar process is applied to each of the squares enclosing the eyes, getting the best square enclosing each eye. At the end, the process selects the picture that is less blurry as the final image.</p>
      <p id="p-00048-en" num="0071">To perform the above, a defocusing of each of the images, using a Gaussian filter is performed. Then, the fast Fourier transform (FFT) is calculated, and the average of 90% of the highest values are calculated, obtaining a value that estimates how sharper the image is. The chosen image is also passed by another process called “unsharp masking” to focus it digitally, which consists of blurring the image, using a Gaussian blur and subtracting the result to the original image on a weighted basis for a larger focus. Then, the portion of the image is cropped in the best frame obtained in the previous step for each eye, and another image, corresponding to the pupil and iris of the eye is cropped, from the best center also obtained in the previous step.</p>
      <p id="p-00049-en" num="0072">By the process just described, a good reflection on the retina can be obtained, producing a color which allows diagnostic analysis. This color is usually related to the internal condition of the eye. In a normal patient, this will be reddish tonality; and in abnormal cases could detect a white color that may indicate the existence of some abnormal body into the eye, or a yellow color indicating some eye deformation. So a post processing in which it is necessary to detect what color appeared in the pupil reflex shooting takes place. To do this the amount of red, white and yellow color in the image of the pupil is calculated. To do this the image of the pupil of each eye is transformed to HSV color space and passed through a mask that leaves in color white all colors within a specific range. The percentage of white pixels is then calculated, getting the percentage of that color in the image. <ul id="ul-00009-en" list-style="none"><li><ul id="ul-00010-en" list-style="none"><li>If the predominant color is red, it is likely that the eye looks normal. <figref>FIG. 4</figref> is an example of this case, where the reflection of the red pupil <b>10</b>, <b>11</b>, <b>12</b> and <b>13</b> seen in both eyes is normal.</li><li>If the predominant color is red, with a percentage of orange or yellow color, is likely to have a common problem in sight. <figref>FIG. 5</figref> is an example of this case, where the presence of a yellow reflection in the right eye <b>14</b> of the patient may be a sign of refractive errors or strabismus. It is recommended for this patient to request a visit to the ophthalmologist.</li><li>If the predominant color is white, there is probably a problem with a tumor disease in the eye. <figref>FIG. 5</figref> is an example of this case, where the reflection of the red reflex seen in the right eye <b>15</b> is normal. The white reflection in the left eye <b>16</b> may be a sign of a dangerous condition within the patient's eye. It is recommended for the patient to visit an ophthalmologist as soon as possible, urgently.</li><li>In case none of the above situations occurs, the analysis does not reach a conclusive result, so the patient should require an expert and conduct more complex tests with the proper equipment, to obtain a more accurate diagnosis.</li></ul></li></ul></p>
      <p id="p-00050-en" num="0077">Finally, the final processed image (<figref>FIG. 7B</figref>) can be seen, to be used for diagnosing ocular diseases. <figref>FIGS. 7A and 7B</figref> show a comparison between a normally captured image with an electronic device, according to the invention (<figref>FIG. 7A</figref>) and the final image processed by the computer application (<figref>FIG. 7B</figref>).</p>
      <p id="p-00051-en" num="0078">The particular embodiments and steps disclosed above are illustrative only, as the application may be modified and practiced in different but equivalent manners apparent to those skilled in the art having the benefit of the teachings herein. It is therefore evident that the particular embodiments and steps disclosed above may be altered or modified, and all such variations are considered within the scope and spirit of the application. Accordingly, the protection sought herein is as set forth in the description. It is apparent that an application with significant advantages has been described and illustrated. Although the present application is shown in a limited number of forms, it is not limited to just these forms, but is amenable to various changes and modifications without departing from the spirit thereof.</p>
    </detailed-desc>
  </description>
  <us-claim-statement>What is claimed is:</us-claim-statement>
  <claims id="claims_eng" lang="eng" format="original" date-changed="20150917">
    <claim num="1" id="clm-00001-en" independent="true">
      <claim-text>
        <b>1</b>. A system for the preliminary diagnosis of ocular diseases CHARACTERIZED in that it comprises:
<claim-text>a device for capturing images or a camera;</claim-text><claim-text>a device generating light or a flash;</claim-text><claim-text>a screen for displaying the image;</claim-text><claim-text>a memory for storing data;</claim-text><claim-text>a computational application stored in the memory that executes the process of capturing a plurality of images of the eyes of an individual, and a final corrected image obtained through the processing of said plurality of images, by performing a post-processing of the final image corrected by calculating the percentage of the colors that compose the pupillary reflex of each eye and comparing it with the values obtained for previous clinical cases; and</claim-text><claim-text>a processor functionally attached to the camera, the flash, the screen and the memory in such a way that it runs the application.</claim-text></claim-text>
    </claim>
    <claim num="2" id="clm-00002-en">
      <claim-text>
        <b>2</b>. The system of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, CHARACTERIZED in that the memory further includes images for the comparison of the final corrected image with previously diagnosed clinical cases, with ocular diseases.</claim-text>
    </claim>
    <claim num="3" id="clm-00003-en">
      <claim-text>
        <b>3</b>. The system of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, CHARACTERIZED in that a computational device is selected from the group consisting of a smart phone, a device with connection to a camera, either an internal camera or a webcam.</claim-text>
    </claim>
    <claim num="4" id="clm-00004-en">
      <claim-text>
        <b>4</b>. The system of <claim-ref idref="clm-00003-en">claim 3</claim-ref>, CHARACTERIZED in that it includes a lighting device of a built-in flash type.</claim-text>
    </claim>
    <claim num="5" id="clm-00005-en" independent="true">
      <claim-text>
        <b>5</b>. An “ex vivo” method for the preliminary diagnosis of ocular diseases, CHARACTERIZED in that said method comprises the steps of:
<claim-text>focusing the image of the individual's eyes, using a camera and a screen of a computing device;</claim-text><claim-text>eliminating ambient lighting;</claim-text><claim-text>capturing a plurality of images of the individual's eyes with said camera, using the flash;</claim-text><claim-text>processing the plurality of images, by using a computational application in order to obtain a final corrected image of the individual's eyes;</claim-text><claim-text>displaying said final corrected image on the screen;</claim-text><claim-text>visually comparing the final processed image with clinical cases previously diagnosed with ocular diseases.</claim-text></claim-text>
    </claim>
    <claim num="6" id="clm-00006-en">
      <claim-text>
        <b>6</b>. The method of <claim-ref idref="clm-00005-en">claim 5</claim-ref>, CHARACTERIZED in that the processing of the plurality of images to obtain a final corrected image by the computational application includes the steps of:
<claim-text>i. making a first selection of images from the plurality of images;</claim-text><claim-text>ii. obtaining an approximation of the area of the individual's face in each image of said first selection;</claim-text><claim-text>iii. aligning the mentioned first selection of images, from the edge detection by its spatial translation in each image of said first selection;</claim-text><claim-text>iv. determining the area of the two eyes in each image of said first selection;</claim-text><claim-text>v. obtaining a determined location of the center of the two eyes from each image of said first selection;</claim-text><claim-text>vi. making a second selection of images, from said first selection, to select a single image of the individual's eyes with greater sharpness;</claim-text><claim-text>vii. processing said single image to obtain a final corrected image with greater focus;</claim-text><claim-text>viii. cutting the eyes of the individual from that final corrected image, from the determined location of the centers and calculating the area of the two eyes; and</claim-text><claim-text>ix. post-processing the final corrected image, to detect the percentage of the colors that compose the pupillary reflex.</claim-text></claim-text>
    </claim>
    <claim num="7" id="clm-00007-en">
      <claim-text>
        <b>7</b>. The method of <claim-ref idref="clm-00006-en">claim 6</claim-ref>, CHARACTERIZED in that the computational application makes said first selection from the plurality of images obtained by the camera, discriminating on the luminance of the pixels.</claim-text>
    </claim>
    <claim num="8" id="clm-00008-en">
      <claim-text>
        <b>8</b>. The method of <claim-ref idref="clm-00006-en">claim 6</claim-ref>, CHARACTERIZED in that the number of images of said first selection ranges between 1 and 60 images.</claim-text>
    </claim>
    <claim num="9" id="clm-00009-en">
      <claim-text>
        <b>9</b>. The method of <claim-ref idref="clm-00006-en">claim 6</claim-ref>, CHARACTERIZED in that the computational application obtains the approximation of the individual's face, detecting it in a first image captured from said first selection, and then cuts the area of all the later images to the first image for further processing.</claim-text>
    </claim>
    <claim num="10" id="clm-00010-en">
      <claim-text>
        <b>10</b>. The method of <claim-ref idref="clm-00006-en">claim 6</claim-ref>, CHARACTERIZED in that in order to align said first selection of the plurality of images, the computational application finds the edges in the first image captured from said first selection, and searches these edges in the later images, to calculate the translation of these images with respect to said first image.</claim-text>
    </claim>
    <claim num="11" id="clm-00011-en">
      <claim-text>
        <b>11</b>. The method of <claim-ref idref="clm-00006-en">claim 6</claim-ref>, CHARACTERIZED in that the computational application calculates the location of the centers of the pupil of each eye for each image, removing outliers and averaging the position of said centers obtained to get the best determined location of the centers.</claim-text>
    </claim>
    <claim num="12" id="clm-00012-en">
      <claim-text>
        <b>12</b>. The method of <claim-ref idref="clm-00006-en">claim 6</claim-ref>, CHARACTERIZED in that the computational application makes a second selection with respect to the sharpness of each image of said first selection, obtaining a value which is representative of the sharpness of each image and selecting the one image with greater sharpness.</claim-text>
    </claim>
    <claim num="13" id="clm-00013-en">
      <claim-text>
        <b>13</b>. The method of <claim-ref idref="clm-00006-en">claim 6</claim-ref>, CHARACTERIZED in that the computer application using said single image, corrects it in order to obtain the final corrected image with greater focus.</claim-text>
    </claim>
    <claim num="14" id="clm-00014-en">
      <claim-text>
        <b>14</b>. The method of <claim-ref idref="clm-00006-en">claim 6</claim-ref>, CHARACTERIZED in that the computer application makes a cut of the final corrected image, using the area of each eye and the determined location of the centers.</claim-text>
    </claim>
    <claim num="15" id="clm-00015-en">
      <claim-text>
        <b>15</b>. The method of <claim-ref idref="clm-00006-en">claim 6</claim-ref>, CHARACTERIZED in that the computational application performs a post-processing of the final corrected image, by calculating the percentage of the colors that compound the pupillary reflex of each eye, selecting the red, white, orange and yellow colors.</claim-text>
    </claim>
    <claim num="16" id="clm-00016-en">
      <claim-text>
        <b>16</b>. The method of <claim-ref idref="clm-00015-en">claim 15</claim-ref>, CHARACTERIZED in that if the red color is in a range greater than 50% of the pixels that compose the area of the pupil, in any of the eyes of the final processed image, the diagnosis corresponds to a normal eye.</claim-text>
    </claim>
    <claim num="17" id="clm-00017-en">
      <claim-text>
        <b>17</b>. The method of <claim-ref idref="clm-00015-en">claim 15</claim-ref>, CHARACTERIZED in that if the red color is in a range greater than 50% of the pixels that compose the area of the pupil, while yellow and/or orange correspond to percentages in a range greater than 10% of the pixels that compose the area of the pupil, in any of the eyes of the final processed image, the diagnosis corresponds to an eye with a type of refractive defect.</claim-text>
    </claim>
    <claim num="18" id="clm-00018-en">
      <claim-text>
        <b>18</b>. The method of <claim-ref idref="clm-00015-en">claim 15</claim-ref>, CHARACTERIZED in that if the red color is in a range minor than 50% of the pixels that compose the area of the iris and the pupil, while white corresponds to a percentage greater than 40% in any of the eyes of the final processed image, the diagnosis is suspected to correspond to an organic and/or structural disease.</claim-text>
    </claim>
    <claim num="19" id="clm-00019-en">
      <claim-text>
        <b>19</b>. The method of <claim-ref idref="clm-00015-en">claim 15</claim-ref>, CHARACTERIZED in that the previously diagnosed clinical cases consist of a set of three or more images previously obtained by the computational device, which represent normal cases, clinical cases of refractive defects, such refractive defects are selected from the group consisting of hyperopia, astigmatism and myopia, and cases of other ocular diseases.</claim-text>
    </claim>
    <claim num="20" id="clm-00020-en">
      <claim-text>
        <b>20</b>. The method of <claim-ref idref="clm-00019-en">claim 19</claim-ref>, CHARACTERIZED in that said other ocular diseases are selected from the group consisting of organic and/or functional diseases such as tumors, malformations, strabismus or cataracts.</claim-text>
    </claim>
  </claims>
  <drawings id="drawings" format="original">
    <figure num="1">
      <img he="N/A" wi="N/A" file="US20150257639A1_00001.PNG" alt="clipped image" img-content="drawing" img-format="png" original="US20150257639A1-20150917-D00000.TIF" />
    </figure>
    <figure num="2">
      <img he="N/A" wi="N/A" file="US20150257639A1_00002.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150257639A1-20150917-D00001.TIF" />
    </figure>
    <figure num="3">
      <img he="N/A" wi="N/A" file="US20150257639A1_00003.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150257639A1-20150917-D00002.TIF" />
    </figure>
    <figure num="4">
      <img he="N/A" wi="N/A" file="US20150257639A1_00004.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150257639A1-20150917-D00003.TIF" />
    </figure>
    <figure num="5">
      <img he="N/A" wi="N/A" file="US20150257639A1_00005.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150257639A1-20150917-D00004.TIF" />
    </figure>
    <figure num="6">
      <img he="N/A" wi="N/A" file="US20150257639A1_00006.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150257639A1-20150917-D00005.TIF" />
    </figure>
    <figure num="7">
      <img he="N/A" wi="N/A" file="US20150257639A1_00007.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150257639A1-20150917-D00006.TIF" />
    </figure>
    <figure num="8">
      <img he="N/A" wi="N/A" file="US20150257639A1_00008.PNG" alt="thumbnail image" img-content="drawing" img-format="png" original="US20150257639A1-20150917-D00000.TIF" />
    </figure>
  </drawings>
  <image file="US20150257639A1.PDF" type="pdf" size="800951" pages="12" />
</lexisnexis-patent-document>