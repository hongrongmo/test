<?xml version="1.0" encoding="utf-8"?>
<!-- Copyright ©2016 LexisNexis Univentio, The Netherlands. -->
<lexisnexis-patent-document schema-version="1.13" date-produced="20160127" file="US20150257738A1.xml" produced-by="LexisNexis-Univentio" lang="eng" date-inserted="20150917" time-inserted="030141" date-changed="20151002" time-changed="033553">
  <bibliographic-data lang="eng">
    <publication-reference publ-type="Application" publ-desc="Patent Application Publication">
      <document-id id="121315076">
        <country>US</country>
        <doc-number>20150257738</doc-number>
        <kind>A1</kind>
        <date>20150917</date>
      </document-id>
    </publication-reference>
    <application-reference appl-type="utility">
      <document-id>
        <country>US</country>
        <doc-number>14656595</doc-number>
        <date>20150312</date>
      </document-id>
    </application-reference>
    <application-series-code>14</application-series-code>
    <language-of-filing>eng</language-of-filing>
    <language-of-publication>eng</language-of-publication>
    <priority-claims date-changed="20150917">
      <priority-claim sequence="1" kind="national">
        <country>KR</country>
        <doc-number>1020140029764</doc-number>
        <date>20140313</date>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability date-changed="20150924">
      <unexamined-printed-without-grant>
        <date>20150917</date>
      </unexamined-printed-without-grant>
    </dates-of-public-availability>
    <classifications-ipcr date-changed="20150929">
      <classification-ipcr sequence="1">
        <text>A61B   8/00        20060101AFI20150917BHUS        </text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>8</main-group>
        <subgroup>00</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150917</date>
        </action-date>
        <generating-office>
          <country>US</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>A61B   8/08        20060101ALI20150917BHUS        </text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>8</main-group>
        <subgroup>08</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150917</date>
        </action-date>
        <generating-office>
          <country>US</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
    </classifications-ipcr>
    <classifications-cpc date-changed="20150929">
      <classification-cpc sequence="1">
        <text>A61B   8/468       20130101 FI20150917BHEP        </text>
        <cpc-version-indicator>
          <date>20130101</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>8</main-group>
        <subgroup>468</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150917</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
      <classification-cpc sequence="2">
        <text>A61B   8/0866      20130101 LI20150919BHEP        </text>
        <cpc-version-indicator>
          <date>20130101</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>8</main-group>
        <subgroup>0866</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150919</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
      <classification-cpc sequence="3">
        <text>A61B   8/463       20130101 LI20150918BHEP        </text>
        <cpc-version-indicator>
          <date>20130101</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>8</main-group>
        <subgroup>463</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150918</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
      <classification-cpc sequence="4">
        <text>A61B   8/465       20130101 LI20150918BHEP        </text>
        <cpc-version-indicator>
          <date>20130101</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>8</main-group>
        <subgroup>465</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150918</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
      <classification-cpc sequence="5">
        <text>A61B   8/466       20130101 LI20150707BHEP        </text>
        <cpc-version-indicator>
          <date>20130101</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>8</main-group>
        <subgroup>466</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150707</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
      <classification-cpc sequence="6">
        <text>A61B   8/469       20130101 LI20150918BHEP        </text>
        <cpc-version-indicator>
          <date>20130101</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>8</main-group>
        <subgroup>469</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150918</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
      <classification-cpc sequence="7">
        <text>A61B   8/483       20130101 LI20150707BHEP        </text>
        <cpc-version-indicator>
          <date>20130101</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>8</main-group>
        <subgroup>483</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150707</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
      <classification-cpc sequence="8">
        <text>A61B   8/5207      20130101 LI20150707BHEP        </text>
        <cpc-version-indicator>
          <date>20130101</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>8</main-group>
        <subgroup>5207</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150707</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
      <classification-cpc sequence="9">
        <text>A61B   8/523       20130101 LI20150707BHEP        </text>
        <cpc-version-indicator>
          <date>20130101</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>8</main-group>
        <subgroup>523</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150707</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
      <classification-cpc sequence="10">
        <text>A61B   8/54        20130101 LI20150917BHEP        </text>
        <cpc-version-indicator>
          <date>20130101</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>8</main-group>
        <subgroup>54</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150917</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
    </classifications-cpc>
    <number-of-claims calculated="yes">19</number-of-claims>
    <invention-title id="title_eng" date-changed="20150917" lang="eng" format="original">ULTRASOUND DIAGNOSIS APPARATUS AND METHOD OF DISPLAYING ULTRASOUND IMAGE</invention-title>
    <parties date-changed="20150917">
      <applicants>
        <applicant sequence="1" app-type="applicant" designation="us-only">
          <addressbook lang="eng">
            <orgname>Samsung Medison Co., Ltd.</orgname>
            <address>
              <city>Gangwon-do</city>
              <country>KR</country>
            </address>
          </addressbook>
          <residence>
            <country>KR</country>
          </residence>
        </applicant>
      </applicants>
      <inventors>
        <inventor sequence="1" designation="us-only">
          <addressbook lang="eng">
            <last-name>KIM</last-name>
            <first-name>Han-eol</first-name>
            <address>
              <city>Gangwon-do</city>
              <country>KR</country>
            </address>
          </addressbook>
        </inventor>
      </inventors>
    </parties>
    <patent-family date-changed="20151009">
      <main-family family-id="173664189">
        <family-member>
          <document-id>
            <country>EP</country>
            <doc-number>2918233</doc-number>
            <kind>A1</kind>
            <date>20150916</date>
          </document-id>
          <application-date>
            <date>20150216</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>CN</country>
            <doc-number>104905814</doc-number>
            <kind>A</kind>
            <date>20150916</date>
          </document-id>
          <application-date>
            <date>20150313</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>KR</country>
            <doc-number>1020150107214</doc-number>
            <kind>A</kind>
            <date>20150923</date>
          </document-id>
          <application-date>
            <date>20140313</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>US</country>
            <doc-number>20150257738</doc-number>
            <kind>A1</kind>
            <date>20150917</date>
          </document-id>
          <application-date>
            <date>20150312</date>
          </application-date>
        </family-member>
      </main-family>
      <complete-family family-id="173664188">
        <family-member>
          <document-id>
            <country>EP</country>
            <doc-number>2918233</doc-number>
            <kind>A1</kind>
            <date>20150916</date>
          </document-id>
          <application-date>
            <date>20150216</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>CN</country>
            <doc-number>104905814</doc-number>
            <kind>A</kind>
            <date>20150916</date>
          </document-id>
          <application-date>
            <date>20150313</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>KR</country>
            <doc-number>1020150107214</doc-number>
            <kind>A</kind>
            <date>20150923</date>
          </document-id>
          <application-date>
            <date>20140313</date>
          </application-date>
        </family-member>
        <family-member>
          <document-id>
            <country>US</country>
            <doc-number>20150257738</doc-number>
            <kind>A1</kind>
            <date>20150917</date>
          </document-id>
          <application-date>
            <date>20150312</date>
          </application-date>
        </family-member>
      </complete-family>
    </patent-family>
  </bibliographic-data>
  <abstract id="abstr_eng" date-changed="20150917" lang="eng" format="original">
    <p id="p-a-00001-en" num="0000">Provided is an ultrasound diagnosis apparatus including: a display unit that displays a first screen including at least one marker; a user interface unit for receiving a selection of a predetermined marker among the at least one marker; and a controller that controls the display unit to display a first screen including a second ultrasound image that represents an object and has a view which is changed according to the predetermined marker. The ultrasound diagnosis apparatus may provide an ultrasound image screen that allows a user to easily and conveniently diagnose an object.</p>
  </abstract>
  <legal-data date-changed="20151002">
    <legal-event sequence="1">
      <publication-date>
        <date>20150417</date>
      </publication-date>
      <event-code-1>AS</event-code-1>
      <legal-description>ASSIGNMENT</legal-description>
      <status-identifier>N</status-identifier>
      <docdb-publication-number> US  2015257738A1</docdb-publication-number>
      <docdb-application-id>444511156</docdb-application-id>
      <new-owner>SAMSUNG MEDISON CO., LTD., KOREA, REPUBLIC OF</new-owner>
      <free-text-description>ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:KIM, HAN-EOL;REEL/FRAME:035434/0895</free-text-description>
      <effective-date>
        <date>20150311</date>
      </effective-date>
    </legal-event>
  </legal-data>
  <description id="descr_eng" lang="eng" format="original" date-changed="20150917">
    <summary>
      <heading id="h-00001-en" level="1">RELATED APPLICATIONS</heading>
      <p id="p-00001-en" num="0001">This application claims the benefit of Korean Patent Application No. 10-2014-0029764, filed on Mar. 13, 2014, in the Korean Intellectual Property Office, the disclosure of which is incorporated herein in its entirety by reference.</p>
      <heading id="h-00002-en" level="1">BACKGROUND</heading>
      <p id="p-00002-en" num="0002">1. Field</p>
      <p id="p-00003-en" num="0003">One or more embodiments of the present invention relate to an ultrasound diagnosis apparatus and a method of displaying an ultrasound image, and more particularly, to an ultrasound diagnosis apparatus and a method of displaying an ultrasound image, which allow a user to easily interpret an ultrasound image.</p>
      <p id="p-00004-en" num="0004">2. Description of the Related Art</p>
      <p id="p-00005-en" num="0005">An ultrasound diagnosis device transmits an ultrasound signal generated by a transducer in a probe to an object, receives information about an ultrasound echo signal reflected from the object, and acquires an image of a portion inside the object. In particular, an ultrasound diagnosis device is used for medical purposes such as observation of the internal structure of an object, detection of foreign substances, and measurement of the degree of an injury. An ultrasound diagnosis device has high stability compared to X-ray diagnosis equipment, allows real-time display of an image, and is highly safe due to no exposure to radiation. Therefore, ultrasound diagnosis devices have been widely used together with other types of imaging diagnosis devices.</p>
      <p id="p-00006-en" num="0006">In general, when a user (e.g., a doctor) interprets an ultrasound image, a marker is set within the ultrasound image for observation of a portion to be examined. Thus, there is a need for an ultrasound diagnosis device and a method of displaying an ultrasound image that allow easy interpretation of an ultrasound image based on a portion indicated by a set marker.</p>
      <heading id="h-00003-en" level="1">SUMMARY</heading>
      <p id="p-00007-en" num="0007">One or more embodiments include an ultrasound diagnostic apparatus and a method of displaying an ultrasound image that facilitate interpretation of an ultrasound image based on a portion indicated by a marker.</p>
      <p id="p-00008-en" num="0008">Additional aspects will be set forth in part in the description which follows and, in part, will be apparent from the description, or may be learned by practice of the presented embodiments.</p>
      <p id="p-00009-en" num="0009">According to one or more embodiments of the present invention, an ultrasound diagnosis apparatus includes: a display unit that displays a first screen including at least one marker; a user interface unit for receiving a selection of a predetermined marker among the at least one marker; and a controller that controls the display unit to display a second screen including a first ultrasound image that represents an object and has a view which is changed according to the predetermined marker.</p>
      <p id="p-00010-en" num="0010">The controller may change the view of the object based on position information of the predetermined marker and information about a viewpoint corresponding to the predetermined marker.</p>
      <p id="p-00011-en" num="0011">The apparatus may further include a memory for storing the position information of the predetermined marker and the information about the viewpoint corresponding to the predetermined marker.</p>
      <p id="p-00012-en" num="0012">The first screen may include a second ultrasound image representing an object and a marker list comprises the at least one marker.</p>
      <p id="p-00013-en" num="0013">The marker list may include the at least one marker indicating a predetermined point of the object or at least one marker representing a display view of the object.</p>
      <p id="p-00014-en" num="0014">When the object is a fetus, the marker list may include at least one marker representing a display view of the object for measuring biometrics.</p>
      <p id="p-00015-en" num="0015">When the object is a fetus, the marker list may also include at least one marker representing a display view of the object for diagnosing whether the fetus is normally growing.</p>
      <p id="p-00016-en" num="0016">The user interface unit may receive a selection of at least one marker from a user in order to generate the marker list.</p>
      <p id="p-00017-en" num="0017">The controller may extract at least one marker representing a display view for diagnosing the object or measuring a part of the object.</p>
      <p id="p-00018-en" num="0018">The marker list may include at least one of the at least one extracted marker and at least one marker selected by the user.</p>
      <p id="p-00019-en" num="0019">The controller may assign the at least one marker to a group based on a distance between markers and generate the marker list including a sub-marker list containing the at least one marker assigned to the group.</p>
      <p id="p-00020-en" num="0020">The controller may assign the at least one marker to a group according to each part of the object and generate the marker list including a sub-marker list containing the at least one marker assigned to the group.</p>
      <p id="p-00021-en" num="0021">The user interface unit may output an edit menu for generating an ultrasound moving image based on at least one ultrasound image corresponding to the at least one marker included in the marker list.</p>
      <p id="p-00022-en" num="0022">The controller may control the apparatus so that the ultrasound moving image generated based on the at least one ultrasound image corresponding to the at least one marker selected through the edit menu is played back.</p>
      <p id="p-00023-en" num="0023">In order to play back the ultrasound moving image, the user interface unit may receive at least one of a playback duration of an ultrasound image corresponding to a selected marker, information about image effects applied to the ultrasound image, and audio information related to the ultrasound image.</p>
      <p id="p-00024-en" num="0024">The controller may control playback of the ultrasound moving image based on the playback duration, the information about image effects, and the audio information.</p>
      <p id="p-00025-en" num="0025">Each item of the marker list may comprises at least one of information about a part of the object corresponding to a marker, information about a display view of the object corresponding to the marker, information about measurable biometrics corresponding to the marker, and the second ultrasound image.</p>
      <p id="p-00026-en" num="0026">According to one or more embodiments of the present invention, a method of displaying an ultrasound image includes: displaying a first screen including at least one marker; receiving a selection of a predetermined marker among the at least one marker; and displaying a second screen including a first ultrasound image that represents an object and has a view which is changed according to the predetermined marker.</p>
      <p id="p-00027-en" num="0027">The method may further include changing the view of the object based on position information of the predetermined marker and information about a viewpoint corresponding to the predetermined marker.</p>
      <p id="p-00028-en" num="0028">The ultrasound diagnosis apparatus and the method of displaying an ultrasound image according to the embodiments of the present invention may provide an ultrasound image screen that allows a user to easily and conveniently diagnose an object.</p>
      <p id="p-00029-en" num="0029">In detail, the ultrasound diagnosis apparatus and the method of displaying an ultrasound image facilitate convenient diagnosis of a portion of an object in which a position where a marker is set is located at a center.</p>
    </summary>
    <description-of-drawings>
      <heading id="h-00004-en" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
      <p id="p-00030-en" num="0030">These and/or other aspects will become apparent and more readily appreciated from the following description of the embodiments, taken in conjunction with the accompanying drawings in which:</p>
      <p id="p-00031-en" num="0031">
        <figref>FIG. 1</figref> illustrates an overall configuration of an ultrasound diagnosis device used in embodiments of the present invention;</p>
      <p id="p-00032-en" num="0032">
        <figref>FIG. 2</figref> illustrates an ultrasound diagnosis apparatus according to an exemplary embodiment of the present invention;</p>
      <p id="p-00033-en" num="0033">
        <figref>FIG. 3</figref> illustrates a screen generated in an ultrasound diagnosis apparatus according to an exemplary embodiment of the present invention;</p>
      <p id="p-00034-en" num="0034">
        <figref>FIG. 4</figref> is a diagram for explaining an operation of an ultrasound diagnosis apparatus according to an exemplary embodiment of the present invention;</p>
      <p id="p-00035-en" num="0035">
        <figref>FIG. 5</figref> is a diagram for explaining an operation of an ultrasound diagnosis apparatus according to another exemplary embodiment of the present invention;</p>
      <p id="p-00036-en" num="0036">
        <figref>FIG. 6</figref> is a diagram for explaining an operation of an ultrasound diagnosis apparatus according to another exemplary embodiment of the present invention;</p>
      <p id="p-00037-en" num="0037">
        <figref>FIG. 7A</figref> is a diagram for explaining an operation of an ultrasound diagnosis apparatus according to another exemplary embodiment of the present invention;</p>
      <p id="p-00038-en" num="0038">
        <figref>FIG. 7B</figref> is a diagram for explaining an operation of an ultrasound diagnosis apparatus according to another exemplary embodiment of the present invention;</p>
      <p id="p-00039-en" num="0039">
        <figref>FIG. 8</figref> illustrates a screen generated in an ultrasound diagnosis apparatus according to another exemplary embodiment of the present invention;</p>
      <p id="p-00040-en" num="0040">
        <figref>FIG. 9A</figref> illustrates a screen generated in an ultrasound diagnosis apparatus according to another exemplary embodiment of the present invention;</p>
      <p id="p-00041-en" num="0041">
        <figref>FIG. 9B</figref> illustrates a screen generated in an ultrasound diagnosis apparatus according to another exemplary embodiment of the present invention;</p>
      <p id="p-00042-en" num="0042">
        <figref>FIG. 10</figref> is a diagram for explaining an operation of an ultrasound diagnosis apparatus according to another exemplary embodiment of the present invention; and</p>
      <p id="p-00043-en" num="0043">
        <figref>FIG. 11</figref> is a flowchart of a method of displaying an ultrasound image according to an exemplary embodiment of the present invention.</p>
    </description-of-drawings>
    <detailed-desc>
      <heading id="h-00005-en" level="1">DETAILED DESCRIPTION</heading>
      <p id="p-00044-en" num="0044">Exemplary embodiments of the present invention will now be described more fully hereinafter with reference to the accompanying drawings so that they may be easily implemented by one of ordinary skill in the art. However, the present embodiments may have different forms and should not be construed as being limited to the descriptions set forth herein. In addition, parts not related to the present invention are omitted to clarify the description of exemplary embodiments of the present invention. In the accompanying drawings, like reference numerals refer to like elements throughout.</p>
      <p id="p-00045-en" num="0045">Throughout the specification, it will be understood that when an element is referred to as being “connected” or “coupled” to another element, it can be directly connected to or electrically coupled to the other element with one or more intervening elements interposed therebetween. Throughout the specification, it will also be understood that when a part “includes” or “comprises” an element, unless there is a particular description contrary thereto, the part can further include other elements, not excluding the other elements. In addition, terms such as “ . . . unit”, “ . . . module”, or the like refer to units that perform at least one function or operation, and the units may be implemented as hardware or software or as a combination of hardware and software. As used herein, the term “and/or” includes any and all combinations of one or more of the associated listed items. Expressions such as “at least one of,” when preceding a list of elements, modify the entire list of elements and do not modify the individual elements of the list.</p>
      <p id="p-00046-en" num="0046">Throughout the specification, an “ultrasonic image” refers to an image of an object obtained using an ultrasonic wave. Furthermore, in the present specification, an “object” may include a person or an animal, or a part of a person or an animal. For example, the object may include organs such as the liver, the heart, the womb, the brain, a breast, and the abdomen, or a blood vessel. Furthermore, the “object” may include a phantom. A phantom is a material having a volume that approximately equal to the density and effective atomic number of a living organism.</p>
      <p id="p-00047-en" num="0047">Furthermore, in the present specification, a “user” refers to a medical professional, such as a doctor, a nurse, a medical laboratory technologist, and a medical imaging expert, and a technician who repairs a medical apparatus, but the user is not limited thereto.</p>
      <p id="p-00048-en" num="0048">The embodiments of the present invention will now be described in detail with reference to the accompanying drawings.</p>
      <p id="p-00049-en" num="0049">
        <figref>FIG. 1</figref> illustrates an overall configuration of an ultrasound diagnosis device <b>100</b> used in embodiments of the present invention.</p>
      <p id="p-00050-en" num="0050">Referring to <figref>FIG. 1</figref>, the ultrasound diagnosis device <b>100</b> includes a probe <b>2</b>, an ultrasound transmission/reception unit <b>10</b>, an image processor <b>20</b>, a communication unit <b>30</b>, a memory <b>40</b>, an input device <b>50</b>, and a controller <b>60</b>, and the components may be connected to one another via buses <b>70</b>.</p>
      <p id="p-00051-en" num="0051">The ultrasound diagnosis device <b>100</b> may be embodied not only as a cart type device but also as a portable device. Examples of portable ultrasound diagnosis apparatuses may include a Picture Archiving and Communications System (PACS) viewer, a smartphone, a laptop computer, a personal digital assistant (PDA), and a tablet PC. However, the present invention is not limited thereto.</p>
      <p id="p-00052-en" num="0052">The probe <b>2</b> transmits ultrasound signals to an object <b>1</b>, based on a driving signal applied by the ultrasound transmission/reception unit <b>10</b>, and receives echo signals reflected from the object <b>1</b>. The probe <b>2</b> includes a plurality of transducers that oscillate based on electric signals transmitted thereto and generate acoustic energy, that is, ultrasound waves. Furthermore, the probe <b>2</b> may be connected to a main body of the ultrasound diagnosis device <b>100</b> by wires or wirelessly. According to embodiments of the present invention, the ultrasound diagnosis device <b>100</b> may include a plurality of probes <b>2</b>.</p>
      <p id="p-00053-en" num="0053">A transmission unit <b>11</b> supplies a driving signal to the probe <b>2</b> and includes a pulse generator <b>17</b>, a transmission delaying unit <b>18</b>, and a pulser <b>19</b>. The pulse generator <b>17</b> generates pulses for forming transmission ultrasound waves based on a predetermined pulse repetition frequency (PRF), and the transmission delaying unit <b>18</b> applies a delay time to the pulses in order to determine transmission directionality of the pulses. Pulses, to which a delay time is applied, correspond to a plurality of piezoelectric vibrators included in the probe <b>2</b>, respectively. The pulser <b>19</b> applies a driving signal (or a driving pulse) to the probe <b>2</b> at a timing corresponding to each pulse to which a delay time is applied.</p>
      <p id="p-00054-en" num="0054">A reception unit <b>12</b> generates ultrasound data by processing echo signals received from the probe <b>2</b>. The reception unit <b>12</b> may include an amplifier <b>13</b>, an analog-to-digital converter (ADC) <b>14</b>, a reception delaying unit <b>15</b>, and a summing unit <b>16</b>. The amplifier <b>13</b> amplifies echo signals in each channel, and the ADC <b>14</b> performs analog-to-digital conversion on the amplified echo signals. The reception delaying unit <b>15</b> applies delay times for determining reception directionality to the echo signals subjected to the analog-to-digital conversion, and the summing unit <b>16</b> generates ultrasound data by summing the echo signals processed by the reception delaying unit <b>15</b>. According to embodiments of the present invention, the reception unit <b>12</b> may not include the amplifier <b>13</b>. In other words, if the sensitivity of the probe <b>2</b> or the capability of the ADC <b>14</b> to process bits is enhanced, the amplifier <b>13</b> may be omitted.</p>
      <p id="p-00055-en" num="0055">The image processor <b>20</b> generates an ultrasound image by scan-converting ultrasound data generated by the ultrasound transmission/reception unit <b>10</b> and displays the ultrasound image. In addition, an ultrasound image may include not only a gray-scale ultrasound image obtained by scanning an object in an amplitude (A) mode, a brightness (B) mode, and a motion (M) mode, but also a Doppler image representing a moving object by using the Doppler effect. The Doppler image may include a blood flow Doppler image (also called a color Doppler image) showing a flow of blood, a tissue Doppler image showing movement of tissue, and a spectral Doppler image showing the speed at which an object moves as a waveform.</p>
      <p id="p-00056-en" num="0056">A B mode processor <b>22</b> extracts B mode components from ultrasound data and processes the B mode components. An image generator <b>24</b> may generate an ultrasound image in which signal intensities are represented as brightness based on the extracted B mode components.</p>
      <p id="p-00057-en" num="0057">Similarly, a Doppler processor <b>23</b> may extract Doppler components from ultrasound data, and the image generator <b>24</b> may generate a Doppler image indicating movement of an object as colors or waveforms based on the extracted Doppler components.</p>
      <p id="p-00058-en" num="0058">The image generator <b>24</b> according to an embodiment of the present invention may generate a three-dimensional (3D) ultrasound image via volume-rendering of volume data and an elasticity image which shows the degree of deformation of the object <b>1</b> due to pressure. Furthermore, the image generator <b>24</b> may display additional information in an ultrasound image by using text and graphics. In addition, the generated ultrasound image may be stored in the memory <b>40</b>.</p>
      <p id="p-00059-en" num="0059">A display unit <b>25</b> displays and outputs the generated ultrasound image. The display unit <b>25</b> may display and output not only an ultrasound image, but also various information processed by the ultrasound diagnosis device <b>100</b>, on a screen via a graphical user interface (GUI). In addition, the ultrasound diagnosis device <b>100</b> may include two or more display units <b>25</b> according to embodiments of the present invention.</p>
      <p id="p-00060-en" num="0060">The communication unit <b>30</b> is connected to a network <b>3</b> by wires or wirelessly and communicates with an external device or server. The communication unit <b>30</b> may exchange data with a hospital server or another medical device in a hospital that is connected via a Picture Archiving and Communications System (PACS). Furthermore, the communication unit <b>30</b> may perform data communication according to the Digital Imaging and Communications in Medicine (DICOM) standard.</p>
      <p id="p-00061-en" num="0061">The communication unit <b>30</b> may transmit or receive data related to diagnosis of the object <b>1</b>, e. g., an ultrasound image, ultrasound data, and Doppler data of the object <b>1</b>, via the network <b>3</b>. The communication unit <b>30</b> may also transmit or receive medical images obtained by other medical devices, such as a CT image, an MR image, and an X-ray image. Furthermore, the communication unit <b>30</b> may receive information related to a diagnosis history or a treatment schedule of a patient from a server and utilize the information to diagnose the patient, i.e., the object <b>1</b>. Furthermore, the communication unit <b>30</b> may perform data communication with a server or a medical device in a hospital as well as a portable terminal of a doctor or a patient.</p>
      <p id="p-00062-en" num="0062">The communication unit <b>30</b> is connected to the network <b>3</b> in a wired or wireless manner and may exchange data with a server <b>35</b>, a medical device <b>34</b>, or a portable terminal <b>36</b>. The communication unit <b>30</b> may include at least one component that enables communication with an external device, e.g., a local area communication module <b>31</b>, a wired communication module <b>32</b>, and a mobile communication module <b>33</b>.</p>
      <p id="p-00063-en" num="0063">The local area communication module <b>31</b> is a module for performing local area communication with a device that is within a predetermined distance. Examples of local area communication technology include a wireless Local Area Network (LAN), Wi-Fi, Bluetooth, ZigBee, Wi-Fi Direct (WFD), Ultra Wideband (UWB), Infrared Data Association (IrDA), Bluetooth Low Energy (BLE), and Near Field Communication (NFC), but are not limited thereto.</p>
      <p id="p-00064-en" num="0064">The wired communication module <b>32</b> is a module for performing communication by using an electric signal or an optical signal. Examples of wired communication technology include wired communication technologies using a pair cable, a coaxial cable, an optical fiber cable, and an Ethernet cable.</p>
      <p id="p-00065-en" num="0065">The mobile communication module <b>33</b> transmits or receives wireless signals to or from at least one of a base station, an external terminal, and a server on a mobile communication network. Here, the wireless signals may include voice call signals, video call signals, or various types of data for transmission and reception of text/multimedia messages.</p>
      <p id="p-00066-en" num="0066">The memory <b>40</b> stores various data processed by the ultrasound diagnosis device <b>100</b>. For example, the memory <b>40</b> may store not only medical data related to the diagnosis of the object <b>1</b>, such as ultrasound data and ultrasound images that are input or output, but also algorithms or programs that are executed in the ultrasound diagnosis device <b>100</b>.</p>
      <p id="p-00067-en" num="0067">The memory <b>40</b> may be embodied as any of various storage media such as a flash memory, a hard disk drive, and Electrically Erasable Programmable Read-Only Memory (EEPROM). Furthermore, the ultrasound diagnosis device <b>100</b> may utilize a web storage or a cloud server that functions as the memory <b>40</b> online.</p>
      <p id="p-00068-en" num="0068">The input device <b>50</b> is a means via which a user inputs data for controlling the ultrasound diagnosis device <b>100</b>. The input device <b>50</b> may include hardware components, such as a keypad, a mouse, a touch panel, a touch screen, a trackball, and a jog switch. However, the present invention is not limited thereto, and the input device <b>50</b> may further include various other input elements such as an electrocardiogram measuring module, a respiration measuring module, a voice recognition sensor, a gesture recognition sensor, a fingerprint recognition sensor, an iris recognition sensor, a depth sensor, a distance sensor, etc.</p>
      <p id="p-00069-en" num="0069">The controller <b>60</b> may control overall operations of the ultrasound diagnosis device <b>100</b>. In other words, the controller <b>60</b> may control operations among the probe <b>2</b>, the ultrasound transmission/reception unit <b>10</b>, the image processor <b>20</b>, the communication unit <b>30</b>, the memory <b>40</b>, and the input device <b>50</b>.</p>
      <p id="p-00070-en" num="0070">All or some of the probe <b>2</b>, the ultrasound transmission/reception unit <b>10</b>, the image processor <b>20</b>, the communication unit <b>30</b>, the memory <b>40</b>, the input device <b>50</b>, and the controller <b>60</b> may be implemented as software modules.</p>
      <p id="p-00071-en" num="0071">However, the present invention is not limited thereto, and some of the above components may be implemented as hardware modules. Furthermore, at least one of the ultrasound transmission/reception unit <b>10</b>, the image processor <b>20</b>, and the communication unit <b>30</b> may be included in the controller <b>60</b>, but the present invention is not limited thereto.</p>
      <p id="p-00072-en" num="0072">In order to diagnose disease by using an ultrasound image including an object, a marker may be set in the ultrasound image for determining a portion of the object to be examined or indicating a predetermined position of the object.</p>
      <p id="p-00073-en" num="0073">In detail, the marker may be set in a portion of the object that needs to be carefully observed for a user to diagnose a patient's disease or identify the presence of an abnormality in the patient. In order to more accurately diagnose a portion of an object in which the above-described marker is set, an ultrasound diagnosis apparatus configured to output a modified ultrasound image and a method of displaying an ultrasound image are provided.</p>
      <p id="p-00074-en" num="0074">
        <figref>FIG. 2</figref> illustrates an ultrasound diagnosis apparatus <b>200</b> according to an exemplary embodiment of the present invention.</p>
      <p id="p-00075-en" num="0075">Referring to <figref>FIG. 2</figref>, the ultrasound diagnosis apparatus <b>200</b> according to the present embodiment includes a controller <b>210</b>, a display unit <b>230</b>, and a user interface unit <b>220</b>. The ultrasound diagnosis apparatus <b>200</b> may further include a memory <b>240</b>.</p>
      <p id="p-00076-en" num="0076">Furthermore, the ultrasound diagnosis apparatus <b>200</b> may be incorporated into the ultrasound diagnosis device <b>100</b> shown in <figref>FIG. 1</figref>. In detail, the controller <b>210</b>, the display unit <b>230</b>, the user interface unit <b>220</b>, and the memory <b>240</b> correspond to the image generator <b>24</b>, the display unit <b>25</b>, the input device <b>50</b>, and the memory <b>40</b>, respectively.</p>
      <p id="p-00077-en" num="0077">Furthermore, the ultrasound diagnosis apparatus <b>200</b> may correspond to the medical device <b>34</b> or the portable terminal <b>36</b>, respectively, and receive ultrasound data acquired by the ultrasound diagnosis device <b>100</b> via the network <b>3</b> for use.</p>
      <p id="p-00078-en" num="0078">The display unit <b>230</b> displays a first screen including at least one marker. In detail, the display unit <b>230</b> may display a first screen that includes a marker list containing the at least one marker. Herein, the marker list may include the at least one marker indicating a predetermined point of the object or at least one marker representing a display view of the object. Furthermore, the first screen may further include a first ultrasound image representing an object. Here, the first ultrasound image is generated using ultrasound data acquired by scanning the object via a probe, and may include at least one of a two-dimensional (2D) ultrasound image and a 3D ultrasound image. Furthermore, a marker may be set at a predetermined point of an object or in a predetermined portion or region of the object. For example, the marker may be set at a diagnostically meaningful point in an object, or in a predetermined organ corresponding to a portion of the object to be examined. For example, if the object is a fetus, a marker may be set at a point on the back of the fetus's neck in order to measure a Nuchal Translucency (NT) thickness. As another example, a marker may be set in a fetus's head in order to measure sizes of the fetal head and cerebral ventricles within the fetal brain.</p>
      <p id="p-00079-en" num="0079">The user interface unit <b>220</b> receives selection of a predetermined marker among the at least one marker. In detail, the user interface unit <b>220</b> may receive selection of a predetermined marker in a marker list included in the screen displayed on the display unit <b>230</b>. The user interface unit <b>220</b> may also generate a user interface screen via which a predetermined input may be received from a user. The user interface screen may also be generated by the controller <b>210</b>. The display unit <b>230</b> may then display the user interface screen generated by the user interface unit <b>220</b> or the controller <b>210</b>. For example, the first screen may be a user interface screen including a marker list for receiving selection of a predetermined marker from the user, and may be generated by the user interface unit <b>220</b> or the controller <b>210</b>.</p>
      <p id="p-00080-en" num="0080">The controller <b>210</b> controls the display unit <b>230</b> to display a second screen including a second ultrasound image corresponding to a predetermined marker selected via the user interface unit <b>220</b>. Here, the second ultrasound image represents an object and has a view which is changed according to the predetermined marker.</p>
      <p id="p-00081-en" num="0081">In detail, the controller <b>210</b> may generate an ultrasound image by scan-converting ultrasound data acquired by scanning an object. For example, a 2D ultrasound image generated by the controller <b>210</b> may include not only a gray-scale ultrasound image obtained by scanning an object in an A mode, a B mode, and a M mode, but also a Doppler image representing a moving object by using a Doppler effect.</p>
      <p id="p-00082-en" num="0082">The controller <b>210</b> may extract B mode components from ultrasound data and generate a B mode ultrasound image in which signal intensities are represented as brightness based on the extracted B mode components. Furthermore, the controller <b>210</b> may extract Doppler components from ultrasound data and generate a Doppler image indicating movement of an object as colors or waveforms based on the extracted Doppler components.</p>
      <p id="p-00083-en" num="0083">Furthermore, the controller <b>210</b> may generate volume data by using ultrasound data and produce a 3D ultrasound image by performing volume-rendering on the volume data.</p>
      <p id="p-00084-en" num="0084">In addition, the controller <b>210</b> may not generate an ultrasound image therein but receive an ultrasound image corresponding to an object from the outside. For example, the ultrasound diagnosis apparatus <b>200</b> may receive an ultrasound image from another ultrasound diagnosis apparatus (not shown).</p>
      <p id="p-00085-en" num="0085">The display unit <b>230</b> may display a first screen including a marker list and a first ultrasound image received or generated by the controller <b>210</b>.</p>
      <p id="p-00086-en" num="0086">In detail, the user interface unit <b>220</b> may generate and output a user interface screen for receiving a predetermined command or data via a user input. The user interface unit <b>220</b> may receive the predetermined command or data from the user via the user interface screen. The user may recognize predetermined information when viewing the user interface screen displayed through the display unit <b>230</b>, and input a predetermined command or data via the user interface unit <b>220</b>.</p>
      <p id="p-00087-en" num="0087">For example, the user interface unit <b>220</b> may include a mouse, a keyboard, or another input device including hard keys for receiving a predetermined command or data via a user input. For example, the user may enter predetermined data or command by manipulating at least one of the mouse, the keyboard, and the other input device in the user interface unit <b>220</b>.</p>
      <p id="p-00088-en" num="0088">In another example, the user interface unit <b>220</b> may be formed as a touch pad. In detail, the user interface unit <b>220</b> may include a touch pad (not shown) combined with a display panel (not shown) in the display unit <b>230</b>. In this case, the user interface screen may be output to the display panel. Then, when a predetermined command is input via the user interface screen, the touch pad detects information corresponding to the predetermined command and transmits the detected information to the controller <b>210</b>. Then, the controller <b>210</b> interprets the detected information and recognizes and executes the predetermined command input by the user.</p>
      <p id="p-00089-en" num="0089">In detail, if the user interface unit <b>220</b> is formed as a touch pad, when the user touches a predetermined point on the user interface screen, the user interface unit <b>220</b> detects a position of the touched point and transmits the detected position to the controller <b>210</b>. The controller <b>210</b> may then recognize a user request or command corresponding to a menu displayed at the detected position and execute the recognized user request or command.</p>
      <p id="p-00090-en" num="0090">An example where the controller <b>210</b> generates a user interface screen and outputs the user interface screen to the display unit <b>230</b>, and the user interface unit <b>220</b> receives predetermined data or command from a user and transmits the predetermined data and command to the controller <b>210</b> will now be described in detail.</p>
      <p id="p-00091-en" num="0091">In detail, the controller <b>210</b> generates a marker list and then a first screen including the marker list and outputs the first screen. Then, the display unit <b>230</b> displays the first screen. If the user interface unit <b>220</b> is formed as the above-described touch pad, the user selects a predetermined marker by touching a point which is on the displayed first screen and indicated by the predetermined marker in the marker list. Then, the controller <b>210</b> may recognize the selection of the predetermined marker and control the display unit <b>230</b> to display a second screen that includes an ultrasound image that represents an object and has a view that is changed according to the predetermined marker. A screen displayed on the display unit <b>230</b> will now be described in more detail with reference to <figref>FIG. 3</figref>.</p>
      <p id="p-00092-en" num="0092">
        <figref>FIG. 3</figref> illustrates a screen generated in an ultrasound diagnosis apparatus according to an exemplary embodiment of the present invention, and more particularly, a first screen <b>300</b> displayed on the display unit <b>230</b> according to control of the controller <b>210</b>.</p>
      <p id="p-00093-en" num="0093">Referring to <figref>FIG. 3</figref>, the first screen <b>300</b> includes a first ultrasound image <b>310</b> and a marker list <b>330</b>. The first screen <b>300</b> is an ultrasound image acquired by performing an ultrasound scan on an object <b>301</b>. In <figref>FIG. 3</figref>, the object <b>301</b> is a fetus, and the first ultrasound image <b>310</b> is a 3D ultrasound image.</p>
      <p id="p-00094-en" num="0094">The marker list <b>330</b> includes at least one marker item.</p>
      <p id="p-00095-en" num="0095">For example, if a marker indicates a predetermined portion or region in an ultrasound image or object <b>301</b>, as shown in <figref>FIG. 3</figref>, the marker may not be displayed as a marker (e.g., a first marker <b>321</b>) indicating a predetermined point within the first ultrasound image <b>310</b>. In this case, the marker may not be displayed in the first ultrasound image <b>310</b>. Instead, an image (not shown) showing the predetermined portion or region may be included in each marker item of the marker list <b>330</b> so that the user visually recognizes the marker indicating the predetermined portion or region.</p>
      <p id="p-00096-en" num="0096">Furthermore, if a marker is set at a predetermined point within an ultrasound image or object, the marker (e.g., the first marker <b>321</b>) may be displayed so as to indicate the predetermined point in the first ultrasound image <b>310</b>, as shown in <figref>FIG. 3</figref>.</p>
      <p id="p-00097-en" num="0097">The first marker <b>321</b> may have an arrow shape as shown in <figref>FIG. 3</figref> or other various shapes such as a circular shape, a polygonal shape, a hand shape, a cross shape, etc. The first marker <b>321</b> may also have various colors that can be represented by using 24-bit Red, Green, Blue (RGB) values.</p>
      <p id="p-00098-en" num="0098">In detail, the marker list <b>330</b> may include at least one marker item corresponding to a marker representing a display view of the object <b>301</b>. For example, each marker item included in the marker list <b>330</b> may include an ultrasound image having a display view corresponding to a marker set at a predetermined point within the first ultrasound image <b>310</b> or the object <b>301</b>.</p>
      <p id="p-00099-en" num="0099">At least one of first through fourth markers <b>321</b> through <b>324</b> may also be displayed on the object <b>301</b> in the first ultrasound image <b>310</b>. Alternatively, each of the first through fourth markers <b>321</b> through <b>324</b> may be displayed at a predetermined point in the first ultrasound image <b>310</b> and not on the object <b>301</b>. The marker list <b>330</b> is a list of the at least one of the first through fourth markers <b>321</b> through <b>324</b> located on the first ultrasound image <b>310</b>, and a marker item of the market list <b>330</b> may include information about each of the first through fourth markers <b>321</b> through <b>324</b>. For example, first and second marker items <b>331</b> and <b>332</b> may include information about the first marker <b>321</b> and about the second marker <b>322</b>, respectively.</p>
      <p id="p-00100-en" num="0100">Each marker item (e.g., first marker item <b>331</b>) of the marker list <b>330</b> may include at least one of information about a point or part of the object <b>301</b> corresponding to a marker, information about a display view of the object <b>301</b> corresponding to the marker, information about measurable biometrics corresponding to the marker, and a second ultrasound image having the marker at the center thereof.</p>
      <p id="p-00101-en" num="0101">Here, the information about a point or part of the object <b>301</b> refers to information about a body point or a body part of the object <b>301</b> where a marker is located and may include a name of the body point or body part such as the head, face, torso, arms, legs, the abdomen, or chest, or a name of an organ in which the marker is located, such as the cerebellum, cerebrum, heart, or stomach. In detail, if the object <b>301</b> is a fetus, the information about a point or part of the object <b>301</b> may include names of body parts such as the head, face, eyes, lips, spine, gastrointestinal (GI) tract, adrenal gland, kidney, bladder, external genitalia, anus, umbilical cord insertion, arms, hands, legs, feet, diaphragm, lungs, heart, etc.</p>
      <p id="p-00102-en" num="0102">The information about a display view refers to information about a frontal view of the object <b>301</b> where a marker is located and may include information about displayed planes of the object <b>301</b> such as a sagittal plane, a coronal plane, a horizontal or axial plane, a mid-sagittal plane, etc. In detail, a ‘display view’ refers to a frontal view of the object appearing on a screen and in which a marker is positioned at the center thereof.</p>
      <p id="p-00103-en" num="0103">The information about measurable biometrics refers to information about biometrics that can be accurately measured from a view representing a front part of an object with a marker at the center thereof. Biometrics refers to biological information of physical characteristics or traits of a human and includes all values used to determine normality in a human body. For example, fetal biometrics may include Gestational Sac (GS), Crown Rump Length (CRL), Bi-parietal Diameter (BPD), Head Circumference (HC), Abdominal Circumference (AC), Femur Length (FL), Anterior Posterior Thoracic Diameter (APTD), Thorax Transverse Diameter (TTD), Occipital Frontal Diameter (OFD), Outer Ocular Distance (OOD), Humerus (HUM), NT, and Nasal Bone.</p>
      <p id="p-00104-en" num="0104">The second ultrasound image contained in each marker item (e. g., first marker item <b>331</b>) of the marker list <b>330</b> means an ultrasound image representing an object of which a view is changed to correspond to a marker. The second ultrasound image may be an ultrasound image representing the front of the object <b>301</b> where the marker is located.</p>
      <p id="p-00105-en" num="0105">The second ultrasound image may be included in each marker item of the marker list <b>330</b> as a thumbnail image.</p>
      <p id="p-00106-en" num="0106">The user may request display of a second ultrasound image by selecting a predetermined marker item (e. g, the first marker item <b>331</b>). Alternatively, the user may request display of the second ultrasound image by selecting a predetermined marker (e.g., the first marker <b>321</b>) displayed on the first ultrasound image <b>310</b>. According to the above user selection, the controller <b>210</b> may control the display unit <b>230</b> to display the second ultrasound image.</p>
      <p id="p-00107-en" num="0107">
        <figref>FIG. 4</figref> is a diagram for explaining an operation of an ultrasound diagnosis apparatus <b>200</b> according to an exemplary embodiment of the present invention.</p>
      <p id="p-00108-en" num="0108">As described above, a marker may be automatically set by the controller <b>210</b> or input directly by a user.</p>
      <p id="p-00109-en" num="0109">In detail, the controller <b>210</b> may automatically set at least one marker representing a display view for diagnosing an object or measuring a portion of the object. For example, in order to diagnose whether the object has a disease or abnormality, the controller <b>210</b> may automatically extract a portion of the object having a risk of a disease or disorder and automatically set a marker in the portion of the object. For example, if the result of analysis of an ultrasound image shows that a tumor is present in the object, a marker may be set at a central portion of the tumor so that the details of the tumor are displayed.</p>
      <p id="p-00110-en" num="0110">Furthermore, the controller <b>210</b> may automatically set at least one marker representing a display view for measuring a portion of the object and biometrics.</p>
      <p id="p-00111-en" num="0111">Referring to <figref>FIG. 4</figref>, when an object <b>401</b> is a fetus, the controller <b>210</b> may set as a marker <b>410</b> a central point of a front of a head that is a portion of the object <b>401</b> necessary to determine whether a brain of the object <b>401</b> is growing at a normal rate.</p>
      <p id="p-00112-en" num="0112">Furthermore, if the marker <b>410</b> is extracted and included in a marker list, when a user selects the marker <b>410</b> from the marker list, a second screen including a second ultrasound image may be displayed. In this case, the second ultrasound image includes the front of the head in which the marker <b>410</b> is located at a center of the second screen. Furthermore, the controller <b>210</b> may set a point for measuring an NT as a marker <b>412</b>. If the marker <b>412</b> is set and included in a marker list, when a user selects the marker <b>412</b> from the marker list, a second screen including a second ultrasound image may be displayed. In this case, the second ultrasound image shows a cross-section of the fetal NT with the marker <b>412</b> located at a center of the second screen.</p>
      <p id="p-00113-en" num="0113">Furthermore, the user interface unit <b>220</b> may receive at least one marker from the user. Referring to <figref>FIG. 4</figref>, the user may set markers <b>410</b> and <b>412</b> at predetermined points in a displayed first ultrasound image <b>400</b>.</p>
      <p id="p-00114-en" num="0114">
        <figref>FIG. 5</figref> is a diagram for explaining an operation of an ultrasound diagnosis apparatus <b>200</b> according to another exemplary embodiment of the present invention.</p>
      <p id="p-00115-en" num="0115">The controller <b>210</b> may change a view of an object based on position information of a marker and information about a viewpoint corresponding to the marker. The position information and the information about the viewpoint may be stored together when the marker is set. It is hereinafter assumed that an ultrasound image on which the marker is set is a 3D ultrasound image.</p>
      <p id="p-00116-en" num="0116">In detail, the memory <b>240</b> may store position information of a marker and information about a viewpoint corresponding to the marker. If there are a plurality of markers, the memory <b>240</b> may store identification (ID) information that is used to distinguish each of the plurality of markers as well as the position information of the marker and the information about the viewpoint that are mapped to the ID information. The ID information of the marker may be created as a combination of letters and numbers. Furthermore, the ID information may be designated for each marker by a user. For example, if an ID number is used as ID information of a marker, the memory <b>240</b> may assign ‘marker<b>1</b>’ as an ID number of the first marker, map position information of the first marker and information about the viewpoint to the ID number marker<b>1</b>, and store the ID number ‘marker <b>1</b>’ and the position information of the first marker and the information about the viewpoint. Position information of a marker and information about a viewpoint corresponding to the marker will now be described in more detail with reference to <figref>FIG. 5</figref>.</p>
      <p id="p-00117-en" num="0117">Referring to <figref>FIG. 5</figref>, a marker <b>510</b> may be set on an object <b>501</b> in a 3D ultrasound image <b>500</b>. Position information of the marker <b>510</b> may be coordinate information of the marker <b>510</b> in a 3D coordinate system with a predetermined reference point (0,0,0) as an origin. The position information of the marker <b>510</b> may include at least one of Cartesian coordinates and Euler coordinates.</p>
      <p id="p-00118-en" num="0118">‘Information about a viewpoint corresponding to a marker’ may mean position information of a viewpoint <b>520</b> corresponding to a display view <b>530</b> with a marker <b>510</b> located at a center thereof. More specifically, it is assumed that an image having the display view <b>530</b> with the marker <b>510</b> at the center thereof is captured by using a virtual camera. In this case, the display view <b>530</b> with the marker <b>510</b> at the center thereof may be a view captured by a camera having the viewpoint <b>520</b>. Here, the marker <b>510</b> may be located at the center of the display view <b>530</b>, and a viewpoint corresponding to the marker <b>510</b> may mean the viewpoint <b>520</b> of the display view <b>530</b> having the marker <b>510</b> at the center thereof.</p>
      <p id="p-00119-en" num="0119">The information about the viewpoint <b>520</b> corresponding to the marker <b>510</b> may include at least one of Cartesian coordinates and Euler coordinates.</p>
      <p id="p-00120-en" num="0120">
        <figref>FIG. 6</figref> is a diagram for explaining an operation of the ultrasound diagnosis apparatus <b>200</b> according to another exemplary embodiment of the present invention.</p>
      <p id="p-00121-en" num="0121">Referring to <figref>FIG. 6</figref>, a first ultrasound image representing a display view <b>610</b> having a viewpoint P<b>1</b> (x11, y11, z11) may be included in and displayed on a first screen. In this case, since the viewpoint P<b>1</b> (x11, y11, z11) corresponds to a viewpoint of a virtual camera when an object, i.e., a fetus <b>601</b>, is captured from a rear side of the fetus <b>601</b>, the first ultrasound image may be an ultrasound image showing the back of the fetus <b>601</b>. For example, the first ultrasound image may have the display view <b>610</b> with a marker <b>611</b> set at point (x12, y12, z12) on the back of the fetus <b>601</b> and located at a center thereof.</p>
      <p id="p-00122-en" num="0122">When a user selects a marker <b>621</b> set at a predetermined point (x22, y22, z22) on the right side of a head of the fetus <b>601</b> from a menu marker list, the controller <b>210</b> may control the display unit <b>230</b> to display a second ultrasound image that represents the fetus <b>601</b> and has a view which is changed to correspond to the marker <b>621</b>. In other words, when the marker <b>621</b> is selected, the controller <b>210</b> may control the display unit <b>230</b> to display a second ultrasound image having a display view <b>620</b> corresponding to the marker <b>621</b>.</p>
      <p id="p-00123-en" num="0123">As described above, the controller <b>210</b> may change a view of the object based on position information of the selected marker <b>621</b> and information about a viewpoint corresponding to the selected marker <b>621</b>. In detail, the memory <b>240</b> stores position coordinates (x12, y12, z11) of the marker that are mapped to the marker and position coordinates (x11, y11, z11) of the viewpoint P<b>1</b> corresponding to the marker. The memory <b>240</b> may also store position coordinates (x22, y22, z22) of the marker <b>621</b> mapped to the marker <b>621</b> and position coordinates (x21, y21, z21) of the viewpoint P<b>2</b> corresponding to the marker <b>621</b>. When the marker <b>621</b> is selected, the controller <b>210</b> calculates a variation between a position of the viewpoint P<b>1</b> of the first ultrasound image currently being displayed and a changed position of the viewpoint P<b>2</b> of the first ultrasound image by using the position coordinates (x11, y11, z11) and (x21, y21, z21) of the viewpoints P<b>1</b> and P<b>2</b>. The controller <b>210</b> then moves a view representing the fetus <b>601</b> according to the calculated variation. The controller <b>210</b> may also perform rendering on ultrasound data obtained by scanning the fetus <b>601</b> and generate a 3D ultrasound image. Alternatively, other various image processing techniques may be used to change a view according to a change in a viewpoint.</p>
      <p id="p-00124-en" num="0124">
        <figref>FIGS. 7A and 7B</figref> are other diagrams for explaining an operation of the ultrasound diagnosis apparatus <b>200</b> of <figref>FIG. 2</figref> according to an exemplary embodiment of the present invention.</p>
      <p id="p-00125-en" num="0125">
        <figref>FIG. 7A</figref> illustrates a first screen <b>710</b> including a first ultrasound image <b>720</b> and a marker list <b>730</b> according to an exemplary embodiment of the present invention. <figref>FIG. 7B</figref> illustrates an example of a second screen <b>750</b> including a second ultrasound image <b>760</b> and a marker list <b>730</b> according to an exemplary embodiment of the present invention.</p>
      <p id="p-00126-en" num="0126">Referring to <figref>FIG. 7A</figref>, if an object is a fetus <b>701</b>, the marker list <b>730</b> may include items for at least one of first through third markers Marker <b>1</b><b>731</b>, Marker <b>2</b><b>732</b>, and Marker <b>3</b><b>733</b> for diagnosing abnormality in development of the fetus <b>701</b>. For example, the first marker Marker <b>1</b><b>731</b> and the second marker Marker <b>2</b><b>732</b> may be set on the right side and front of the fetus <b>701</b>, respectively. The third marker Marker <b>3</b><b>733</b> may be set on a side of the abdomen of the fetus <b>701</b> as shown in <figref>FIG. 7</figref> in order to observe a part of the rear of the fetus <b>701</b> including an umbilical cord.</p>
      <p id="p-00127-en" num="0127">As shown in <figref>FIG. 7</figref>, the first ultrasound image <b>720</b> is a 3D ultrasound image representing a side of the fetus <b>701</b> and corresponding to the third marker Marker <b>3</b><b>733</b>.</p>
      <p id="p-00128-en" num="0128">Referring to <figref>FIG. 7B</figref>, when a user selects an item <b>740</b> corresponding to a first marker Marker <b>1</b><b>731</b> from the marker list <b>730</b> by using a cursor <b>750</b> via the user interface unit <b>220</b>, the controller <b>210</b> controls the display unit <b>230</b> to display a second ultrasound image <b>760</b> having a view corresponding to the first marker Marker <b>1</b><b>731</b>. Thus, the second ultrasound image <b>760</b> having a view representing the right side of a fetus <b>701</b> is displayed on a second screen <b>750</b>. In other words, the second ultrasound image <b>760</b> representing the fetus <b>701</b>, of which a view is changed to correspond to the first marker <b>731</b>, may be displayed according to the user's selection of the first marker <b>731</b>.</p>
      <p id="p-00129-en" num="0129">Furthermore, the item <b>740</b> corresponding to the selected first marker Marker <b>1</b><b>731</b> may be highlighted for display. As shown in <figref>FIG. 7B</figref>, the item <b>740</b> corresponding to the first marker Marker <b>1</b><b>731</b> may be displayed such that edges thereof are thicker than those of the remaining items of second and third markers Marker <b>2</b> and Marker <b>3</b>. Alternatively, the item <b>740</b> of the selected first marker <b>731</b> may be displayed using a different color or shape than the remaining items. Furthermore, when the second ultrasound image <b>760</b> is output, an indicator <b>761</b> which indicates a change in an ultrasound image may be additionally displayed. This configuration may allow a user to easily interpret a selected marker and an image having a view changed according to the selected marker.</p>
      <p id="p-00130-en" num="0130">
        <figref>FIG. 8</figref> illustrates a screen generated in the ultrasound diagnosis apparatus <b>200</b> according to another exemplary embodiment of the present invention. In detail, <figref>FIG. 8</figref> illustrates a first screen <b>800</b> that is displayed by the display unit <b>230</b> according to a control of the controller <b>210</b>, according to another exemplary embodiment of the present invention. The first screen <b>800</b> includes a first ultrasound image <b>810</b> and a marker list <b>820</b>. The first screen <b>800</b> is an ultrasound image acquired by performing an ultrasound scan on a fetus <b>801</b>. In <figref>FIG. 8</figref>, an object is a fetus <b>801</b>, and the first ultrasound image <b>810</b> is a 3D ultrasound image.</p>
      <p id="p-00131-en" num="0131">Referring to <figref>FIG. 8</figref>, if an object is a fetus <b>801</b>, the marker list <b>820</b> may include at least one marker representing a display view of the fetus <b>801</b> for measuring biometrics. Each marker item <b>821</b>, <b>822</b>, or <b>823</b> in the marker list <b>820</b> may include ID information (e.g., ‘Marker<b>1</b>’) of a corresponding marker displayed on the first screen <b>800</b>. Furthermore, unlike in the first screen <b>300</b> shown in <figref>FIG. 3</figref> where the first marker <b>321</b> corresponding to the first marker item <b>331</b> in the marker list <b>330</b> is displayed on the first ultrasound image <b>310</b>, a marker is not displayed on the first ultrasound image <b>810</b> in the first screen <b>800</b>. However, according to the present embodiment, the marker is not displayed in the first ultrasound image <b>800</b>.</p>
      <p id="p-00132-en" num="0132">Referring to <figref>FIG. 8</figref>, each of the marker items <b>821</b>, <b>822</b>, and <b>823</b> of the marker list <b>820</b> may include at least one of ID information of a corresponding marker &amp; information about a biometric parameter to be measured <b>824</b> (hereinafter, collectively referred to as ‘information’ and an image <b>823</b> having a display view needed for measurement of biometrics).</p>
      <p id="p-00133-en" num="0133">In detail, the information <b>824</b> may include biometric values that can be used to determine health conditions and normal development of the fetus <b>801</b>. For example, the information about biometric parameters to be measured may include GS, CRL, BPD, HC, AC, FL, APTD, TTD, OFD, OOD, HUM, NT, and nasal bone. Such information may include information about a view for biometric measurement. For example, the information about a view for biometric measurement may include information about views for measuring fetal GS, CRL, BPD, HC, AC, FL, APTD, TTD, OFD, OOD, HUM, NT, and nasal bone. In another example, when CRL is measured on a mid-sagittal plane, the information about biometric parameters to be measured may include information regarding, for example, a ‘CRL-midsagittal plane’.</p>
      <p id="p-00134-en" num="0134">Referring to <figref>FIG. 8</figref>, a first marker item <b>821</b> is an item corresponding to Marker <b>1</b> and may include a CRL as a biometric parameter to be measured and an ultrasound image <b>823</b> having a mid-sagittal plane as a display view for measuring the CRL.</p>
      <p id="p-00135-en" num="0135">In detail, when a user selects the first marker item <b>821</b> with a cursor <b>840</b>, an ultrasound image <b>823</b> in a mid-sagittal plane for measuring a CRL may be displayed on a region where the first ultrasound image <b>810</b> has been displayed.</p>
      <p id="p-00136-en" num="0136">
        <figref>FIGS. 9A and 9B</figref> illustrate screens generated in the ultrasound diagnosis apparatus <b>200</b>, according to another exemplary embodiment of the present invention;</p>
      <p id="p-00137-en" num="0137">The controller <b>210</b> may assigns the at least one marker to a group based on a distance between markers and generate a marker list including a sub-marker list containing the at least one marker assigned to the group.</p>
      <p id="p-00138-en" num="0138">
        <figref>FIG. 9A</figref> illustrates a first screen <b>900</b> displayed by the display unit <b>230</b> according to a control of the controller <b>210</b>, according to another exemplary embodiment of the present invention. The first screen <b>900</b> includes a first ultrasound image <b>910</b> and a marker list <b>950</b>.</p>
      <p id="p-00139-en" num="0139">Referring to <figref>FIG. 9A</figref>, the controller <b>210</b> measures distances between markers <b>911</b> through <b>915</b> and groups markers that are within a predetermined distance from one another. In detail, the controller <b>210</b> may calculate Euclidean distances between each of the markers <b>911</b> through <b>915</b> and group markers for which the Euclidean distance falls within a predetermined range.</p>
      <p id="p-00140-en" num="0140">Furthermore, the controller <b>210</b> may group markers according to each body part of an object. In detail, for each body part such as the head, face, lips, spine, GI tract, adrenal gland, kidney, bladder, external genitalia, anus, arms, hands, legs, diaphragm, or lungs, markers located at the body part may be grouped together. For example, markers located within the face of the object <b>901</b> may be clustered into a single marker group.</p>
      <p id="p-00141-en" num="0141">The first screen <b>900</b> may further include a group setting menu <b>930</b>. When a user selects the group setting menu <b>930</b> via the user interface unit <b>220</b>, grouping may be performed automatically. Furthermore, when markers within a predetermined distance from one another are grouped, the user may set the predetermined distance through the user interface unit <b>220</b>. In addition, when markers are grouped according to each body part, the user may set a body part for which the markers are to be grouped through the user interface unit <b>220</b>.</p>
      <p id="p-00142-en" num="0142">
        <figref>FIG. 9B</figref> illustrates a screen <b>950</b> that is output when the grouping described with reference to <figref>FIG. 9A</figref> is completed, according to an exemplary embodiment of the present invention.</p>
      <p id="p-00143-en" num="0143">For example, if the controller <b>210</b> measures distances between each of the markers <b>911</b> through <b>914</b> and groups the markers located within a predetermined distance from one another, the markers <b>911</b> through <b>914</b> located within a predetermined region <b>970</b> corresponding to the predetermined distance may be grouped together, while a marker <b>915</b> that is not within the predetermined region <b>970</b> is not grouped with markers <b>911</b> through <b>914</b>.</p>
      <p id="p-00144-en" num="0144">When the grouping is completed, a marker list <b>965</b> may include a sub-marker list <b>960</b> of grouped markers. For example, if the user clicks on the sub-marker list <b>960</b>, a list (not shown) of the markers <b>911</b> through <b>914</b> that belong to a predetermined group and lie within the predetermined region <b>970</b> may be subsequently displayed.</p>
      <p id="p-00145-en" num="0145">
        <figref>FIG. 10</figref> is a diagram for explaining an operation of the ultrasound diagnosis apparatus <b>200</b> according to another exemplary embodiment of the present invention. In detail, <figref>FIG. 10</figref> illustrates a first screen <b>1000</b> displayed by the display unit <b>230</b> according to a control of the controller <b>210</b>, according to another exemplary embodiment of the present invention. The first screen <b>1000</b> includes a first ultrasound image <b>1010</b> and a marker list <b>1020</b>.</p>
      <p id="p-00146-en" num="0146">The user interface unit <b>220</b> may output an edit menu <b>1030</b> for generating an ultrasound moving image by using ultrasound images corresponding to a plurality of markers in the marker list <b>1020</b>. Thus, the first screen <b>1000</b> may include the edit menu <b>1030</b>.</p>
      <p id="p-00147-en" num="0147">In detail, the first screen <b>1000</b> may include the edit menu <b>1030</b> for generating and/or editing an ultrasound moving image by using ultrasound images corresponding to the plurality of markers. As shown in <figref>FIG. 10</figref>, the edit menu <b>1030</b> may be a cine bar for generating a moving image. The cine bar is used as a moving image editing tool. Thus, if an ultrasound moving image is located above the cine bar and a playback interval thereof is set on the cine bar, the ultrasound moving image may be reproduced during the playback interval.</p>
      <p id="p-00148-en" num="0148">Referring to <figref>FIG. 10</figref>, a user selects a first marker item <b>1021</b> and a second marker item <b>1022</b> and places them at a first time interval <b>1031</b> and a third time interval <b>1033</b>, respectively. Furthermore, a second time interval <b>1032</b> is interposed between the first and third time intervals <b>1031</b> and <b>1033</b> so that there is a time gap for transition from an ultrasound image corresponding to the first marker item <b>1021</b> to an ultrasound image corresponding to the second marker item <b>1022</b>. The user may also select a predetermined marker item (e.g., first marker item <b>1021</b>) and place it at a predetermined time interval (e.g., first time interval <b>1031</b>) by using a click and drag method.</p>
      <p id="p-00149-en" num="0149">The controller <b>210</b> may then control playback of an ultrasound moving image produced based on a plurality of second ultrasound images corresponding to a plurality of selected markers, through the edit menu. In the embodiment described above, an ultrasound image corresponding to the first marker item <b>1021</b> may be played back during the first time interval <b>1031</b>, and after a lapse of the second time interval <b>1032</b>, an ultrasound image corresponding to the second marker item <b>1022</b> may be played back.</p>
      <p id="p-00150-en" num="0150">Furthermore, in order to play back an ultrasound moving image, the user interface unit <b>220</b> may generate a menu <b>1051</b> for inputting at least one of playback duration of an ultrasound image corresponding to a selected marker item, information about image effects be applied to the ultrasound image, and audio information related to the ultrasound image. In addition, through the menu <b>1051</b>, the user interface unit <b>220</b> may receive information about at least one of a playback duration of an ultrasound image corresponding to a selected marker item, information about image effects provided to the ultrasound image, and audio information related to the ultrasound image.</p>
      <p id="p-00151-en" num="0151">The controller <b>210</b> may then control the ultrasound diagnosis apparatus <b>200</b> so that an ultrasound moving image consisting of a plurality of ultrasound images corresponding to a plurality of selected markers is played back based on at least one of the playback duration, the information about image effects, and the audio information that are input via the menu <b>1051</b>. In detail, the menu <b>1051</b> may include at least one menu item for setting or controlling at least one of control of a playback duration, editing of a playback order, editing of text added during playback of a moving image, image brightness, image contrast, transparency, rotation flip, and fade effects including fade-in and fade-out. Thus, the menu <b>1051</b> may allow a user to freely edit an ultrasound moving image.</p>
      <p id="p-00152-en" num="0152">In another example, if a user requests insertion of a fetal heartbeat sound <b>1040</b> into an ultrasound moving image via the user interface unit <b>220</b>, the controller <b>210</b> may control the ultrasound diagnosis apparatus <b>200</b> so that the fetal heartbeat sound <b>1040</b> is played back together with the ultrasound moving image during time intervals set for reproducing the ultrasound moving image. For example, if the user requests playback of the fetal heartbeat sound <b>1040</b> together with the ultrasound moving image during first through fifth time intervals <b>1031</b> through <b>1035</b>, the fetal heartbeat sound <b>1040</b> may be reproduced during the first through fifth time intervals <b>1031</b> through <b>1035</b>. When the fetal heartbeat sound <b>1040</b> is added to the ultrasound moving image, the resulting ultrasound moving image is more vivid when reproduced.</p>
      <p id="p-00153-en" num="0153">As described above, by generating or playing back an ultrasound moving image by using ultrasound images corresponding to markers, it is possible to sequentially reproduce clinically important ultrasound images that are suited to user's intentions. Thus, according to embodiments of the present invention, a user may easily diagnose disease by using an ultrasound moving image, and a patient may conveniently listen to the user's explanation about the patient's health conditions while viewing the ultrasound image.</p>
      <p id="p-00154-en" num="0154">
        <figref>FIG. 11</figref> is a flowchart of a method <b>1100</b> of displaying an ultrasound image according to an exemplary embodiment of the present invention. The method <b>1100</b> of displaying an ultrasound image according to the present embodiment includes the same operations as those performed by the ultrasound diagnosis apparatus <b>200</b> described with reference to <figref>FIGS. 1 through 10</figref>. Thus, the same descriptions as already presented with respect to <figref>FIGS. 1 through 10</figref> are omitted.</p>
      <p id="p-00155-en" num="0155">Referring to <figref>FIG. 11</figref>, according to the method <b>1100</b>, a first screen including at least one marker is displayed (operation <b>1110</b>). Operation <b>1110</b> may be performed by the display unit <b>230</b> in the ultrasound diagnosis apparatus <b>200</b> of <figref>FIG. 2</figref>. In detail, a first screen that includes a marker list containing the at least one marker may be displayed. Herein, the marker list may include the at least one marker indicating a predetermined point of the object or at least one marker representing a display view of the object. Furthermore, the first screen may further include a first ultrasound image representing an object.</p>
      <p id="p-00156-en" num="0156">Selection of a predetermined marker among the displayed at least one marker list is received (operation <b>1120</b>). Operation <b>1120</b> may be performed by the user interface unit <b>220</b>. In detail, the user interface unit <b>220</b> may receive selection of a predetermined marker in a marker list included in the screen displayed on the display unit <b>230</b>.</p>
      <p id="p-00157-en" num="0157">Following operation <b>1120</b>, a view of the object may be changed according to the predetermined marker selected in operation <b>1120</b>, based on position information of the predetermined marker and information about a viewpoint corresponding to the predetermined marker. Accordingly, a second ultrasound image representing an object of which a view is changed may be generated.</p>
      <p id="p-00158-en" num="0158">A second screen including the second ultrasound image that represents the object having the changed view is displayed (operation <b>1130</b>). Operation <b>1130</b> may be performed by the display unit <b>230</b> according to a control of the controller <b>210</b>.</p>
      <p id="p-00159-en" num="0159">As described above, an ultrasound diagnosis apparatus and a method of displaying an ultrasound image according to embodiments of the present invention are adapted to change a view of an ultrasound image corresponding to an object by selecting a marker in a marker list, thereby allowing a user to more conveniently and easily diagnose a portion of the object to be examined.</p>
      <p id="p-00160-en" num="0160">While one or more embodiments of the present invention have been described with reference to the figures, it will be understood by those of ordinary skill in the art that various changes in form and details may be made therein without departing from the spirit and essential characteristics of the present invention as defined by the following claims. Thus, it should be understood that the exemplary embodiments described therein should be considered in a descriptive sense only and not for purposes of limitation. The scope of the invention is defined not by the embodiments but by the appended claims, and all modifications or substitutions within the scope of the appended claims and their equivalents will be construed as being included in the present invention.</p>
    </detailed-desc>
  </description>
  <us-claim-statement>What is claimed is:</us-claim-statement>
  <claims id="claims_eng" lang="eng" format="original" date-changed="20150917">
    <claim num="1" id="clm-00001-en" independent="true">
      <claim-text>
        <b>1</b>. An ultrasound diagnosis apparatus comprising:
<claim-text>a display unit that displays a first screen including at least one marker;</claim-text><claim-text>a user interface unit for receiving a selection of a predetermined marker among the at least one marker; and</claim-text><claim-text>a controller that controls the display unit to display a first screen including a second ultrasound image that represents an object and has a view which is changed according to the predetermined marker.</claim-text></claim-text>
    </claim>
    <claim num="2" id="clm-00002-en">
      <claim-text>
        <b>2</b>. The apparatus of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, wherein the controller changes the view of the object based on position information of the predetermined marker and information about a viewpoint corresponding to the predetermined marker.</claim-text>
    </claim>
    <claim num="3" id="clm-00003-en">
      <claim-text>
        <b>3</b>. The apparatus of <claim-ref idref="clm-00002-en">claim 2</claim-ref>, further comprising a memory for storing the position information of the predetermined marker and the information about the viewpoint corresponding to the predetermined marker.</claim-text>
    </claim>
    <claim num="4" id="clm-00004-en">
      <claim-text>
        <b>4</b>. The apparatus of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, wherein the first screen includes a second ultrasound image representing an object and a marker list comprises the at least one marker</claim-text>
    </claim>
    <claim num="5" id="clm-00005-en">
      <claim-text>
        <b>5</b>. The apparatus of <claim-ref idref="clm-00004-en">claim 4</claim-ref>, wherein the marker list comprises the at least one marker indicating a predetermined point of the object or at least one marker representing a display view of the object.</claim-text>
    </claim>
    <claim num="6" id="clm-00006-en">
      <claim-text>
        <b>6</b>. The apparatus of <claim-ref idref="clm-00004-en">claim 4</claim-ref>, wherein when the object is a fetus, the marker list comprises at least one marker representing a display view of the object for measuring biometrics.</claim-text>
    </claim>
    <claim num="7" id="clm-00007-en">
      <claim-text>
        <b>7</b>. The apparatus of <claim-ref idref="clm-00004-en">claim 4</claim-ref>, wherein when the object is a fetus, the marker list comprises at least one marker representing a display view of the object for diagnosing whether the fetus is normally growing.</claim-text>
    </claim>
    <claim num="8" id="clm-00008-en">
      <claim-text>
        <b>8</b>. The apparatus of <claim-ref idref="clm-00004-en">claim 4</claim-ref>, wherein the user interface unit receives a selection of at least one marker from a user in order to generate the marker list.</claim-text>
    </claim>
    <claim num="9" id="clm-00009-en">
      <claim-text>
        <b>9</b>. The apparatus of <claim-ref idref="clm-00004-en">claim 4</claim-ref>, wherein the controller extracts at least one marker representing a display view for diagnosing the object or measuring a part of the object.</claim-text>
    </claim>
    <claim num="10" id="clm-00010-en">
      <claim-text>
        <b>10</b>. The apparatus of <claim-ref idref="clm-00009-en">claim 9</claim-ref>, wherein the marker list comprises at least one of the at least one extracted marker and at least one marker selected by the user.</claim-text>
    </claim>
    <claim num="11" id="clm-00011-en">
      <claim-text>
        <b>11</b>. The apparatus of <claim-ref idref="clm-00004-en">claim 4</claim-ref>, wherein the controller assigns the at least one marker to a group based on a distance between markers and generates the marker list including a sub-marker list containing the at least one marker assigned to the group.</claim-text>
    </claim>
    <claim num="12" id="clm-00012-en">
      <claim-text>
        <b>12</b>. The apparatus of <claim-ref idref="clm-00004-en">claim 4</claim-ref>, wherein the controller assigns the at least one marker to a group according to each part of the object and generates the marker list including a sub-marker list containing the at least one marker assigned to the group.</claim-text>
    </claim>
    <claim num="13" id="clm-00013-en">
      <claim-text>
        <b>13</b>. The apparatus of <claim-ref idref="clm-00004-en">claim 4</claim-ref>, wherein the user interface unit outputs an edit menu for generating an ultrasound moving image based on at least one ultrasound image corresponding to the at least one marker included in the marker list.</claim-text>
    </claim>
    <claim num="14" id="clm-00014-en">
      <claim-text>
        <b>14</b>. The apparatus of <claim-ref idref="clm-00013-en">claim 13</claim-ref>, wherein the controller controls the apparatus so that the ultrasound moving image generated based on the at least one ultrasound image corresponding to the at least one marker selected through the edit menu is played back.</claim-text>
    </claim>
    <claim num="15" id="clm-00015-en">
      <claim-text>
        <b>15</b>. The apparatus of <claim-ref idref="clm-00013-en">claim 13</claim-ref>, wherein in order to play back the ultrasound moving image, the user interface unit receives at least one of a playback duration of an ultrasound image corresponding to a selected marker, information about image effects applied to the ultrasound image, and audio information related to the ultrasound image via the edit menu.</claim-text>
    </claim>
    <claim num="16" id="clm-00016-en">
      <claim-text>
        <b>16</b>. The apparatus of <claim-ref idref="clm-00015-en">claim 15</claim-ref>, wherein the controller controls playback of the ultrasound moving image based on the playback duration, the information about image effects, and the audio information.</claim-text>
    </claim>
    <claim num="17" id="clm-00017-en">
      <claim-text>
        <b>17</b>. The apparatus of <claim-ref idref="clm-00004-en">claim 4</claim-ref>, wherein each item of the marker list comprises at least one of information about a part of the object corresponding to a marker, information about a display view of the object corresponding to the marker, information about measurable biometrics corresponding to the marker, and the second ultrasound image.</claim-text>
    </claim>
    <claim num="18" id="clm-00018-en" independent="true">
      <claim-text>
        <b>18</b>. A method of displaying an ultrasound image, the method comprising:
<claim-text>displaying a first screen including at least one marker;</claim-text><claim-text>receiving a selection of a predetermined marker among the at least one marker; and</claim-text><claim-text>displaying a second screen including a first ultrasound image that represents an object and has a view which is changed according to the predetermined marker.</claim-text></claim-text>
    </claim>
    <claim num="19" id="clm-00019-en">
      <claim-text>
        <b>19</b>. The method of <claim-ref idref="clm-00018-en">claim 18</claim-ref>, further comprising changing the view of the object based on position information of the predetermined marker and information about a viewpoint corresponding to the predetermined marker. </claim-text>
    </claim>
  </claims>
  <drawings id="drawings" format="original">
    <figure num="1">
      <img he="N/A" wi="N/A" file="US20150257738A1_00001.PNG" alt="clipped image" img-content="drawing" img-format="png" original="US20150257738A1-20150917-D00000.TIF" />
    </figure>
    <figure num="2">
      <img he="N/A" wi="N/A" file="US20150257738A1_00002.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150257738A1-20150917-D00001.TIF" />
    </figure>
    <figure num="3">
      <img he="N/A" wi="N/A" file="US20150257738A1_00003.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150257738A1-20150917-D00002.TIF" />
    </figure>
    <figure num="4">
      <img he="N/A" wi="N/A" file="US20150257738A1_00004.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150257738A1-20150917-D00003.TIF" />
    </figure>
    <figure num="5">
      <img he="N/A" wi="N/A" file="US20150257738A1_00005.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150257738A1-20150917-D00004.TIF" />
    </figure>
    <figure num="6">
      <img he="N/A" wi="N/A" file="US20150257738A1_00006.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150257738A1-20150917-D00005.TIF" />
    </figure>
    <figure num="7">
      <img he="N/A" wi="N/A" file="US20150257738A1_00007.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150257738A1-20150917-D00006.TIF" />
    </figure>
    <figure num="8">
      <img he="N/A" wi="N/A" file="US20150257738A1_00008.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150257738A1-20150917-D00007.TIF" />
    </figure>
    <figure num="9">
      <img he="N/A" wi="N/A" file="US20150257738A1_00009.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150257738A1-20150917-D00008.TIF" />
    </figure>
    <figure num="10">
      <img he="N/A" wi="N/A" file="US20150257738A1_00010.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150257738A1-20150917-D00009.TIF" />
    </figure>
    <figure num="11">
      <img he="N/A" wi="N/A" file="US20150257738A1_00011.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150257738A1-20150917-D00010.TIF" />
    </figure>
    <figure num="12">
      <img he="N/A" wi="N/A" file="US20150257738A1_00012.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150257738A1-20150917-D00011.TIF" />
    </figure>
    <figure num="13">
      <img he="N/A" wi="N/A" file="US20150257738A1_00013.PNG" alt="thumbnail image" img-content="drawing" img-format="png" original="US20150257738A1-20150917-D00000.TIF" />
    </figure>
  </drawings>
  <image file="US20150257738A1.PDF" type="pdf" size="1741627" pages="22" />
</lexisnexis-patent-document>