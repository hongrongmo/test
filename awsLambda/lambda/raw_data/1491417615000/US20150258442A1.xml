<?xml version="1.0" encoding="utf-8"?>
<!-- Copyright Â©2016 LexisNexis Univentio, The Netherlands. -->
<lexisnexis-patent-document schema-version="1.13" date-produced="20160127" file="US20150258442A1.xml" produced-by="LexisNexis-Univentio" lang="eng" date-inserted="20150917" time-inserted="030349" date-changed="20151214" time-changed="184645">
  <bibliographic-data lang="eng">
    <publication-reference publ-type="Application" publ-desc="Patent Application Publication">
      <document-id id="121318097">
        <country>US</country>
        <doc-number>20150258442</doc-number>
        <kind>A1</kind>
        <date>20150917</date>
      </document-id>
    </publication-reference>
    <application-reference appl-type="utility">
      <document-id>
        <country>US</country>
        <doc-number>14206765</doc-number>
        <date>20140312</date>
      </document-id>
    </application-reference>
    <application-series-code>14</application-series-code>
    <language-of-filing>eng</language-of-filing>
    <language-of-publication>eng</language-of-publication>
    <dates-of-public-availability date-changed="20150924">
      <unexamined-printed-without-grant>
        <date>20150917</date>
      </unexamined-printed-without-grant>
    </dates-of-public-availability>
    <classifications-ipcr date-changed="20151013">
      <classification-ipcr sequence="1">
        <text>A63F  13/537       20140101AFI20150917BHUS        </text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>A</section>
        <class>63</class>
        <subclass>F</subclass>
        <main-group>13</main-group>
        <subgroup>537</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150917</date>
        </action-date>
        <generating-office>
          <country>US</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>A63F  13/837       20140101ALI20150917BHUS        </text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>A</section>
        <class>63</class>
        <subclass>F</subclass>
        <main-group>13</main-group>
        <subgroup>837</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150917</date>
        </action-date>
        <generating-office>
          <country>US</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
    </classifications-ipcr>
    <classifications-cpc date-changed="20151013">
      <classification-cpc sequence="1">
        <text>A63F  13/537       20140902 FI20150917BHEP        </text>
        <cpc-version-indicator>
          <date>20140902</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>63</class>
        <subclass>F</subclass>
        <main-group>13</main-group>
        <subgroup>537</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150917</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
      <classification-cpc sequence="2">
        <text>A63F  13/577       20130101 LI20151009BHEP        </text>
        <cpc-version-indicator>
          <date>20130101</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>63</class>
        <subclass>F</subclass>
        <main-group>13</main-group>
        <subgroup>577</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20151009</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
      <classification-cpc sequence="3">
        <text>A63F  13/58        20140902 LI20151009BHEP        </text>
        <cpc-version-indicator>
          <date>20140902</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>63</class>
        <subclass>F</subclass>
        <main-group>13</main-group>
        <subgroup>58</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20151009</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
      <classification-cpc sequence="4">
        <text>A63F  13/837       20140901 LI20150917BHEP        </text>
        <cpc-version-indicator>
          <date>20140901</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>63</class>
        <subclass>F</subclass>
        <main-group>13</main-group>
        <subgroup>837</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150917</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
    </classifications-cpc>
    <number-of-claims calculated="yes">20</number-of-claims>
    <invention-title id="title_eng" date-changed="20150917" lang="eng" format="original">POTENTIAL DAMAGE INDICATOR OF A TARGETED OBJECT</invention-title>
    <parties date-changed="20150917">
      <applicants>
        <applicant sequence="1" app-type="applicant">
          <addressbook lang="eng">
            <orgname>Wargaming.net LLP</orgname>
            <role>03</role>
            <address>
              <city>Walthamstow</city>
              <country>GB</country>
            </address>
          </addressbook>
        </applicant>
      </applicants>
      <inventors>
        <inventor sequence="1" designation="us-only">
          <addressbook lang="eng">
            <last-name>Yudo</last-name>
            <first-name>Dzmitry</first-name>
            <address>
              <city>Minsk</city>
              <country>BY</country>
            </address>
          </addressbook>
        </inventor>
        <inventor sequence="2" designation="us-only">
          <addressbook lang="eng">
            <last-name>Alexeev</last-name>
            <first-name>Alexey</first-name>
            <address>
              <city>Minsk</city>
              <country>BY</country>
            </address>
          </addressbook>
        </inventor>
      </inventors>
    </parties>
    <patent-family date-changed="20150917">
      <main-family family-id="173672818">
        <family-member>
          <document-id>
            <country>US</country>
            <doc-number>20150258442</doc-number>
            <kind>A1</kind>
            <date>20150917</date>
          </document-id>
          <application-date>
            <date>20140312</date>
          </application-date>
        </family-member>
      </main-family>
      <complete-family family-id="173672817">
        <family-member>
          <document-id>
            <country>US</country>
            <doc-number>20150258442</doc-number>
            <kind>A1</kind>
            <date>20150917</date>
          </document-id>
          <application-date>
            <date>20140312</date>
          </application-date>
        </family-member>
      </complete-family>
    </patent-family>
  </bibliographic-data>
  <abstract id="abstr_eng" date-changed="20150917" lang="eng" format="original">
    <p id="p-a-00001-en" num="0000">Methods and systems for providing multiple viewing modes of a simulated environment are described herein. The different viewing modes may include a magnified view of the environment, an unmagnified view, and/or a magnified view combined with an unmagnified view. The different viewing modes may include a model of a user controlled object which mimics the movement of the user controlled object to provide the user with information regarding the positioning or orientation of the user controlled object with respect to the user's current view. In the different viewing modes, a potential damage indicator may be provided on a targeted object to indicate potential damage to the targeted object based on a current weapon selection.</p>
  </abstract>
  <legal-data date-changed="20151002">
    <legal-event sequence="1">
      <publication-date>
        <date>20140414</date>
      </publication-date>
      <event-code-1>AS</event-code-1>
      <legal-description>ASSIGNMENT</legal-description>
      <status-identifier>N</status-identifier>
      <docdb-publication-number> US  2015258442A1</docdb-publication-number>
      <docdb-application-id>444512524</docdb-application-id>
      <new-owner>WARGAMING.NET LLP, UNITED KINGDOM</new-owner>
      <free-text-description>ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:YUDO, DZMITRY;ALEXEEV, ALEXEY;REEL/FRAME:032666/0765</free-text-description>
      <effective-date>
        <date>20140311</date>
      </effective-date>
    </legal-event>
  </legal-data>
  <description id="descr_eng" lang="eng" format="original" date-changed="20150917">
    <summary>
      <heading id="h-00001-en" level="1">FIELD</heading>
      <p id="p-00001-en" num="0001">Aspects of the disclosure relate to computer systems, computer software, and video games. More particularly, aspects of the disclosure relate to video game software, including multiple viewing modes.</p>
      <heading id="h-00002-en" level="1">BACKGROUND</heading>
      <p id="p-00002-en" num="0002">Video games are increasingly popular. Online multiplayer video games have become particularly popular due, at least in part, to the ability of players to compete with multiple other human players.</p>
      <p id="p-00003-en" num="0003">Popular genres of multiplayer games include the first-person-shooter (FPS) and the third-person shooter genres. In FPS games, the player's on-screen view simulates the view of the character or vehicle controlled by the player; that is, the first-person view. The object of many FPS games is to accomplish a goal within a game. Common goals include killing other game characters that represent other players, capturing flags that represent opponents' territory, assaulting another team's base, and the like. Third person shooter games often have similar goals but differ in the perspective of the player. In third person shooter games, the player views the game world from above or behind the character or vehicle controlled by the player. Typically, the player is provided with the option of viewing faraway objects in the environment in more detail such as a sniper mode in which the view simulates the view through a sniper rifle scope. While in the sniper mode, the environment surrounding the player's character or vehicle is not shown.</p>
      <heading id="h-00003-en" level="1">SUMMARY</heading>
      <p id="p-00004-en" num="0004">The following presents a simplified summary of various aspects described herein. This summary is not an extensive overview, and is not intended to identify key or critical elements or to delineate the scope of the claims. The following summary merely presents some concepts in a simplified form as an introductory prelude to the more detailed description provided below.</p>
      <p id="p-00005-en" num="0005">Methods and apparatuses for providing different views of a simulated environment are described herein. According to an aspect, a user can view the simulated environment in a first mode with a first magnification level and change to another viewing mode containing a magnified and an unmagnified view which may be controlled manually or automatically. The magnified view may be magnified for the area or portion of the environment viewed through a reticle. The user may also be able to adjust the magnification level of the magnified view.</p>
      <p id="p-00006-en" num="0006">According to another aspect, a model of a user controlled object may be displayed on the screen to provide the user with information about the orientation of the user controlled object. The second version may be a model of the full size version of the user controlled object, and the second version of the user controlled object may be displayed while the user is in a magnified viewing mode. The orientation of parts of the second version may be the same as the orientation of parts of the first version. The second version may further be provided with a directional indicator to provide the user with information regarding the movement direction of the user controlled object.</p>
      <p id="p-00007-en" num="0007">According to yet another aspect, a potential damage indicator may be displayed on screen to provide a user with information about damage which a targeted object may receive from a selected weapon. When the selected weapon is changed, the potential damage indicator can also change to reflect the potential damage which a targeted object may receive from the newly selected weapon.</p>
      <p id="p-00008-en" num="0008">The methods described herein may be performed based on instructions stored on a statutory computer readable medium, or executed by a virtual environment server configured to perform as described herein.</p>
      <p id="p-00009-en" num="0009">These and other aspects will be apparent upon reading the detailed description below.</p>
    </summary>
    <description-of-drawings>
      <heading id="h-00004-en" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
      <p id="p-00010-en" num="0010">A more complete understanding of the present invention and the advantages thereof may be acquired by referring to the following description in consideration of the accompanying drawings, in which like reference numbers indicate like features, and wherein:</p>
      <p id="p-00011-en" num="0011">
        <figref>FIG. 1</figref> is an illustrative network environment in which one or more aspects described herein may be used.</p>
      <p id="p-00012-en" num="0012">
        <figref>FIG. 2</figref> is a block diagram illustrating an example virtual world client according to one or more aspects described herein.</p>
      <p id="p-00013-en" num="0013">
        <figref>FIG. 3</figref> is a block diagram illustrating an example virtual world server according to one or more aspects described herein.</p>
      <p id="p-00014-en" num="0014">
        <figref>FIG. 4</figref> illustrates a block architecture diagram of software modules that may be used to implement various features described herein.</p>
      <p id="p-00015-en" num="0015">
        <figref>FIG. 5A</figref> illustrates an instance of a character object according to various features described herein.</p>
      <p id="p-00016-en" num="0016">
        <figref>FIG. 5B</figref> illustrates an instance of a vehicle object according to various features described herein.</p>
      <p id="p-00017-en" num="0017">
        <figref>FIG. 6</figref> illustrates a screenshot of a video game user interface implementing one or more illustrative aspects described herein.</p>
      <p id="p-00018-en" num="0018">
        <figref>FIG. 7</figref> illustrates a screenshot of a video game user interface implementing one or more illustrative aspects described herein.</p>
      <p id="p-00019-en" num="0019">
        <figref>FIG. 8</figref> illustrates a screenshot of a video game user interface implementing one or more illustrative aspects described herein.</p>
      <p id="p-00020-en" num="0020">
        <figref>FIG. 9</figref> illustrates a screenshot of a video game user interface implementing one or more illustrative aspects described herein.</p>
      <p id="p-00021-en" num="0021">
        <figref>FIGS. 10A and 10B</figref> illustrate screenshots of a video game user interface implementing one or more illustrative aspects described herein.</p>
      <p id="p-00022-en" num="0022">
        <figref>FIGS. 11A and 11B</figref> illustrate screenshots of a video game user interface implementing one or more illustrative aspects described herein.</p>
      <p id="p-00023-en" num="0023">
        <figref>FIG. 12</figref> illustrates a flowchart for a method of providing two different views of an environment according to one or more illustrative aspects described herein.</p>
      <p id="p-00024-en" num="0024">
        <figref>FIG. 13</figref> illustrates a flowchart for a method of providing a second version of a controlled object according to one or more illustrative aspects described herein.</p>
      <p id="p-00025-en" num="0025">
        <figref>FIG. 14</figref> illustrates a flowchart for a method of providing a potential damage indicator based on a weapon selection according to one or more illustrative aspects described herein.</p>
    </description-of-drawings>
    <detailed-desc>
      <heading id="h-00005-en" level="1">DETAILED DESCRIPTION</heading>
      <p id="p-00026-en" num="0026">In the following description of the various aspects, reference is made to the accompanying drawings, which form a part hereof, and in which is shown by way of illustration how various features described herein may be practiced. It is understood that other embodiments may be used and structural and functional modifications may be made.</p>
      <p id="p-00027-en" num="0027">
        <figref>FIG. 1</figref> illustrates a network environment in which clients <b>101</b> may interact with virtual world servers <b>105</b> to provide a virtual world for users to access. Clients <b>101</b> may include a variety of devices including generic data processing device <b>101</b><i>a</i>, personal computer (PC) <b>101</b><i>b</i>, laptop, portable, or netbook computer <b>101</b><i>c</i>, personal data assistant, mobile phone or device <b>101</b><i>d</i>, a tablet device (not shown) and the like. Each of clients <b>101</b> may have a network adapter that allows clients <b>101</b> to connect to virtual world servers <b>105</b> through network <b>100</b>. In one example, network <b>100</b> may include an Internet Protocol (IP) based network, e.g., the Internet. Other networks may include cellular networks, cable networks, fiber optic networks, wireless networks, wired network and/or combinations thereof. Network <b>100</b> may further include one or more sub-networks such as wired or wireless local area networks (LANs), wide area networks (WANs), and the like.</p>
      <p id="p-00028-en" num="0028">In one or more arrangements, virtual world servers <b>105</b> may be included in a virtual world server system <b>103</b> that includes multiple linked physical and/or logical servers <b>105</b>. Using such a distributed system, servers <b>105</b> may be able to distribute load across each of server <b>105</b>. For example, if server <b>105</b><i>a </i>is experiencing high loads, some of the operations may be passed to either server <b>105</b><i>b </i>or <b>105</b><i>c </i>or both. Load may further be distributed based on user geography or on other predetermined bases. Alternatively, the virtual world may be hosted on a single server, e.g., virtual world server <b>105</b><i>a</i>. Each of servers <b>105</b> may collectively generate and manage a single instance of the virtual world, or each server <b>105</b><i>a</i>, <b>105</b><i>b </i>and <b>105</b><i>c </i>may provide independent instances of the world. An instance of a virtual world, as used herein, describes a stand-alone instance of the virtual world that does not interact with or depend on other instances of the virtual world. Depending on the processing load, a virtual world server system <b>103</b> may divide a plurality of users among multiple instances of the virtual world, to reduce or alleviate overloading on a single server or prevent overpopulation. Each server <b>105</b> may be logical or physical, e.g., multiple logical servers may reside and be running on the same physical computing device/server, or servers may be physically separate devices.</p>
      <p id="p-00029-en" num="0029">The network environment of <figref>FIG. 1</figref> may also associate with one or more matchmaking servers <b>106</b> such as a system of servers. For example, a matchmaking server <b>106</b> may determine what set of players to assign to a same instance of the virtual world to ensure that all players meet predefined criteria for that instance of the virtual world. As another example, player account information may be stored on a central server and matchmaking may occur on periphery servers distributed in various geographic locations to ensure better performance. Alternatively, a single server may work in stand-alone mode.</p>
      <p id="p-00030-en" num="0030">
        <figref>FIG. 2</figref> illustrates an example client device <b>200</b> such as PC <b>101</b><i>b</i>, laptop, portable, or netbook computer <b>101</b><i>c</i>, personal data assistant, mobile phone or device <b>101</b><i>d</i>, or a tablet device (<figref>FIG. 1</figref>) that may be used to access and interact with a virtual world provided by a virtual world server such as server <b>105</b><i>a </i>of <figref>FIG. 1</figref>. Client device <b>200</b> may include a variety of components and modules including a processor <b>217</b>, random access memory (RAM) <b>215</b>, read only memory (ROM) <b>213</b>, databases <b>201</b> and <b>203</b>, client software <b>205</b>, output adapter <b>211</b>, input interface <b>209</b> and communication interface <b>207</b>. Software, databases, operating systems, and the like may be stored in nonvolatile memory <b>206</b> (e.g., a magnetic disk or solid state hard drive, or equivalent). Object database <b>201</b> may be configured to store data defining and otherwise associated with an object used by a user of device <b>200</b> to explore and interact with the virtual world. World database <b>203</b>, on the other hand, may be configured to store data for defining and generating the environment in which the objects exist. For example, world database <b>203</b> may store texture maps for rendering a floor or ground, walls, a sky and the like. In another example, world database <b>203</b> may store simulated environments, buildings, trees and other data defining animate or inanimate objects existing in the world, data defining computer controlled characters and the like. Each of database <b>201</b>, <b>203</b> may or may not be a conventional database, and instead may refer to data stored in a memory, accessed as needed by the client software. Data associated with an object or the virtual world may be communicated between client device <b>200</b> and a virtual world server using communication interface <b>207</b>. For example, object positions, attributes and status may be updated or environments may be changed by communicating such data through interface <b>207</b>.</p>
      <p id="p-00031-en" num="0031">The world and the objects may be graphically rendered by client software <b>205</b> and subsequently sent to output adapter <b>211</b> and display <b>219</b>. The client software <b>205</b> may, in one or more arrangements, be configured to generated three dimensional (3-D) models of the virtual world and components thereof as well as the object corresponding to a user. A user may control the object and interact with the world through input interface <b>209</b> using various types of input devices including keyboard <b>223</b> and mouse <b>225</b>, and one or more touch sensors <b>227</b> that sense when a user has pressed his or her finger at various locations, such as location <b>229</b>. In some embodiments the one or more touch sensors <b>227</b> may be included in a touch pad, touch screen or the like. Devices that include one or more touch sensors <b>227</b> may detect various gestures performed by a user as one or more of his or her fingers are pressed onto the one or more touch sensors <b>227</b> (or the touch pad, touch screen, etc.). There are various types of touch sensors that a device may use, including capacitive touch sensors and resistive touch sensors. Some touch sensors may be usable with a stylus and a user may use the stylus instead of his or her finger to provide input to the touch sensor. Additionally, some touch sensors may be able to detect a single touch, while other touch sensors may be able to detect multiple touches at a given time. Other types of input devices may include a microphone (e.g., for voice communications over the network), joysticks, motion sensing devices and/or combinations thereof. In one or more arrangements, music or other audio such as speech may be included as part of the virtual world. In such instances, the audio may be outputted through speaker <b>221</b>.</p>
      <p id="p-00032-en" num="0032">Client software <b>205</b>, computer executable instructions, and other data used by processor <b>217</b> and other components of client device <b>200</b> may be stored RAM <b>215</b>, ROM <b>213</b>, nonvolatile memory <b>206</b> or a combination thereof. Other types of memory may also be used, including both volatile and nonvolatile memory. Software <b>205</b> may provide instructions to processor <b>217</b> such that when the instructions are executed, processor <b>217</b>, client device <b>200</b> and/or other components thereof are caused to perform functions and methods described herein. In one example, instructions for generating a user interface for interfacing with the virtual world server may be stored in RAM <b>215</b>, ROM <b>213</b> and/or nonvolatile memory <b>206</b>. Client software <b>205</b> may include both applications and operating system software, and may include code segments, instructions, applets, pre-compiled code, compiled code, computer programs, program modules, engines, program logic, and combinations thereof. Computer executable instructions and data may further be stored on some physical form of computer readable storage media (referred to herein as âcomputer memoryâ) including, e.g., electrically erasable programmable read-only memory (EEPROM), flash memory or other memory technology, CD-ROM, DVD or other optical disk storage, magnetic cassettes, magnetic tape, magnetic storage and the like.</p>
      <p id="p-00033-en" num="0033">Referring now to <figref>FIG. 3</figref>, a virtual world server <b>300</b> (e.g., an instance of server <b>105</b>) may be configured to generate and operate a massive multiplayer online game, such as virtual world or the like. Server <b>300</b> may include processor <b>301</b>, ROM <b>303</b>, RAM <b>305</b>, communication interface <b>307</b>, object position database <b>309</b>, world database <b>311</b>, user database <b>313</b>, server software <b>317</b>, and a statistics database <b>312</b>. Object position database <b>309</b> may be configured to store position information for each object (e.g., based on commands to move a vehicle received from each client). The statistics database <b>312</b> may be configured to store and/or transfer statistics relevant to game operation, including, for example, tracking player achievement and general game server performance.</p>
      <p id="p-00034-en" num="0034">A world database <b>311</b> may store rules, algorithms and other data for interactions that are available in the world. For example, a manner in which a computer controller character moves or otherwise behaves may be defined in data stored in world database <b>311</b>. Additionally, item information may be defined in world database <b>311</b> so that items may not be modified by each client. In another example, world database <b>311</b> may store location information for non-object items and components. User database <b>313</b>, on the other hand, may be configured to store information describing a user controlling an object. For example, user database <b>313</b> may include account information, user preferences, one or more classes of user experience points and/or levels, payment information, user identification information, character definitions, state tables, and the like. Each of databases <b>309</b>, <b>311</b>, <b>312</b>, <b>313</b> may or may not be a conventional database, and instead may refer to data stored in a memory, accessed as needed by the server software. For example, user database <b>313</b> may in fact be a collection of multiple databases or database tables.</p>
      <p id="p-00035-en" num="0035">Features described herein may be used with or in a variety of video games, including but not limited to, WORLD OF TANKSÂ®, World of Tanks Blitzâ¢, and World of Tanks 360 by Wargaming.netÂ®. Aspects described herein may also be used with other video games and are not limited to any one genre or implementation. Aspects described herein may be implemented in video game application software stored on a computer readable medium, e.g., storage <b>201</b>, <b>203</b>, <b>205</b>, <b>206</b>, <b>213</b>, <b>215</b>, <b>309</b>, <b>311</b><b>312</b>, and/or <b>313</b>, and executable by a data processing device.</p>
      <p id="p-00036-en" num="0036">Various aspects of the disclosure provide features and capabilities that enhance game play by providing options through which users can develop strategies to play the video game. According to various aspects described herein, a video game may provide a graphically simulated virtual world or virtual environment, in which the game takes place, referred to herein interchangeably as a virtual world and as a simulated environment of the video game. The simulated environment may have features similar to actual geographic locations or may have fictional, science fiction or fantasy-themed environments.</p>
      <p id="p-00037-en" num="0037">
        <figref>FIG. 4</figref> illustrates a block diagram of a video game software application <b>401</b>. Each block in <figref>FIG. 4</figref> illustrates a logical software module or function that performs an action, provides a capability or feature, implements an object, or performs some other aspect of the video game. When the video game software <b>401</b> executes on a data processing system such as a PC or game console, the modules operate collectively to provide a video game experience to a player. The modules illustrated in <figref>FIG. 4</figref> are illustrative only, and additional or different modules may be used. The same, additional or different modules may be executed in tandem on a server with which each client device is connected.</p>
      <p id="p-00038-en" num="0038">Video game software <b>401</b> may include, e.g., a game manager module <b>402</b>, which manages the overall operation of the video game and may be the initial module launched when the video game is executed. Video game software <b>401</b> may also include a network module <b>403</b>, which manages network games sessions and communication with one or more game servers. A network game session may include e.g., a co-operative campaign with other networked players, or other compartmentalized periods of game play involving players located at discrete network locations. A memory manager module <b>409</b> performs memory management during execution of the video game <b>401</b>. An input module <b>404</b> may receive and interpret user input via a game controller, keyboard, mouse, and the like, and provide the interpreted commands to game manager <b>402</b>, network module <b>403</b>, or other applicable module. UI module <b>405</b> may manage and control the user interface, including the display displayed on the video output device, interpreting input via the input module <b>404</b>, and providing audio output via audio module <b>408</b>.</p>
      <p id="p-00039-en" num="0039">Various software modules may operate with one or more classes or objects defined and used in the video game <b>401</b>. The classes and objects may be defined with reference to an object module <b>410</b>, and may include portions of executable software code and/or one or more data structures, depending on the object. Each object may be rendered and simulated in the virtual world in accordance with a physics engine <b>407</b>. Video game software <b>401</b> may include other software modules <b>411</b> as needed. <figref>FIG. 4</figref> illustrates one possible software architecture. Others may be used. Each module depicted in <figref>FIG. 4</figref> may communicate directly or indirectly with each other module, e.g., by passing objects, data, parameters, input, and output, etc.</p>
      <p id="p-00040-en" num="0040">A first class of in-game objects may define characters in the video game. One or more characters may be defined by various attributes associated with the character, e.g., name, physical appearance, skills, etc. Skills may be defined based on a character's genre or task, e.g., gunners, tank commanders, and drivers in the present example. A gunner may have skills such as aiming accuracy and aiming speed, a tank commander may have skills that regulate the overall efficiency of the tank crew, a driver may have skills that determine the vehicle speed or precision of direction. Additional character attributes may include one or more other skills that can improve performance of the character or vehicle so as to enhance the strategic gaming experience such as firefighting skills, the ability to repair vehicles, the ability to camouflage vehicles, and the like. One crew member (e.g., a commander) may represent multiple crew members.</p>
      <p id="p-00041-en" num="0041">A second class of in-game objects may define vehicles in the video game. A vehicle may be defined as any simulated inanimate object directly or indirectly controllable by or dependent on an in-game character or user/player. Illustrative vehicles may include tanks, airplanes, ships (and/or submarines), and the like. Vehicles may have various attributes and functions that provide advantageous qualities to the vehicle during combat. For example, some vehicles might be fast with minimal firepower, whereas other vehicles may be slower but extremely powerful. Infinite variations of strength, speed, defense, and any other attribute are possible.</p>
      <p id="p-00042-en" num="0042">Object module <b>410</b> may provide an array of vehicles, vehicle components, characters and other equipment. Vehicles, vehicle components, characters and other equipment may be defined by one or more objects and instantiated during the game. Each object may have various attributes and functions and provide advantages and disadvantages based thereon. A vehicle component may refer to an upgradeable component of a vehicle, e.g., armor plating, engine, guns, etc.</p>
      <p id="p-00043-en" num="0043">
        <figref>FIG. 5A</figref> illustrates a block diagram of an instance <b>501</b> of a character object. Object instance <b>501</b> has an object class <b>505</b> (Character). Instance <b>501</b> may acquire one or more attributes from the object class. Attributes <b>507</b>, when examined, define a state of the instance. In this example, the Character has the following attributes: Name <b>511</b>, Qualification <b>512</b>, Training Level <b>513</b>, and Competence <b>514</b>. A character may also have additional skill types 509. Additional skill types may include Repair Skills <b>515</b>, Firefighting skills <b>516</b>, and Camouflage skills <b>517</b>. Other skill types, attributes, etc., may also or alternatively be used.</p>
      <p id="p-00044-en" num="0044">Each attribute may have a particular value. The attribute may have a default value inherited from the Qualification type <b>512</b>. For some attributes, a player may increase attribute value by allocating experience points, gained during gameplay, to the character. Increased attribute value enhances gameplay by improving performance of the vehicle containing the characters. For example, by allocating experience points to the gunner of a tank, the Training Level <b>513</b> may be increased resulting in more accurate gun pointing by a vehicle containing that character, leading to improved vehicle performance during battle. Similarly, the effectiveness of the additional skill types is increased in accordance with the value of the skill Thus, for example, a Firefighting skill <b>516</b> value of 100% is proportionally more effective than a value of 50%. Increased firefighting effectiveness results in reduced damage to the vehicle in the event of a fire. By staffing a vehicle with characters having improved attributes and skills, vehicle performance is maximized allowing for a more effective performance during game play.</p>
      <p id="p-00045-en" num="0045">In some embodiments, attributes might not be able to be changed. Qualification <b>512</b> may not be changed; for example, a driver may not be retrained as a gunner. A character's Competence attribute <b>514</b> refers to their ability to operate a specific vehicle type; for example a specific type of tank such as the M3 Stuart tank. Competence <b>514</b> may be changed by retraining the character to operate the same Qualification <b>512</b> on a different vehicle. Changing Competence <b>514</b> may result in a decreased Training Level <b>513</b> in the new vehicle. Additional experience points may be used to raise the Training Level <b>513</b> in the new vehicle. A character may eventually be associated with multiple competence attributesâone per vehicle the character has been associated with.</p>
      <p id="p-00046-en" num="0046">
        <figref>FIG. 5B</figref> illustrates a block diagram of an instance <b>551</b> of a vehicle object. Object instance <b>551</b> has an object class <b>555</b> (Vehicle). Instance <b>551</b> may acquire one or more attributes <b>557</b> from the object class. Attributes <b>557</b>, when examined, define a state of the instance. In this example, object instance <b>551</b> is a Liechttraktor Tank and has attributes associated with tank properties. Exemplary attributes include Name <b>561</b>, Hit Points <b>563</b>, Weight/Load limit <b>564</b>, Engine Power (h.p.) <b>565</b>, Speed Limit <b>566</b>, Hull Armor <b>567</b>, Turret Armor <b>568</b>, Standard Shell Damage <b>569</b>, Standard Shell Penetration <b>570</b>, Rate of Fire <b>571</b>, Turret Traverse Speed <b>572</b>, View Range <b>573</b>, and Signal Range <b>574</b>. These attributes contribute to the vehicle's effectiveness in combat. Attribute types may also have an attribute value, which determines the effectiveness of the attribute function. For example, the Speed Limit attribute <b>566</b> has a value of 46 km/h, which indicates how fast the vehicle can travel. One or more of the attributes, alone or in combination, may be used to assign the vehicle to a subclass. In this example, vehicle <b>551</b> may be in a subclass of tanks referred to as âLight Tanksâ based on hit points, speed, armor, etc. Other classes of tanks may include medium tanks and heavy tanks, among others. Subclass may be used to quickly identify to a user a general approximation of attributes associated with a vehicle without requiring the user to review each attribute in detail.</p>
      <p id="p-00047-en" num="0047">Aspects of the disclosure involve providing a user with different views of a virtual world or three-dimensional simulated environment. Aspects of the disclosure also include providing the user with additional information in the different views of the environment and gameplay information.</p>
      <p id="p-00048-en" num="0048">Various examples described throughout this disclosure will be described in terms of a user or player touching or pressing a control. Such embodiments may include a device with a touch screen that allows a user or player to press his or her finger (or a stylus or other item that can be detected by a touch sensor of the touch screen) onto the touch screen to provide touch and/or gesture input. When terms such as touch, press, or gesture are used, it can be understood that the computing device is detecting the touch and/or gesture input via one or more touch sensors and/or one or more processors of the computing device. For example, one or more touch sensors may detect a user's touch and provide a signal to the one or more processors representing the touch. The one or more processors may process the signal to determine a location of the touch and/or a direction of the touch. Based on one or more signals received from the touch sensor, the one or more processors may determine that a gesture is being performed by the user (e.g, the user may be swiping or dragging his or her finger across the touch screen). Software, such as the video game application (see e.g., <figref>FIG. 4</figref>), may have access to the touch and/or gesture input (e.g., via the operating system of the device) and may perform additional processing to interpret the touch and/or gesture input. Some instances may include processing the touch and/or gesture input based on a user interface being displayed to the user and responding to the touch and/or gesture input by updating the user interface and/or controlling an object of the virtual world).</p>
      <p id="p-00049-en" num="0049">The various examples described throughout this disclosure are not meant to be limited to a touch screen device or a similar device with a touch sensor. Aspects of the disclosure may be used in a device that has a display screen and a different input device, such as a keyboard or mouse.</p>
      <p id="p-00050-en" num="0050">Using Modules to Display Different Views of the Virtual World</p>
      <p id="p-00051-en" num="0051">A player or user can provide input to manipulate or control an object in a virtual world or three-dimensional simulated environment or change views of the virtual world or simulated environment through the input module <b>404</b> of video game software <b>401</b> which can communicate with a virtual world server <b>300</b> such as a virtual environment server <b>105</b>. The input module <b>404</b> can pass the user input to the other modules including the UI module <b>405</b> to cause changes in the environment or views to be displayed on a display device in response to the user input. Through manipulation of an object in the environment such as a vehicle or character, the user can interact with the simulated environment and view different portions of the environment. The user can further view the environment through a number of different viewpoints and viewing ranges including a first-person view and a third-person view, and the user can change between different viewing modes and/or viewpoints. For example, if the controlled object is a tank vehicle, the player's point of view may be a first-person view from the viewpoint of a character located in the vehicle or a third-person view from a point a short distance behind the user controlled character or vehicle. The distance for the third-person view from behind the user controlled character or vehicle can vary depending on the terrain and viewing modes. The direction of the player's view of the environment may be controlled together with the direction in which a weapon is aimed. The direction of the player's view of the environment may also be changed independently of the direction of a weapon. The player can further control the character or vehicle independently of the direction of the view such that the forward direction for a player's character or vehicle may be in a direction different than the direction of the view being displayed.</p>
      <p id="p-00052-en" num="0052">In accordance with aspects of the disclosure, a player may be able to switch between viewing modes to view objects in the environment which appear a long distance away from the player's viewpoint in more detail or to view portions of the environment with different magnification levels. For example, a first viewing mode may be a normal or unmagnified view of the environment with objects shown having sizes relative to their distances from a player's viewpoint. In a second viewing mode, a player may have a magnified or zoomed in view of a portion of the environment. In another viewing mode, a portion of the on-screen view may be a first view and another portion of the on-screen view may be a different view. The magnified views may also provide additional information to the user in the form of, for example, a potential damage indicator. Examples of aspects of these different viewing modes are illustrated in and described with respect to <figref>FIGS. 6-14</figref>.</p>
      <p id="p-00053-en" num="0053">
        <figref>FIG. 6</figref> illustrates a video game user interface using first viewing mode <b>600</b>, e.g., a third-person view. <figref>FIG. 6</figref> includes a general environment in which a controlled object such as a player's character or vehicle <b>602</b> may be located. Tank vehicle <b>602</b> may have independently controllable and movable parts such as a turret <b>608</b> and a hull <b>610</b>. Turret <b>608</b> and hull <b>610</b> of tank vehicle <b>602</b> may independently pivot with respect to each other. Controls in the form of on-screen controls or virtual controls may be provided to interact with the video game and control various features such as manipulating the tank vehicle <b>602</b>, the aim, and/or view. <figref>FIG. 6</figref> shows an ammunition selection panel <b>616</b>, a firing button <b>618</b>, a virtual joystick <b>620</b>, a viewing mode button <b>622</b>, a consumables panel <b>624</b>, and a view controller <b>626</b>.</p>
      <p id="p-00054-en" num="0054">A second vehicle <b>604</b> may be located in the environment such as an enemy vehicle. A reticle or sight guide <b>606</b> which may be used to assist in targeting and aiming is shown on the screen to provide the player with information regarding the direction, distance, and point at which a weapon (e.g., a gun, missile, or other projectile weapon) may be directed. A point of aim <b>612</b> may be provided in the center of the reticle <b>606</b> to indicate the specific point at which the weapon is aimed. For an object in the distance, the player may find it difficult to determine the particular point on the object at which the gun is aimed. To increase the ease of aiming and accuracy, the player may switch to another viewing mode in which a more detailed or magnified view of a selected area of the environment is shown.</p>
      <p id="p-00055-en" num="0055">In accordance with some aspects, <figref>FIG. 7</figref> shows an illustrative second viewing mode in which the area in and around reticle <b>606</b> is magnified or zoomed in, e.g., representative of a first person view. The magnified view may simulate viewing an environment through a telescopic sight or scope or binoculars. The player can enter a viewing mode by selecting a viewing mode button <b>622</b>. In response to the viewing mode button <b>622</b> selection, video game software <b>401</b> or a virtual world server can generate or render the magnified view and cause the display to show the magnified view of a portion of the simulated environment using modules such as UI module <b>405</b> and graphics module <b>406</b>. Depending on the magnification level, video game software <b>401</b> can cause the size of the area and/or number of pixels displaying each portion of the environment to be increased over a lesser magnification level of the same area. In other words, the higher the magnification level, the more pixels or screen area are used to show the same portion of the environment. The magnified or zoomed area may be centered around the center of the reticle which may also be point of aim <b>612</b>.</p>
      <p id="p-00056-en" num="0056">
        <figref>FIG. 7</figref> shows a screenshot <b>700</b> of the second viewing mode of the environment shown in <figref>FIG. 6</figref>. In this viewing mode, the screen may be entirely replaced with the magnified view. With the magnified view, the player can more precisely aim a weapon at an opposing vehicle <b>604</b>. The player can control movement of the vehicle using a virtual joystick <b>620</b> and control firing of the weapon using a fire button <b>618</b>, which can provide input to input module <b>404</b>. Visual indicators may be provided in response to receiving a movement command such as a directional indicator which will be described in more detail with respect to <figref>FIGS. 8 and 9</figref>. The player can control the view and/or aiming direction of the weapon using another virtual or hardware input option such as by swiping the screen or dragging a point on the screen, using hardware buttons mapped to commands for viewing direction changes, or using an accelerometer and/or gyroscope to detect tilting of a device which may also be used to control the view or aiming direction of the weapon. The player may further control the view displayed independently of the aiming direction of the weapon by swiping the screen or dragging a point on the screen in a particular area such as the tracked area <b>626</b> shown at the bottom of the screen in <figref>FIG. 6</figref>. Input can also be provided using hardware input devices such as a keyboard, mouse, joystick, or controller. To change to another viewing mode, the player can select a viewing mode button such as button <b>622</b>. Similar to <figref>FIG. 6</figref>, the second viewing mode may include a point of aim <b>612</b> to indicate the target of a weapon. In <figref>FIG. 7</figref>, the point of view may be a first-person view simulating aiming a weapon or viewing the environment through a scope. Since the view shown by the viewing camera and the aiming of the weapon may differ, <figref>FIG. 7</figref> shows the instance where the viewing camera and aiming of the weapon are the same.</p>
      <p id="p-00057-en" num="0057">According to an aspect, a miniature version or model <b>702</b> of vehicle <b>602</b> may be included in this view to show the player the orientation of vehicle <b>602</b> relative to the current viewpoint and the travel direction arrows of the vehicle <b>602</b> which are illustrated in <figref>FIGS. 8 and 9</figref>. Model <b>702</b> may be a more simplistic version of vehicle <b>602</b> such as a smaller icon or figure or other visual representation of full size vehicle <b>602</b>. In the example shown in <figref>FIG. 7</figref>, model <b>702</b> is a figure with the general outline of portions of the full size vehicle. For example, model <b>702</b> shows a general shape of turret <b>608</b> and hull <b>610</b> of tank vehicle <b>602</b>. The figure used can also differ depending on the type or category of the full size character or vehicle. A common representation or model may be used for vehicles of each type. For example, a representative model of each category of Self Propelled Guns (SPG, or artillery), Light Tanks, Medium Tanks, Heavy Tanks, and Tank Destroyers may be used. In another example, one common model may be used for tank vehicles having pivotable turrets and another common model may be used for tank vehicles with non-pivoting turrets. The positioning of model <b>702</b> on the screen may also be adjusted based on a player's preference and can be displayed in any location of the screen. Model <b>702</b> may also include a graphical directional indicator such as a specific coloring, shading, or marking in an area of model <b>702</b> to indicate the front or back of the vehicle.</p>
      <p id="p-00058-en" num="0058">Model <b>702</b> can further dynamically respond to input which affects the positioning of the vehicle <b>602</b> relative to the current viewpoint. For example, for some tank vehicles, the turret can be pivoted independently of the hull of the tank with the player's view following the direction of the turret or the direction of the turret following the player's view. Model <b>702</b> can show the position or orientation of the turret <b>608</b> relative to the hull <b>610</b> of the tank for tank vehicles with this capability. As discussed herein, the direction of a player's view can be changed independently of the direction in which a vehicle or character may travel, so the direction of the player's view may not necessarily be from the front of the vehicle. Model <b>702</b> further enables the player to more easily maneuver the vehicle since the player is able to ascertain the direction that a vehicle will travel in response to directional commands. For example, in the view shown in <figref>FIG. 7</figref>, the front of tank vehicle <b>602</b> is pointed in the general direction of the left side of the view as indicated with model <b>702</b> such that in response to a forward movement command tank vehicle <b>602</b> will travel towards the left side of the view, and the view of the environment will shift towards the left in response to the player's input and resulting movement of tank vehicle <b>602</b>. Because the turret and hull of a tank vehicle may be controlled separately, the player may maintain the position of the turret relative to the environment while pivoting the hull around the turret, for example, in a clockwise or counter-clockwise direction. The pivoting of hull <b>610</b> changes the forward direction of tank vehicle <b>602</b>, and hull <b>710</b> of model <b>702</b> can pivot in the same manner as tank vehicle <b>602</b>. Turret <b>708</b> and hull <b>710</b> of model <b>702</b> can respond similarly to pivoting of one or both turret <b>608</b> and hull <b>610</b> of tank vehicle <b>602</b>. Thus, model <b>702</b> can dynamically reflect in real-time the positioning of various portions of tank vehicle <b>602</b> relative to the current viewpoint and mimic the movement and/or orientation of vehicle <b>602</b>.</p>
      <p id="p-00059-en" num="0059">
        <figref>FIG. 8</figref> illustrates an aspect relating to a directional indicator <b>803</b> which provides information relating to the direction that tank vehicle <b>602</b> is traveling in response to an inputted movement command. As discussed herein, user input can be provided through a virtual controller such as a virtual joystick <b>620</b> which is depicted in <figref>FIG. 8</figref>. In the example shown in <figref>FIG. 8</figref>, the user is commanding tank vehicle <b>602</b> to move in the forward direction, for example, by moving joystick <b>620</b> in the up direction. In response to receiving a forward movement command, tank vehicle <b>602</b> moves in the forward direction, and directional indicator <b>803</b> is displayed to show the direction that tank vehicle <b>602</b> is traveling. Directional indicator <b>803</b> may be in the form of a set of arrows pointing in the direction of travel as shown in <figref>FIG. 8</figref>. Different sets of arrows can be used for movement in different directions, such as forward, backward, turning, and pivoting. Different colors can be used for the arrows to differentiate between different travel directions. For example, different colors may be used for each of forward, backward, and pivoting movements. Arrows may be represented linearly (e.g., aligned with each other along a straight central axis <b>805</b>) when the vehicle is travelling in a straight line, or aligned along an arced or curved central axis when the vehicle is turning or pivoting (e.g., see <figref>FIG. 11B</figref>). The arrows may be evenly distributed along central axis <b>805</b>. The sharpness of the arc or the degree of curvature of the arc in central axis <b>805</b> may depend on whether the vehicle is pivoting or turning and the degree to which the vehicle is turning. For example, a sharper arc may be displayed when the vehicle is turning more sharply, and a flatter arc may be displayed when the vehicle is making a slight turn. In other words, the alignment of the arrows or curvature of the central axis may correspond to a general trajectory or projected path of the vehicle. For a forward movement, the arrows may extend from the front of the vehicle, and for a backwards movement, the arrows may extend from the back of the vehicle. As another example, the arrows may curve to the right of the vehicle when the vehicle is turning right and curve to the left of the vehicle when the vehicle is turning left. For a pivoting motion, two sets of arrows may be used as shown in <figref>FIG. 11B</figref>. The sets of arrows may be on opposing sides of the vehicle and extend along a central axis curved in a clockwise direction from the vehicle when the vehicle is pivoting clockwise. Similarly, the arrows may extend in a counter-clockwise direction when the vehicle is pivoting counter-clockwise.</p>
      <p id="p-00060-en" num="0060">
        <figref>FIG. 9</figref> illustrates an aspect relating to a directional indicator <b>903</b> of the model <b>702</b>. As shown in <figref>FIG. 8</figref>, tank vehicle <b>602</b> is provided with directional indicator <b>803</b> when the tank vehicle is moving such as moving in a particular direction or pivoting. Model <b>702</b> which mimics or matches the movement and/or orientation of vehicle <b>602</b> may also include a directional indicator <b>903</b> which matches directional indicator <b>803</b> of the tank vehicle <b>602</b>. In the example of <figref>FIG. 9</figref>, tank vehicle <b>602</b> is moving in the forward direction in response to a forward movement command as shown in <figref>FIG. 8</figref>. In the magnified view shown in <figref>FIG. 9</figref>, the movement of tank vehicle <b>602</b> is also reflected by directional indicator <b>903</b> for the model <b>702</b>. Similar to directional indicator <b>803</b> for tank vehicle <b>602</b>, directional indicator <b>703</b> may be in the form of a set of arrows aligned along a central axis <b>903</b> matching directional indicator <b>803</b> having a size proportional to model <b>702</b>. The proportional size may be the same as the proportion between the directional indicator <b>803</b> and the tank vehicle <b>602</b>. Directional indicator <b>703</b> may also reflect a backward or pivoting movement of tank vehicle <b>602</b>. An example of a backward movement indicator <b>905</b> is shown in <figref>FIG. 11A</figref>. An example of a pivoting directional indicator <b>907</b> is shown in <figref>FIG. 11B</figref>, and tank vehicle <b>602</b> would similarly be provided with a pivoting directional indicator comprising two sets of arrows curved in the direction of the pivoting.</p>
      <p id="p-00061-en" num="0061">In accordance with another aspect, <figref>FIGS. 10A and 10B</figref> show a third viewing mode <b>1000</b> which includes more than one view of the scenario depicted in <figref>FIG. 6</figref>. The different views may be any combination of first-person views and third-person views and any combination of magnification or zoom levels. In the example shown in <figref>FIG. 10A</figref>, a first-person view and a third-person view are used. The third-person view may be a normal or unmagnified view, and the first-person view may be a magnified or zoomed in view. A portion or spatial area of the on-screen display may be used for the first view <b>1002</b> which is shown as the first-person magnified view, and the remaining portion of the on-screen display may be the second view <b>1010</b> which is shown as the third-person normal view. Alternatively, each view may be first person views having differing magnification levels, or each view may be third-person views having differing magnification levels.</p>
      <p id="p-00062-en" num="0062">The area of magnified view <b>1002</b> may be any size and may depend on a player's preferences. The player may be able to customize the size of the on-screen area and the shape provided for magnified view <b>1002</b> as well as the on-screen position of the magnified view an example of which is illustrated in <figref>FIG. 10B</figref>. In the example shown in <figref>FIG. 10A</figref>, magnified view <b>1002</b> is positioned within reticle <b>606</b> by, for example, overlaying a magnification of the area within reticle <b>606</b> in the unmagnified view. The center point of the reticle may also serve as the center of the magnified view or zooming point. As can be seen through a comparison of <figref>FIG. 6</figref> and <figref>FIG. 10A</figref>, opposing tank <b>604</b> in magnified view <b>1002</b> is enlarged such that the user can more precisely aim at portions of opposing tank <b>604</b>. Using a combination of the two views <b>1002</b>, <b>1010</b>, the player is able to more accurately aim while also being aware of the vehicle's surrounding environment. Thus, the player can see objects or obstacles in the environment while also viewing objects at a distance in more detail.</p>
      <p id="p-00063-en" num="0063">The third viewing mode <b>1000</b> shown in <figref>FIG. 10A</figref> may be produced by generating an unmagnified, third-person view of the environment from a particular view point and generating a magnified view according to a pre-selected or user selected zoom or magnification level of a first-person view of the environment from the same view point. When the user selects to enter third viewing mode <b>1000</b>, the system can combine the two views by replacing the area displayed within reticle <b>606</b> of the unmagnified view with the magnified, first-person view of the environment <b>1002</b>. In other words, in switching, for example, to third viewing mode <b>1000</b> from a full display of the unmagnified view of the environment as shown in <figref>FIG. 6</figref>, the unmagnified view of the environment is unchanged except for the portion of the display designated for the magnified view, in this example, the area within reticle <b>606</b>.</p>
      <p id="p-00064-en" num="0064">In the example shown in <figref>FIG. 10A</figref>, the magnified view is located within reticle <b>606</b> in place of an unmagnified view. The two views may also be displayed together on-screen with a gradual reduction of the magnification level in an intermediate area <b>1006</b> between magnified area <b>1002</b> of the displayed screen to unmagnified area <b>1010</b> of the screen. In intermediate area <b>1006</b>, the magnification level may be reduced as the distance from magnified area <b>1002</b> increases to gradually blend the different views. For example, with <figref>FIG. 10A</figref>, the immediate screen area outside of reticle <b>606</b> may be magnified but have a lesser magnification level than the area within reticle <b>606</b>. As the on-screen distance from reticle <b>606</b> increases within intermediate area <b>1006</b>, the magnification level can decrease resulting in a magnification level that changes as a function of the radial screen distance from magnified view <b>1002</b> such that there is not a clear distinction between the magnified area and unmagnified area.</p>
      <p id="p-00065-en" num="0065">According to another aspect, any number of views may be shown on the screen. For example, another magnified view may be shown on the screen with a magnification level different than magnified view <b>1002</b>. The second magnified view may be of the same area of the environment as first magnified view <b>1002</b> or of a different area of the environment.</p>
      <p id="p-00066-en" num="0066">According to some aspects, the magnification level or zoom settings of the magnified view may be controlled in a variety of ways. For example, the player can manually adjust the magnification level or zoom settings of the magnified view. The player can increase or decrease the zoom or magnification level while a magnified view is being actively displayed. The magnification level may also or alternatively depend on a weapon or vehicle in use by the player. The magnification level may further be automatically determined based on a distance between tank vehicle <b>602</b> and a targeted object such as tank vehicle <b>604</b>. If no object is being targeted, a default magnification level may be used.</p>
      <p id="p-00067-en" num="0067">Magnified view <b>1002</b> may also include a model <b>702</b> of the player's vehicle similar to the magnified view described with respect to <figref>FIG. 7</figref>. As can be seen in <figref>FIG. 10A</figref>, the orientation of the turret relative to hull of model <b>702</b> is the same as tank <b>802</b>. Further, the overall orientation of tank <b>802</b> and model <b>702</b> relative to the viewpoint of the player is the same. Moreover, the model <b>702</b> responds in the same way to input controlling or changing the orientation or position of tank <b>802</b> as tank <b>802</b>. For example, in response to a command to pivot turret <b>808</b> of tank <b>802</b>, the turret of model <b>702</b> will pivot from the same starting point in the same direction and at the same rate as the turret of tank <b>802</b>. In other words, model <b>702</b> identically mimics the movement of the corresponding parts of tank <b>802</b>.</p>
      <p id="p-00068-en" num="0068">
        <figref>FIG. 10B</figref> depicts an illustrative view of another aspect including different views. As discussed above, the user can customize various aspects of the view including the on-screen position, size, and shape of a magnified view such as magnified view <b>1002</b>. In a preferences setting, the user can select a preferred on-screen position or location for a magnified view. The user may be able to manipulate a simulated magnified view in a simulated viewing mode with two different magnified views in the preferences setting. The user can move the simulated magnified view to the user's preferred position and change the size and shape of the magnified view according to the user's preferences. The software may store this preference for later retrieval and use when the user switches to a viewing mode including a magnified view.</p>
      <p id="p-00069-en" num="0069">In the example shown in <figref>FIG. 10B</figref>, the user has selected to have magnified view <b>1002</b> positioned in the upper right corner of the display and for magnified view <b>1002</b> to have a rectangular shape such that the magnified view is not limited to only the area within reticle <b>606</b>. The feature of enabling the user to position the magnified view according to the user's preferences allows the user to maintain a normal view of the environment while allocating a portion of the screen which may be less useful to the user to show the magnified view. In the example of <figref>FIG. 10B</figref>, the user can still see other tank vehicles which may be approaching on the ground while at the same time seeing a zoomed in view of targeted tank vehicle <b>604</b>. The user may also be able to see other tank vehicles within reticle <b>816</b> of unmagnified view <b>1010</b> which may not be shown in magnified view <b>1002</b> due to the magnification.</p>
      <p id="p-00070-en" num="0070">In yet another aspect, magnified view <b>1002</b> may include a potential damage indicator which will be described in more detail with respect to <figref>FIGS. 11A</figref>, <b>11</b>B, and <b>14</b>.</p>
      <p id="p-00071-en" num="0071">
        <figref>FIGS. 11A and 11B</figref> show another aspect that can be displayed in an unmagnified or magnified view. In a video game, the player can control a weapon and cause damage to a targeted object by firing the weapon at the targeted object. Various areas of a target may have different armor levels for different weapons and thus have different vulnerabilities to different weapons. A player would find it helpful to have knowledge of the strengths and weaknesses of a targeted object depending on the weapon selected and/or ammunition selected for the weapon. This information may be provided in the form of a potential damage indicator. The potential damage indicator can, for example, be static or dynamic. A static damage indicator may be calculated based on the type of armor and/or the strength of the armor on a portion or region of the targeted object and/or particular characteristics of the selected weapon against the type of armor on the targeted object as well as the current damage level of the targeted object. A dynamic potential damage indicator may be a real-time reflection of a probability of inflicting damage on portions of a targeted object. The dynamic potential damage indicator may be based on calculations similar to those performed for the static damage indicator and can further take into account changing conditions such as the weather, wind speed, and traveling speed and direction of the player and/or the opponent's tank vehicles which may affect the force of the impact of a weapon on a targeted object and the aiming accuracy of the weapon. The potential damage indicator may further take into account a potential angle of impact when the selected ammunition hits the armor. The potential angle of impact can be determined from various factors including the exit velocity of the ammunition from the gun, the angle at which the gun is aimed at the targeted object, and the surface angle of the armor at the point of impact. A projected or estimated trajectory of the ammunition can be calculated from these factors.</p>
      <p id="p-00072-en" num="0072">A player's weapon may be a gun which can be used with different types of ammunition where the ammunition can cause different amounts of damage to a target (e.g., opponent's vehicle or character or building) depending on a variety of variables such as the type of ammunition (e.g., armor piercing shell, high explosive shell, armor-piercing composite rigid shell, grenade, missile, bomb), the point of impact on the target, the distance from the target, traveling speed and direction, the size of the ammunition, and the type of gun (e.g., long barrel, short barrel, sniper rifle, machine gun) used with the ammunition. In the example of a tank vehicle weapon, one type of ammunition may be an armor piercing shell which is especially damaging for a particular type of armor. Another example is a high explosive shell which can be especially damaging for the tracks of a tank vehicle and at close range to the target.</p>
      <p id="p-00073-en" num="0073">The ammunition can also have different levels of accuracy. For example, while the point of aim may indicate the aiming point of the weapon, the fired ammunition might not hit that exact point. Accuracy of a weapon may be represented with an on-screen indicator around the point of aim where the area within the accuracy indicator may indicate the probability that the weapon will hit a target within the area indicated by the accuracy indicator.</p>
      <p id="p-00074-en" num="0074">
        <figref>FIGS. 11A and 11B</figref> illustrate examples of a potential damage indicator <b>924</b> which may be in the form of a shading or coloring or other indicator overlayed or otherwise presented on a targeted object. Using the potential damage indicator <b>924</b>, a player may determine the best and/or least armored portions of a targeted object. <figref>FIG. 11A</figref> shows a screenshot of a magnified view <b>1100</b> including an opponent's tank vehicle <b>604</b> with a potential damage indicator <b>1102</b> based on the currently selected ammunition.</p>
      <p id="p-00075-en" num="0075">In the example shown in <figref>FIG. 11A</figref>, an armor piercing composite rigid (APCR) shell for the gun of the player's tank vehicle is selected. Potential damage indicator <b>1102</b> is shown in the form of a colored shading that is different from the original color of the tank. The tank may also be outlined in the same color as the damage indicator when the targeted tank is an enemy tank. Saturation level or darkness of the colored shading may be used to indicate portions or regions of the tank which possess stronger armor or weaker armor which will better withstand damage from a shell or the probability in which the selected gun and ammo type will penetrate the armor. Lighter portions or those which have less shading or color saturation in the particular damage indicator color may be more poorly armored such that there is a greater likelihood that contact with a shell will incur damage and/or that the selected ammunition may cause greater damage compared to other regions of the targeted object. In other words, the portions of the tank which have less shading or color saturation may have weaker armor. Alternatively, darker portions or those which have more shading or color saturation in the particular indicator color may be more poorly armored such that there is a greater likelihood that contact with a shell will cause damage and/or that the selected ammunition may cause greater damage compared to other regions of the targeted object. The regions of the tank may be determined by the types of parts within the region. For example, the hull of the tank may have stronger armor and therefore be less susceptible to attacks while the tracks of the tank may be a weaker point of the tank. The turret may also have the same level of armor throughout.</p>
      <p id="p-00076-en" num="0076">Other forms of visual indicators may be used to provide a player with information about the stronger and weaker portions of a tank for a particular weapon selection such as a graphical or visual pattern, different colors, text indicators, numerical indicators, and a flashing pattern. The different types of damage indicators may be used alone or in combination with each other.</p>
      <p id="p-00077-en" num="0077">
        <figref>FIG. 11B</figref> shows an example of a potential damage indicator <b>1108</b> when another weapon and/or ammunition is selected. Ammunition selection panel <b>616</b> may be used to select ammunition to be loaded into the gun. For example, ammunition selection panel <b>616</b> includes an armor piercing composite rigid shell <b>1104</b>, a high explosive shell <b>1106</b>, armor piercing <b>1108</b>. In the example shown in <figref>FIG. 11B</figref>, a high explosive shell is selected for the tank gun. Similar to <figref>FIG. 11A</figref>, damage indicator <b>1110</b> may be shown in a magnified view. In the magnified view, the player is able to better discern between the various portions of the tank with different armor weaknesses/strengths and is able to more precisely aim at the various portions of the tank. Also similar to <figref>FIG. 11A</figref>, damage indicator <b>1110</b> uses a shading or saturation level of a color to indicate strong and weak parts of the tank. As can be seen by comparing <figref>FIGS. 9A and 11B</figref> which display damage indicators <b>1102</b>, <b>1110</b>, different weapons selections can result in different strengths and weaknesses for the same target. With the selection of high explosive shell <b>1106</b> in <figref>FIG. 11B</figref> the majority of the hull and the turret of the opponent's tank <b>604</b> are relatively strong against the high explosive shell. The tracks of tank <b>604</b> however are relatively vulnerable to the high explosive shell and are shown without a shading in <figref>FIG. 11B</figref>.</p>
      <p id="p-00078-en" num="0078">
        <figref>FIG. 12</figref> illustrates a flowchart of a method of providing a view including at least two different views according to an aspect, for example, as shown in <figref>FIG. 8</figref>. At step <b>1202</b>, a first viewing mode may be presented on a display device by a module (e.g., UI module and/or graphics module). The first viewing mode may be, for example, an unmagnified or normal first-person or third-person view of a simulated environment based on an object (e.g., character or vehicle) controlled by a user or player. At step <b>1204</b>, a module (e.g., input module) may receive a player input to enter a specific viewing mode. For example, the player may choose or select a button or option to enter a second viewing mode where at least a portion of the displayed environment includes a magnified view of a portion of the environment.</p>
      <p id="p-00079-en" num="0079">In response to the player input, a magnified view of a portion of the environment may be generated at step <b>1206</b>. For example, the client software <b>205</b> may retrieve or otherwise obtain data about objects in the environment from the world database <b>203</b>. The data about objects in the environment may include dimensional information which may be multiplied or otherwise manipulated to obtain enlarged dimensions for the magnified view. The client software <b>205</b> may graphically render the magnified view information using the dimensional information received from the world database <b>203</b>. The client software <b>205</b> can also generate the magnified view based on the number of display units used to display each portion of the unmagnified view. For example, if 10 pixels are used to display a particular area of the environment, the client software can generate a magnified view of the same area for a view that is magnified to be twice as large by using 20 pixels to display the same area. The magnified view may be centered around a reticle overlayed on the view of the simulated environment. According to another aspect, the client software <b>205</b> may generate an intermediate area positioned between the magnified view and the unmagnified view. For the environment displayed in the intermediate area, the client software can calculate a magnification level for each point or range of points based on the distance or range of distances of the point or range of points from the magnified view. For example, the greater the distance a point on the display is from the magnified view the less the magnification level assigned for the particular point is. As an example, if the magnified view magnifies an area by 3 times and the radial distance of the intermediate area between the magnified view and the unmagnified view is 1 inch, the magnification level for a radial distance from the magnified view between 0 to 0.5 inches may be 2 times, and the magnification level for a radial distance from the magnified view between 0.5 inches and 1 inch may be 1.5 times.</p>
      <p id="p-00080-en" num="0080">At step <b>1208</b>, the second viewing mode may be displayed on a display device. In the second viewing mode, at least a portion of the display may be used to present a magnified view of a portion of the simulated environment. The positioning of the magnified view of the environment may be based on user preferences. The system may retrieve user preferences of the location of the magnified view from memory and may superimpose or overlay the user designated portion of the display with the magnified view. In the example shown in <figref>FIG. 10B</figref>, the system can generate the unmagnified view and generate a magnified view centered around the center of reticle <b>816</b>. In the area designated by the user in the user preferences as being used for the magnified view, the system can display the magnified view <b>1002</b> instead of the normal, unmagnified view <b>1010</b>. A smaller model of the full scale version of the player's vehicle may be presented on the screen with the magnified view. The model may follow changes to the positioning of portions of the controlled vehicle relative to the displayed point of view in response to commands affecting the positioning of the full size version of the vehicle. In one aspect, the client software may consult world database <b>311</b> for movement information of the player's vehicle and may apply the same movement information to the movement of the smaller model.</p>
      <p id="p-00081-en" num="0081">
        <figref>FIG. 13</figref> illustrates a flow chart of an example of a method of displaying a view including a magnified and unmagnified view and a model of a controlled object. At step <b>1302</b>, the current orientation of a controlled object (e.g., vehicle or character) with respect to the current view and with respect to moveable portions of the controlled object can be determined. At step <b>1304</b>, a model of the controlled object can be generated based on the current orientations of the controlled object. At step <b>1306</b>, a magnified view of a portion of the environment is generated. As discussed herein, the portion of the environment to be magnified may be based on a player's view of the environment and may be centered on the environment located in the center of the view. Similarly, the magnified portion of the environment may be the portion of the environment in and around a reticle overlayed on the environment in that the view zooms in on the point at the center of the reticle. At step <b>1308</b>, a second view mode may be displayed in which a portion of the display is dedicated to an unmagnified view and a portion of the display is dedicated to a magnified view. For example, the apparatus or system executing the software may cause a display device to show a magnified environment in a portion of the view and an unmagnified environment in a portion of the view as described with respect to <figref>FIGS. 10A and 10B</figref>. The view shown may also be of two or more portions of the environment with different magnification levels.</p>
      <p id="p-00082-en" num="0082">
        <figref>FIG. 14</figref> shows a flowchart of an exemplary method according to an aspect of the disclosure relating to displaying a potential damage indicator. At step <b>1402</b>, a selection of a weapon may be received. Potential damage to a targeted object based on the currently selected weapon may be calculated at step <b>1404</b> such as a probability of causing damage or a potential degree of damage. The potential damage to a targeted object may depend on a number of variables such as the distance between the targeted object and the location from which the weapon is fired, the armor or shield and other attributes of the targeted object, the current amount of damage to the targeted object, the type of weapon currently selected, conditions in the environment (e.g., weather, temperature, wind speed and direction, gravity) and the point and/or angle at which the weapon makes contact with the targeted object. Potential damage to a targeted object may be calculated for each point or region on the object. According to an aspect, the calculated potential damage for a particular location may be based on the particular location being the point of impact for a weapon. This calculation may be performed for each location on the targeted object. To calculate the potential damage, client software may retrieve attribute information of the targeted object from the virtual world server or retrieve attribute information stored in the world database <b>203</b> that was previously received from the virtual world server. The calculated potential damage may be provided to the player in the form of a visual or graphical damage indicator. For example, for a targeted tank vehicle object, the tank vehicle object may have at least the attributes shown in and described with respect to <figref>FIG. 5B</figref>. The targeted tank may have three regions with different potential damage levels which may be based on armor strength levels. The tank vehicle may have hull armor with a certain strength level and turret armor with a strength level different from the hull armor while the tracks of the tank vehicle may have another armor strength level. A potential damage level can be calculated for each region using the attributes of the selected weapon. For example, a potential damage value may be obtained by comparing a damage value of the selected weapon with a strength value for the armor and calculating a potential damage values based on the difference. Another factor in the potential damage value may be the standard shell damage value and standard shell penetration value. This factor may be included in the potential damage calculation by comparing the standard shell penetration and damage values of the targeted vehicle with the shell penetration and damages values of the selected weapon.</p>
      <p id="p-00083-en" num="0083">According to another aspect, the potential damage of a targeted object may be calculated for the entirety or for each part of the targeted object based on the current conditions such as the projected point of impact on the object, current environment conditions, current distance from the targeted object, and armor or shield strength of the targeted object. The potential damage may take into account the radius of damage for a particular weapon. For example, a shell may inflict the greatest amount of damage at the point of impact, and the amount of damage will decrease as the distance from the point of impact increases.</p>
      <p id="p-00084-en" num="0084">Accordingly, at step <b>1406</b>, the damage indicator may be displayed on the targeted object. The damage indicator may be, for example, in the form of a certain color, shading, or pattern for portions of the targeted object where the color, shading level or saturation level, or the pattern used may indicate different amounts of potential damage. A particular damage level or probability level may correspond to a certain saturation level of the shading where the greater the damage or probability level the less saturated the shading and vice versa. For example, there may be three damage or probability levels and three different shading levels corresponding to the three damage or probability levels.</p>
      <p id="p-00085-en" num="0085">This damage indicator may also be dynamic in that the damage indicator may change depending on the current conditions in the simulated environment and in response to selecting a different weapon. As shown in <figref>FIG. 14</figref>, the method may return to step <b>1402</b> in response to the selection of another weapon.</p>
      <p id="p-00086-en" num="0086">According to another aspect, a magnified view may provide a user with a more detailed view of a portion of the environment including a targeted object and the magnified view may be particularly useful in more accurately aiming a weapon as described herein. The damage indicator may be provided in the magnified view where the user is able to discern potential damage to parts of the targeted object based in part on the currently selected weapon. While a magnified view and damage indicator are displayed, a user may be able to change the selection of a weapon. Since the damage indicator can dynamically change based on which weapon is currently selected, the player is able to repeatedly select different weapons and visually see which weapons are most effective against the targeted object and where the weak points on the targeted object are for the currently selected weapon. For example, a gun of a tank vehicle may be used with different types of ammunition. A first type of ammunition may be particularly effective against the tracks of an opponent's tank vehicle while a second type of ammunition may be particularly effective against the particular armor used on an opponent's tank vehicle.</p>
      <p id="p-00087-en" num="0087">While the steps of the methods illustrated in <figref>FIGS. 12-14</figref> are described and shown in a particular order, these steps may be rearranged and performed in any order.</p>
      <p id="p-00088-en" num="0088">The present aspects have been described in terms of preferred and illustrative embodiments. Numerous other embodiments, modifications and variations within the scope and spirit of the appended claims will occur to persons of ordinary skill in the art from a review of this disclosure.</p>
    </detailed-desc>
  </description>
  <claims id="claims_eng" lang="eng" format="original" date-changed="20150917">
    <claim num="1" id="clm-00001-en" independent="true">
      <claim-text>
        <b>1</b>. A method, comprising:
<claim-text>receiving a weapon selection from a user;</claim-text><claim-text>calculating potential damage to each of a plurality of regions of a target located in a simulated environment, the potential damage being based at least on a structural attribute of each region and one or more attributes of the selected weapon; and</claim-text><claim-text>displaying a damage indicator on one or more regions of the target based on the calculated potential damage for the respective region of the target.</claim-text></claim-text>
    </claim>
    <claim num="2" id="clm-00002-en">
      <claim-text>
        <b>2</b>. The method of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, wherein displaying the damage indicator on one or more regions of the target based on the calculated potential damage comprises:
<claim-text>for each region, displaying, on the region of the target, a shading level corresponding to the calculated potential damage for the region of the target.</claim-text></claim-text>
    </claim>
    <claim num="3" id="clm-00003-en">
      <claim-text>
        <b>3</b>. The method of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, wherein the target is a tank vehicle comprising a hull having a hull armor attribute and a turret having a turret armor attribute,
<claim-text>wherein calculating potential damage to each of the plurality of regions of the target comprises:
<claim-text>calculating a hull potential damage to the hull based on the hull armor attribute and one or more attributes of the selected weapon; and</claim-text><claim-text>calculating a turret potential damage to the turret based on the turret armor attribute and one or more attributes of the selected weapon, and</claim-text></claim-text><claim-text>wherein displaying the damage indicator on one or more regions of the target comprises:
<claim-text>displaying a hull damage indicator on the hull based on the calculated hull potential damage; and</claim-text><claim-text>displaying a turret damage indicator on the turret based on the calculated turret potential damage.</claim-text></claim-text></claim-text>
    </claim>
    <claim num="4" id="clm-00004-en">
      <claim-text>
        <b>4</b>. The method of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, wherein calculating the potential damage to each region of a target based at least on a structural attribute of each region and one or more attributes of the selected weapon comprises:
<claim-text>calculating the potential damage to each region of the target based on the structural attribute of each region, one or more attributes of the selected weapon, and current environmental conditions in the simulated environment.</claim-text></claim-text>
    </claim>
    <claim num="5" id="clm-00005-en">
      <claim-text>
        <b>5</b>. The method of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, further comprising:
<claim-text>receiving a second weapon selection from the user;</claim-text><claim-text>calculating an updated potential damage to each of the plurality of regions of the target based on the structural attribute of each region and one or more attributes of the selected second weapon; and</claim-text><claim-text>displaying an updated damage indicator on one or more regions of the target based on the updated potential damage for each region of the target.</claim-text></claim-text>
    </claim>
    <claim num="6" id="clm-00006-en">
      <claim-text>
        <b>6</b>. The method of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, wherein the one or more attributes of the selected weapon comprises at least one of: type of ammunition, point of impact on the target, distance from the target, size of the ammunition, a standard shell damage factor, and a standard shell penetration factor.</claim-text>
    </claim>
    <claim num="7" id="clm-00007-en">
      <claim-text>
        <b>7</b>. The method of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, wherein displaying the damage indicator on regions of the target based on the calculated potential damage comprises:
<claim-text>displaying the damage indicator on the target in a magnified view of the target.</claim-text></claim-text>
    </claim>
    <claim num="8" id="clm-00008-en">
      <claim-text>
        <b>8</b>. The method of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, wherein the damage indicator corresponds to a probability of causing damage.</claim-text>
    </claim>
    <claim num="9" id="clm-00009-en" independent="true">
      <claim-text>
        <b>9</b>. One or more tangible non-transitory computer readable media storing computer readable instructions that, when executed by a data processing device, cause a system to perform:
<claim-text>receiving a weapon selection from a user;</claim-text><claim-text>calculating potential damage to each of a plurality of regions of a target located in a simulated environment, the potential damage being based at least on a structural attribute of each region and one or more attributes of the selected weapon; and</claim-text><claim-text>displaying a damage indicator on one or more regions of the target based on the calculated potential damage for the respective region of the target.</claim-text></claim-text>
    </claim>
    <claim num="10" id="clm-00010-en">
      <claim-text>
        <b>10</b>. The computer readable media of <claim-ref idref="clm-00009-en">claim 9</claim-ref>, wherein displaying the damage indicator on one or more regions of the target based on the calculated potential damage comprises:
<claim-text>for each region, displaying, on the region of the target, a shading level corresponding to the calculated potential damage for the region of the target.</claim-text></claim-text>
    </claim>
    <claim num="11" id="clm-00011-en">
      <claim-text>
        <b>11</b>. The computer readable media of <claim-ref idref="clm-00009-en">claim 9</claim-ref>, wherein the target is a tank vehicle comprising a hull having a hull armor attribute and a turret having a turret armor attribute,
<claim-text>wherein calculating potential damage to each of the plurality of regions of the target comprises:
<claim-text>calculating a hull potential damage to the hull based on the hull armor attribute and one or more attributes of the selected weapon; and</claim-text><claim-text>calculating a turret potential damage to the turret based on the turret armor attribute and one or more attributes of the selected weapon, and</claim-text></claim-text><claim-text>wherein displaying the damage indicator on one or more regions of the target comprises:
<claim-text>displaying a hull damage indicator on the hull based on the calculated hull potential damage; and</claim-text></claim-text><claim-text>displaying a turret damage indicator on the turret based on the calculated turret potential damage.</claim-text></claim-text>
    </claim>
    <claim num="12" id="clm-00012-en">
      <claim-text>
        <b>12</b>. The computer readable media of <claim-ref idref="clm-00009-en">claim 9</claim-ref>, wherein calculating the potential damage to each region of a target based at least on a structural attribute of each region and one or more attributes of the selected weapon comprises:
<claim-text>calculating the potential damage to each region of the target based on the structural attribute of each region, one or more attributes of the selected weapon, and current environmental conditions in the simulated environment.</claim-text></claim-text>
    </claim>
    <claim num="13" id="clm-00013-en">
      <claim-text>
        <b>13</b>. The computer readable media of <claim-ref idref="clm-00009-en">claim 9</claim-ref>, further comprising:
<claim-text>receiving a second weapon selection from the user;</claim-text><claim-text>updating the potential damage each of the plurality of regions of the target based on the structural attribute of each region and one or more attributes of the selected second weapon; and</claim-text><claim-text>displaying an updated damage indicator on one or more regions of the target based on the updated potential damage for each region of the target.</claim-text></claim-text>
    </claim>
    <claim num="14" id="clm-00014-en">
      <claim-text>
        <b>14</b>. The computer readable media of <claim-ref idref="clm-00009-en">claim 9</claim-ref>, wherein the one or more attributes of the selected weapon comprises at least one of: type of ammunition, point of impact on the target, distance from the target, size of the ammunition, a standard shell damage factor, and a standard shell penetration factor.</claim-text>
    </claim>
    <claim num="15" id="clm-00015-en">
      <claim-text>
        <b>15</b>. The computer readable media of <claim-ref idref="clm-00009-en">claim 9</claim-ref>, wherein displaying the damage indicator on regions of the target based on the calculated potential damage comprises:
<claim-text>displaying the damage indicator on the target in a magnified view of the target.</claim-text></claim-text>
    </claim>
    <claim num="16" id="clm-00016-en">
      <claim-text>
        <b>16</b>. The computer readable media of <claim-ref idref="clm-00009-en">claim 9</claim-ref>, wherein the damage indicator corresponds to a probability of causing damage.</claim-text>
    </claim>
    <claim num="17" id="clm-00017-en" independent="true">
      <claim-text>
        <b>17</b>. A method, comprising:
<claim-text>providing a simulated environment including a user-controlled vehicle and an opponent's vehicle;</claim-text><claim-text>receiving an input to aim a weapon of the user-controlled vehicle at the opponent's vehicle;</claim-text><claim-text>in response to aiming at the opponent's vehicle, determining a structural attribute for each region of the opponent's vehicle and displaying a damage indicator on one or more regions of the opponent's vehicle based at least on the structural attribute for the respective region and a current weapon selection of the user-controlled vehicle.</claim-text></claim-text>
    </claim>
    <claim num="18" id="clm-00018-en">
      <claim-text>
        <b>18</b>. The method of <claim-ref idref="clm-00017-en">claim 17</claim-ref>, wherein the damage indicator is displayed in a magnified view of the simulated environment.</claim-text>
    </claim>
    <claim num="19" id="clm-00019-en">
      <claim-text>
        <b>19</b>. The method of <claim-ref idref="clm-00017-en">claim 17</claim-ref>, wherein the opponent's vehicle is a tank vehicle comprising a hull having a hull armor attribute and a turret having a turret armor attribute,
<claim-text>wherein displaying the damage indicator on one or more regions of the opponent's vehicle comprises:
<claim-text>overlaying a hull damage indicator on the hull of the opponent's vehicle, the hull damage indicator being based at least on the hull armor attribute and the current weapon selection; and</claim-text><claim-text>overlaying a turret damage indicator on the turret of the opponent's vehicle, the turret damage indicator being based at least on the turret armor attribute and the current weapon selection.</claim-text></claim-text></claim-text>
    </claim>
    <claim num="20" id="clm-00020-en">
      <claim-text>
        <b>20</b>. The method of <claim-ref idref="clm-00017-en">claim 17</claim-ref>, further comprising:
<claim-text>receiving a weapon selection for the user-controlled vehicle, the weapon selection comprising changing ammunition for the user-controlled vehicle from a current ammunition type to a second ammunition type; and</claim-text><claim-text>displaying an updated damage indicator on one or more regions of the opponent's vehicle based at least on the structural attribute for the respective region and one or more attributes of the second ammunition type. </claim-text></claim-text>
    </claim>
  </claims>
  <drawings id="drawings" format="original">
    <figure num="1">
      <img he="N/A" wi="N/A" file="US20150258442A1_00001.PNG" alt="clipped image" img-content="drawing" img-format="png" original="US20150258442A1-20150917-D00000.TIF" />
    </figure>
    <figure num="2">
      <img he="N/A" wi="N/A" file="US20150258442A1_00002.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150258442A1-20150917-D00001.TIF" />
    </figure>
    <figure num="3">
      <img he="N/A" wi="N/A" file="US20150258442A1_00003.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150258442A1-20150917-D00002.TIF" />
    </figure>
    <figure num="4">
      <img he="N/A" wi="N/A" file="US20150258442A1_00004.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150258442A1-20150917-D00003.TIF" />
    </figure>
    <figure num="5">
      <img he="N/A" wi="N/A" file="US20150258442A1_00005.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150258442A1-20150917-D00004.TIF" />
    </figure>
    <figure num="6">
      <img he="N/A" wi="N/A" file="US20150258442A1_00006.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150258442A1-20150917-D00005.TIF" />
    </figure>
    <figure num="7">
      <img he="N/A" wi="N/A" file="US20150258442A1_00007.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150258442A1-20150917-D00006.TIF" />
    </figure>
    <figure num="8">
      <img he="N/A" wi="N/A" file="US20150258442A1_00008.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150258442A1-20150917-D00007.TIF" />
    </figure>
    <figure num="9">
      <img he="N/A" wi="N/A" file="US20150258442A1_00009.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150258442A1-20150917-D00008.TIF" />
    </figure>
    <figure num="10">
      <img he="N/A" wi="N/A" file="US20150258442A1_00010.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150258442A1-20150917-D00009.TIF" />
    </figure>
    <figure num="11">
      <img he="N/A" wi="N/A" file="US20150258442A1_00011.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150258442A1-20150917-D00010.TIF" />
    </figure>
    <figure num="12">
      <img he="N/A" wi="N/A" file="US20150258442A1_00012.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150258442A1-20150917-D00011.TIF" />
    </figure>
    <figure num="13">
      <img he="N/A" wi="N/A" file="US20150258442A1_00013.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150258442A1-20150917-D00012.TIF" />
    </figure>
    <figure num="14">
      <img he="N/A" wi="N/A" file="US20150258442A1_00014.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150258442A1-20150917-D00013.TIF" />
    </figure>
    <figure num="15">
      <img he="N/A" wi="N/A" file="US20150258442A1_00015.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150258442A1-20150917-D00014.TIF" />
    </figure>
    <figure num="16">
      <img he="N/A" wi="N/A" file="US20150258442A1_00016.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150258442A1-20150917-D00015.TIF" />
    </figure>
    <figure num="17">
      <img he="N/A" wi="N/A" file="US20150258442A1_00017.PNG" alt="thumbnail image" img-content="drawing" img-format="png" original="US20150258442A1-20150917-D00000.TIF" />
    </figure>
  </drawings>
  <image file="US20150258442A1.PDF" type="pdf" size="2144118" pages="28" />
</lexisnexis-patent-document>