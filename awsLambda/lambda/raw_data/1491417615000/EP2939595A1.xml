<?xml version="1.0" encoding="utf-8"?>
<!-- Copyright ©2016 LexisNexis Univentio, The Netherlands. -->
<lexisnexis-patent-document schema-version="1.13" date-produced="20160127" file="EP2939595A1.xml" produced-by="LexisNexis-Univentio" lang="eng" date-inserted="20151104" time-inserted="091106" date-changed="20160123" time-changed="210834">
  <bibliographic-data lang="eng">
    <publication-reference publ-type="Application" publ-desc="Application published with search report">
      <document-id id="121939428">
        <country>EP</country>
        <doc-number>2939595</doc-number>
        <kind>A1</kind>
        <date>20151104</date>
      </document-id>
    </publication-reference>
    <application-reference>
      <document-id>
        <country>EP</country>
        <doc-number>14166267</doc-number>
        <date>20140428</date>
      </document-id>
    </application-reference>
    <language-of-filing>eng</language-of-filing>
    <language-of-publication>eng</language-of-publication>
    <priority-claims>
      <priority-claim sequence="1" data-format="docdb">
        <country>EP</country>
        <doc-number>14166267</doc-number>
        <kind>A</kind>
        <date>20140428</date>
        <priority-active-indicator>true</priority-active-indicator>
      </priority-claim>
      <priority-claim sequence="1" data-format="epodoc">
        <doc-number>EP20140166267</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability date-changed="20151105">
      <gazette-reference>
        <date>20151104</date>
      </gazette-reference>
      <unexamined-printed-without-grant>
        <date>20151104</date>
      </unexamined-printed-without-grant>
      <examined-printed-without-grant>
        <date>20151104</date>
      </examined-printed-without-grant>
    </dates-of-public-availability>
    <classifications-ipcr date-changed="20151105">
      <classification-ipcr sequence="1">
        <text>A61B   5/087       20060101AFI20140909BHEP        </text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>5</main-group>
        <subgroup>087</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20140909</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>A61B   5/00        20060101ALI20140909BHEP        </text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>5</main-group>
        <subgroup>00</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20140909</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>A61B   5/113       20060101ALI20140909BHEP        </text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>5</main-group>
        <subgroup>113</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20140909</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
    </classifications-ipcr>
    <classifications-cpc date-changed="20151105">
      <classification-cpc sequence="1">
        <text>A61B   5/1135      20130101 FI20140708BHEP        </text>
        <cpc-version-indicator>
          <date>20130101</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>5</main-group>
        <subgroup>1135</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20140708</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
      <classification-cpc sequence="2">
        <text>A61B   5/0873      20130101 LI20140708BHEP        </text>
        <cpc-version-indicator>
          <date>20130101</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>5</main-group>
        <subgroup>0873</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20140708</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
      <classification-cpc sequence="3">
        <text>A61B   5/746       20130101 LI20140708BHEP        </text>
        <cpc-version-indicator>
          <date>20130101</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>5</main-group>
        <subgroup>746</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20140708</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
    </classifications-cpc>
    <number-of-claims calculated="yes">9</number-of-claims>
    <invention-title id="title_ger" date-changed="20151104" lang="ger" format="original">Verfahren und System zur Bestimmung einer Bewegung eines Objekts</invention-title>
    <invention-title id="title_eng" date-changed="20151104" lang="eng" format="original">A method and system for determining a movement of an object</invention-title>
    <invention-title id="title_fre" date-changed="20151104" lang="fre" format="original">Procédé et système pour déterminer un mouvement d'objet</invention-title>
    <references-cited date-changed="20151110">
      <patent-citations name="patcit" date-changed="20151110" />
      <citation>
        <patcit num="1" dnum="EP1410755A1" dnum-type="publication number">
          <document-id>
            <country>EP</country>
            <doc-number>1410755</doc-number>
            <kind>A1</kind>
            <name>SUMITOMO OSAKA CEMENT CO LTD [JP], et al</name>
            <date>20040421</date>
          </document-id>
          <application-date>
            <date>20020617</date>
          </application-date>
        </patcit>
        <category>X</category>
      </citation>
      <citation>
        <patcit num="2" dnum="US5689241A" dnum-type="publication number">
          <document-id>
            <country>US</country>
            <doc-number>5689241</doc-number>
            <kind>A</kind>
            <name>CLARKE SR JAMES RUSSELL [US], et al</name>
            <date>19971118</date>
          </document-id>
          <application-date>
            <date>19960531</date>
          </application-date>
        </patcit>
        <category>X</category>
      </citation>
      <citation>
        <patcit num="3" dnum="US2011208060A1" dnum-type="publication number">
          <document-id>
            <country>US</country>
            <doc-number>20110208060</doc-number>
            <kind>A1</kind>
            <name>HAASE WAYNE C [US], et al</name>
            <date>20110825</date>
          </document-id>
          <application-date>
            <date>20110224</date>
          </application-date>
        </patcit>
        <category>A</category>
      </citation>
      <citation>
        <patcit num="4" dnum="US2010061596A1" dnum-type="publication number">
          <document-id>
            <country>US</country>
            <doc-number>20100061596</doc-number>
            <kind>A1</kind>
            <name>MOSTAFAVI HASSAN [US], et al</name>
            <date>20100311</date>
          </document-id>
          <application-date>
            <date>20080905</date>
          </application-date>
        </patcit>
      </citation>
      <citation>
        <patcit num="5" dnum="US2012253178A1" dnum-type="publication number">
          <document-id>
            <country>US</country>
            <doc-number>20120253178</doc-number>
            <kind>A1</kind>
            <name>MOSTAFAVI HASSAN [US]</name>
            <date>20121004</date>
          </document-id>
          <application-date>
            <date>20110401</date>
          </application-date>
        </patcit>
      </citation>
      <citation>
        <patcit num="6" dnum="WO2013093731A1" dnum-type="publication number">
          <document-id>
            <country>WO</country>
            <doc-number>2013093731</doc-number>
            <kind>A1</kind>
            <name>KONINKL PHILIPS ELECTRONICS NV [NL]</name>
            <date>20130627</date>
          </document-id>
          <application-date>
            <date>20121213</date>
          </application-date>
        </patcit>
      </citation>
      <citation>
        <patcit num="7" dnum="US5825293A" dnum-type="publication number">
          <document-id>
            <country>US</country>
            <doc-number>5825293</doc-number>
            <kind>A</kind>
            <name>AHMED ADEL A [US], et al</name>
            <date>19981020</date>
          </document-id>
          <application-date>
            <date>19960920</date>
          </application-date>
        </patcit>
      </citation>
      <citation>
        <patcit num="8" dnum="US7575554B2" dnum-type="publication number">
          <document-id>
            <country>US</country>
            <doc-number>7575554</doc-number>
            <kind>B2</kind>
            <name>ONISHI HIROSHI [JP]</name>
            <date>20090818</date>
          </document-id>
          <application-date>
            <date>20070921</date>
          </application-date>
        </patcit>
      </citation>
      <citation>
        <patcit num="9" dnum="US2013289431A1" dnum-type="publication number">
          <document-id>
            <country>US</country>
            <doc-number>20130289431</doc-number>
            <kind>A1</kind>
            <name>GAVISH BENJAMIN [IL], et al</name>
            <date>20131031</date>
          </document-id>
          <application-date>
            <date>20130625</date>
          </application-date>
        </patcit>
      </citation>
    </references-cited>
    <parties date-changed="20151104">
      <applicants>
        <applicant sequence="1" app-type="applicant">
          <addressbook lang="eng">
            <orgname>Advanced Digital Broadcast S.A.</orgname>
            <registered-number>100987022</registered-number>
            <issuing-office>European Patent Office</issuing-office>
            <address>
              <address-1>Avenue de Tournay 7</address-1>
              <city>1292 Chambesy</city>
              <country>CH</country>
            </address>
          </addressbook>
        </applicant>
      </applicants>
      <inventors>
        <inventor sequence="1">
          <addressbook lang="eng">
            <name>Jankowski, Bartosz</name>
            <address>
              <address-1>ADB Polska Sp. z o.o. ul. Trasa Polnocna 16</address-1>
              <city>65-119 Zielona Gora</city>
              <country>PL</country>
            </address>
          </addressbook>
        </inventor>
        <inventor sequence="2">
          <addressbook lang="eng">
            <name>Micewicz, Jaros aw</name>
            <address>
              <address-1>ADB Polska Sp. z o.o. ul. Trasa Polnocna 16</address-1>
              <city>65-119 Zielona Gora</city>
              <country>PL</country>
            </address>
          </addressbook>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="attorney">
          <addressbook lang="eng">
            <name>Pawlowski, Adam et al</name>
            <registered-number>101362586</registered-number>
            <issuing-office>European Patent Office</issuing-office>
            <address>
              <address-1>Eupatent.PL ul. Zeligowskiego 3/5</address-1>
              <city>90-752 Lodz</city>
              <country>PL</country>
            </address>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <designation-of-states date-changed="20151104">
      <designation-epc>
        <contracting-states>
          <country>AL</country>
          <country>AT</country>
          <country>BE</country>
          <country>BG</country>
          <country>CH</country>
          <country>CY</country>
          <country>CZ</country>
          <country>DE</country>
          <country>DK</country>
          <country>EE</country>
          <country>ES</country>
          <country>FI</country>
          <country>FR</country>
          <country>GB</country>
          <country>GR</country>
          <country>HR</country>
          <country>HU</country>
          <country>IE</country>
          <country>IS</country>
          <country>IT</country>
          <country>LI</country>
          <country>LT</country>
          <country>LU</country>
          <country>LV</country>
          <country>MC</country>
          <country>MK</country>
          <country>MT</country>
          <country>NL</country>
          <country>NO</country>
          <country>PL</country>
          <country>PT</country>
          <country>RO</country>
          <country>RS</country>
          <country>SE</country>
          <country>SI</country>
          <country>SK</country>
          <country>SM</country>
          <country>TR</country>
        </contracting-states>
        <extension-states>
          <country>BA</country>
          <country>ME</country>
        </extension-states>
      </designation-epc>
    </designation-of-states>
    <patent-family date-changed="20151104">
      <main-family family-id="174441999">
        <family-member>
          <document-id>
            <country>EP</country>
            <doc-number>2939595</doc-number>
            <kind>A1</kind>
            <date>20151104</date>
          </document-id>
          <application-date>
            <date>20140428</date>
          </application-date>
        </family-member>
      </main-family>
      <complete-family family-id="174441998">
        <family-member>
          <document-id>
            <country>EP</country>
            <doc-number>2939595</doc-number>
            <kind>A1</kind>
            <date>20151104</date>
          </document-id>
          <application-date>
            <date>20140428</date>
          </application-date>
        </family-member>
      </complete-family>
    </patent-family>
  </bibliographic-data>
  <abstract id="abstr_eng" date-changed="20151104" lang="eng" format="original">
    <p id="p-a-00001-en" num="0000">A method for determining a movement of an object (100) in an optical axis (A) of a camera (101), comprising the steps of: placing (201) a camera with the optical axis directed towards the object; activating (202) camera continuous autofocus functionality; monitoring (203) autofocus parameter pattern change; and determining (204) the movement of the object depending on the autofocus parameter pattern change. <img id="imga-00001-en" wi="75" he="142" img-content="drawing" file="imgaf001.tif" img-format="tif" /></p>
  </abstract>
  <description id="descr_eng" lang="eng" format="original" date-changed="20151104">
    <heading id="h-00001-en">TECHNICAL FIELD</heading>
    <p id="p-00001-en" num="0001">The present invention relates to a method and system for determining small movements of an object by a passive system, which can be used e.g. to monitor breathing of a person during sleep.</p>
    <heading id="h-00002-en">BACKGROUND</heading>
    <p id="p-00002-en" num="0002">Deficiencies and irregularities in breathing can have very serious consequences on health. This is a case especially during sleeping, which normally occurs in lying position. A sleeping person cannot knowingly observe his irregular breathing and any problems related to it, and therefore a quick reaction is often not possible. Also a person who is aware of his problems related to breathing, but does not have a companion who is monitoring his sleep and who would spot abnormal breathing patterns, lacks a protection that would allow for quick reaction in case of an emergency situation.</p>
    <p id="p-00003-en" num="0003">There are known a number of approaches to methods for monitoring of breathing.</p>
    <p id="p-00004-en" num="0004">A US patent application <patcit id="pcit-00001" dnum="US20100061596A"><text>US20100061596</text></patcit> discloses a method for determining similarity with a portion of a psychological motion, which utilizes images of infant during sleep. The method includes steps of comparing two images of the object and determining a level of similarity between them. Then, the level of similarity is correlated with a portion of physiological information.</p>
    <p id="p-00005-en" num="0005">Another US patent application <patcit id="pcit-00002" dnum="US20120253178A"><text>US20120253178</text></patcit> discloses a system and method for triggering an imaging process based on non-periodicity in breathing. The signals concerning breathing are gathered and analyzed with respect to any non-periodicity. In case of such non-periodicity, an imaging process is initiated. System uses a marker block, the movement of which is monitored by a processor with help of a camera. The processor is configured to continuously process image signals and determine the position of the marker block, therefore determining the breathing amplitude of the patient in substantially real time.</p>
    <p id="p-00006-en" num="0006">An international application <patcit id="pcit-00003" dnum="WO2013093731A"><text>WO2013093731</text></patcit> discloses a method and a system for video processing for monitoring breathing of a person in poor lighting conditions. It takes into account such factors as shadows and noise, and provides computer implemented approach to help reduce their adverse effects.</p>
    <p id="p-00007-en" num="0007">A drawback of the above methods and systems is that they require picture analyses to recognize patterns of changes. They require a significant computational power, which in turn leads to higher energy consumption, costs of manufacturing and overall complexity.</p>
    <p id="p-00008-en" num="0008">A US patent <patcit id="pcit-00004" dnum="US5825293A"><text>US5825293</text></patcit> presents an apparatus and method for monitoring breathing magnetically. The patient wears a sensing element coupled with a detector. The sensing element is placed in a manner allowing for detection of its movement by the detector, for instance it can include a permanent magnet. The detector is then a magnetic detector configured to monitor magnetic field caused by the magnet and provide an alarm signal when a measured rate of variation is detected to be outside of predetermined rate limit.</p>
    <p id="p-00009-en" num="0009">A US patent <patcit id="pcit-00005" dnum="US7575554B"><text>US7575554</text></patcit> discloses a breathing monitoring device for monitoring movement of, for example, chest. The device comprises a housing, which is placed above the chest of the patient. The device is equipped with a displacement amount determination unit and a respiration level determination unit.</p>
    <p id="p-00010-en" num="0010">A US patent application <patcit id="pcit-00006" dnum="US20130289431A"><text>US20130289431</text></patcit> shows an apparatus and method for breathing pattern determination using a non-contact microphone. It utilizes a raw signal indicative of air-flow sounds of the respiration, which is analyzed to determine sets of parameters of respiration.</p>
    <p id="p-00011-en" num="0011">The above methods and systems require additional devices or elements that have to be in contact or in close vicinity to the user. They limit therefore his spatial maneuverability and are prone to accidental dislocation or damaging.</p>
    <p id="p-00012-en" num="0012">It is therefore the aim of the present invention to provide further improvements to systems and methods for monitoring of movement of object in an optical axis of a camera, which can be used e.g. to monitor breathing patterns, that would reduce complexity and require less processing power and would not necessitate additional elements attached to or placed near a user.</p>
    <heading id="h-00003-en">SUMMARY</heading>
    <p id="p-00013-en" num="0013">There is presented a method for determining a movement of an object in an optical axis (A) of a camera, comprising the steps of: placing a camera with the optical axis directed towards the object; activating camera continuous autofocus functionality; monitoring autofocus parameter pattern change; and determining the movement of the object depending on the autofocus parameter pattern change.</p>
    <p id="p-00014-en" num="0014">Preferably, the method further comprises the steps of: analyzing the pattern of the movement of the object; and outputting an alarm signal upon recognizing an abnormal pattern.</p>
    <p id="p-00015-en" num="0015">Preferably, the method comprises comparing the determined parameter pattern with model parameter patterns from a database.</p>
    <p id="p-00016-en" num="0016">There is also presented use of the above-presented method to monitor the breathing pattern of a person.</p>
    <p id="p-00017-en" num="0017">There is also presented a computer program comprising program code means for performing steps of the method when said program is run on a computer, as well as a computer readable medium storing computer-executable instructions performing steps of the method when executed on a computer</p>
    <p id="p-00018-en" num="0018">There is further presented a system for determining a movement of an object in an optical axis (A) of a camera, comprising: a camera placed with the optical axis (A) directed towards the object; and a computer system connected to the camera via a camera interface and comprising a controller configured to: activate camera continuous autofocus functionality; monitor autofocus parameter pattern change; and determine the movement of the object depending on the autofocus parameter pattern change.</p>
    <p id="p-00019-en" num="0019">Preferably, the system further comprises an alarm interface, wherein the controller is configured to analyze the pattern of the movement of the object and to output an alarm signal via the alarm interface upon recognizing an abnormal pattern.</p>
    <p id="p-00020-en" num="0020">Preferably, the system further comprises a database of model parameter patterns, wherein the controller is configured to compare the determined parameter pattern with model parameter patterns from the database.</p>
    <heading id="h-00004-en">BRIEF DESCRIPTION OF DRAWINGS</heading>
    <p id="p-00021-en" num="0021">The present invention is shown by means of exemplary embodiments on a drawing, in which: <ul id="ul-00001-en" list-style="none" compact="compact"><li><figref>Fig. 1</figref> illustrates an exemplary arrangement of the camera with respect to the moving object;</li><li><figref>Fig. 2</figref> shows the steps of a method for monitoring a moving object;</li><li><figref>Fig. 3</figref> shows a system for monitoring a moving object;</li></ul></p>
    <heading id="h-00005-en">NOTATION AND NOMENCLATURE</heading>
    <p id="p-00022-en" num="0022">Some portions of the detailed description which follows are presented in terms of data processing procedures, steps or other symbolic representations of operations on data bits that can be performed on computer memory. Therefore, a computer executes such logical steps thus requiring physical manipulations of physical quantities.</p>
    <p id="p-00023-en" num="0023">Usually these quantities take the form of electrical or magnetic signals capable of being stored, transferred, combined, compared, and otherwise manipulated in a computer system. For reasons of common usage, these signals are referred to as bits, packets, messages, values, elements, symbols, characters, terms, numbers, or the like.</p>
    <p id="p-00024-en" num="0024">Additionally, all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Terms such as "processing" or "creating" or "transferring" or "executing" or "determining" or "detecting" or "obtaining" or "selecting" or "calculating" or "generating" or the like, refer to the action and processes of a computer system that manipulates and transforms data represented as physical (electronic) quantities within the computer's registers and memories into other data similarly represented as physical quantities within the memories or registers or other such information storage.</p>
    <heading id="h-00006-en">DESCRIPTION OF EXAMPLE EMBODIMENTS</heading>
    <p id="p-00025-en" num="0025">
      <figref>Fig. 1</figref> shows a camera 101 placed above a moving object, such that the object movement occurs in the optical axis A of the camera. In the present example, the moving object is a person, e.g. during sleep, whose check moves back and forward with respect to the camera.</p>
    <p id="p-00026-en" num="0026">The camera 101 is used to obtain information about object movement without physical contact. The system utilizes a typical passive autofocus function of the camera. The autofocus is concentrated on the area of a chest of the person, and is constantly following the changes in the distance between the chest and the camera through focus readjustment. The changes can be measured along the optical axis A of the camera, which is directed to a selected point on the chest. They can be also derived from points lying beyond the optical axis A, but still captured by the camera. Monitoring of the autofocus parameters can concern for example monitoring autofocus oscillations as a time function. The camera thus observes the person or a quilt (if present) and regulates autofocus in the rhythm of the breath. The autofocus pattern therefore represents the breathing pattern.</p>
    <p id="p-00027-en" num="0027">The camera 101 can be any digital camera provided with passive continuous autofocus function. In some conditions, the persons clothing (e.g. pyjamas) have some contrasting element to improve autofocus functionality (e.g. in form of a contrasting, black sticker attached to persons clothing). Autofocus function is a well-known tool, and is thoroughly described in literature known to persons skilled in the art.</p>
    <p id="p-00028-en" num="0028">
      <figref>Fig. 2</figref> presents a method for monitoring a moving object. Firstly, the camera is positioned in step 201 so that its optical axis lies on the object to be monitored (e.g. patient chest). Then, the autofocus function of the camera is activated in step 202. This causes the camera 101 to constantly adjust its focus accordingly to the movement of the monitored object. Next, the autofocus parameter pattern is monitored in step 203. In step 204 the object movement is determined on the basis of the autofocus parameter change - for example, the autofocus parameters are converted to physical dimensions, e.g. representing object position change as a measure of distance. The system analyzes the pattern in step 205. For example, the pattern can be compared with model breathing patterns stored in a database 301. A discrepancy in the measured signal pattern can then trigger an alarm signal in step 206. For example, the alarm signal can be used to wake up a sleeping person or to inform a caretaker of the sleeping/lying person about abnormal breathing. This reduces the need for attention of the caretaker towards the lying person.</p>
    <p id="p-00029-en" num="0029">
      <figref>Fig. 3</figref> shows a system for monitoring a moving object. The system comprises a model parameter patterns database 301, which stores e.g. breathing patterns used for comparison with monitored signal. It can comprise signals of normal breathing, for example of a child, a middle aged adult or an elderly person. It can also store abnormal breathing patterns, indicative of known conditions or symptoms related to health problems, so that more precise information can be provided to the user earlier. The system comprises a data bus 309 for communicating, preferably bi-directionally, all circuits of the system. Further, the system comprises a memory 302 for storing required software for the controller 304 and any temporary data needed for operation of the system. The controller 304 is configured to execute software that allows for monitoring and analyzing autofocus parameters patterns and comparing them with patterns stored in breathing patterns database 301. The controller 304 can also act to trigger appropriate actions based on detected abnormal patterns, for example an alarm signal via an alarm interface 305, which can be connected to an alarm device, e.g. a loudspeaker. The system comprises a camera interface 303 to communicate with an external camera and to collect from the camera the autofocus parameter value, which is fed to the controller 304. Logs of movement patterns can be stored in a log database 306 for future analyses.</p>
    <p id="p-00030-en" num="0030">The system may be implemented by using programmable logic circuits such as PGA (Programmable Gate Array), FPGA (Field-Programmable Gate Array) or ASIC (Application-Specific Integrated Circuit).</p>
    <p id="p-00031-en" num="0031">It can be easily recognized, by one skilled in the art, that the aforementioned system and method for monitoring of movement of object can be performed and/or controlled by one or more computer programs. Such computer programs are typically executed by utilizing the computing resources in a computing device such as personal computers, personal digital assistants, cellular telephones, receivers and decoders of digital television or the like. Applications are stored on a non-transitory medium. An example of a non-transitory medium is a non-volatile memory, for example a flash memory or volatile memory, for example RAM. The computer instructions are executed by a processor. These memories are exemplary recording media for storing computer programs comprising computer-executable instructions performing all the steps of the computer-implemented method according the technical concept presented herein.</p>
    <p id="p-00032-en" num="0032">While the invention presented herein has been depicted, described, and has been defined with reference to particular preferred embodiments, such references and examples of implementation in the foregoing specification do not imply any limitation on the invention. It will, however, be evident that various modifications and changes may be made thereto without departing from the broader scope of the technical concept. The presented preferred embodiments are exemplary only, and are not exhaustive of the scope of the technical concept presented herein.</p>
    <p id="p-00033-en" num="0033">Accordingly, the scope of protection is not limited to the preferred embodiments described in the specification, but is only limited by the claims that follow.</p>
  </description>
  <claims id="claims_eng" lang="eng" format="original" date-changed="20151104">
    <claim num="1" id="clm-00001-en" independent="true">
      <claim-text>A method for determining a movement of an object (100) in an optical axis (A) of a camera (101), comprising the steps of:
<claim-text>- placing (201) a camera with the optical axis directed towards the object;</claim-text><claim-text>- activating (202) camera continuous autofocus functionality;</claim-text><claim-text>- monitoring (203) autofocus parameter pattern change; and</claim-text><claim-text>- determining (204) the movement of the object depending on the autofocus parameter pattern change.</claim-text></claim-text>
    </claim>
    <claim num="2" id="clm-00002-en">
      <claim-text>The method according to claim 1, further comprising the steps of:
<claim-text>- analyzing (205) the pattern of the movement of the object;</claim-text><claim-text>- outputting (206) an alarm signal upon recognizing an abnormal pattern (205).</claim-text></claim-text>
    </claim>
    <claim num="3" id="clm-00003-en">
      <claim-text>The method according to claim 1, comprising comparing the determined parameter pattern with model parameter patterns from a database (301).</claim-text>
    </claim>
    <claim num="4" id="clm-00004-en">
      <claim-text>Use of the method according to any of claims 1 -3 to monitor the breathing pattern of a person.</claim-text>
    </claim>
    <claim num="5" id="clm-00005-en">
      <claim-text>A computer program comprising program code means for performing steps (202-204) of the method according to claim 1 when said program is run on a computer.</claim-text>
    </claim>
    <claim num="6" id="clm-00006-en">
      <claim-text>A computer readable medium storing computer-executable instructions performing steps (202-204) of the method according to claim 1 when executed on a computer</claim-text>
    </claim>
    <claim num="7" id="clm-00007-en" independent="true">
      <claim-text>A system for determining a movement of an object (100) in an optical axis (A) of a camera (101), comprising:
<claim-text>- a camera (101) placed with the optical axis (A) directed towards the object (100); and</claim-text><claim-text>- a computer system connected to the camera (101) via a camera interface (303) and comprising a controller (304) configured to:
<claim-text>- activate (202) camera continuous autofocus functionality;</claim-text><claim-text>- monitor (203) autofocus parameter pattern change; and</claim-text><claim-text>- determine (204) the movement of the object depending on the autofocus parameter pattern change.</claim-text></claim-text></claim-text>
    </claim>
    <claim num="8" id="clm-00008-en">
      <claim-text>The system according to claim 7, further comprising an alarm interface (305), wherein the controller (304) is configured to analyze (205) the pattern of the movement of the object and to output (206) an alarm signal via the alarm interface (305) upon recognizing an abnormal pattern (205).</claim-text>
    </claim>
    <claim num="9" id="clm-00009-en">
      <claim-text>The system according to claim 7, further comprising a database (301) of model parameter patterns, wherein the controller (304) is configured to compare the determined parameter pattern with model parameter patterns from the database (301).</claim-text>
    </claim>
  </claims>
  <drawings id="drawings" format="original">
    <figure num="1">
      <img he="N/A" wi="N/A" file="EP2939595A1_00001.PNG" alt="clipped image" img-content="drawing" img-format="png" original="imgaf001.tif" />
    </figure>
    <figure num="2">
      <img he="N/A" wi="N/A" file="EP2939595A1_00002.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="imgf0001.tif" />
    </figure>
    <figure num="3">
      <img he="N/A" wi="N/A" file="EP2939595A1_00003.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="imgf0002.tif" />
    </figure>
    <figure num="4">
      <img he="N/A" wi="N/A" file="EP2939595A1_00004.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="imgf0003.tif" />
    </figure>
    <figure num="5">
      <img he="N/A" wi="N/A" file="EP2939595A1_00005.PNG" alt="thumbnail image" img-content="drawing" img-format="png" original="imgaf001.tif" />
    </figure>
  </drawings>
  <image file="EP2939595A1.PDF" type="pdf" size="190537" pages="11" />
</lexisnexis-patent-document>