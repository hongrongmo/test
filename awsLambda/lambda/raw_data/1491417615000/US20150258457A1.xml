<?xml version="1.0" encoding="utf-8"?>
<!-- Copyright ©2016 LexisNexis Univentio, The Netherlands. -->
<lexisnexis-patent-document schema-version="1.13" date-produced="20160127" file="US20150258457A1.xml" produced-by="LexisNexis-Univentio" lang="eng" date-inserted="20150917" time-inserted="030351" date-changed="20151027" time-changed="110529">
  <bibliographic-data lang="eng">
    <publication-reference publ-type="Application" publ-desc="Patent Application Publication">
      <document-id id="121318129">
        <country>US</country>
        <doc-number>20150258457</doc-number>
        <kind>A1</kind>
        <date>20150917</date>
      </document-id>
    </publication-reference>
    <application-reference appl-type="utility">
      <document-id>
        <country>US</country>
        <doc-number>14204369</doc-number>
        <date>20140311</date>
      </document-id>
    </application-reference>
    <application-series-code>14</application-series-code>
    <language-of-filing>eng</language-of-filing>
    <language-of-publication>eng</language-of-publication>
    <dates-of-public-availability date-changed="20150924">
      <unexamined-printed-without-grant>
        <date>20150917</date>
      </unexamined-printed-without-grant>
    </dates-of-public-availability>
    <classifications-ipcr date-changed="20150924">
      <classification-ipcr sequence="1">
        <text>A63F  13/86        20140101AFI20150917BHUS        </text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>A</section>
        <class>63</class>
        <subclass>F</subclass>
        <main-group>13</main-group>
        <subgroup>86</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150917</date>
        </action-date>
        <generating-office>
          <country>US</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-ipcr>
    </classifications-ipcr>
    <classifications-cpc date-changed="20150924">
      <classification-cpc sequence="1">
        <text>A63F  13/86        20140902 FI20150917BHEP        </text>
        <cpc-version-indicator>
          <date>20140902</date>
        </cpc-version-indicator>
        <section>A</section>
        <class>63</class>
        <subclass>F</subclass>
        <main-group>13</main-group>
        <subgroup>86</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <action-date>
          <date>20150917</date>
        </action-date>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
      </classification-cpc>
    </classifications-cpc>
    <number-of-claims calculated="yes">20</number-of-claims>
    <invention-title id="title_eng" date-changed="20150917" lang="eng" format="original">METHOD AND SYSTEM FOR DATA COLLECTION USING LARGE-SCALE INTERACTIVE USER RESPONSE</invention-title>
    <references-cited date-changed="20151027">
      <patent-citations name="patcit" date-changed="20151027" />
      <citation>
        <patcit num="1" dnum="US5221094A" dnum-type="publication number">
          <document-id>
            <country>US</country>
            <doc-number>5221094</doc-number>
            <kind>A</kind>
            <name>HANSON MARK [US]</name>
            <date>19930622</date>
          </document-id>
          <application-date>
            <date>19920727</date>
          </application-date>
        </patcit>
      </citation>
      <citation>
        <patcit num="2" dnum="US5288075A" dnum-type="publication number">
          <document-id>
            <country>US</country>
            <doc-number>5288075</doc-number>
            <kind>A</kind>
            <name>KELLEY GLEN M [US]</name>
            <date>19940222</date>
          </document-id>
          <application-date>
            <date>19920121</date>
          </application-date>
        </patcit>
      </citation>
      <citation>
        <patcit num="3" dnum="US6343990B1" dnum-type="publication number">
          <document-id>
            <country>US</country>
            <doc-number>6343990</doc-number>
            <kind>B1</kind>
            <name>RASMUSSEN SEAN [CA], et al</name>
            <date>20020205</date>
          </document-id>
          <application-date>
            <date>20000127</date>
          </application-date>
        </patcit>
      </citation>
      <citation>
        <patcit num="4" dnum="US2005107162A1" dnum-type="publication number">
          <document-id>
            <country>US</country>
            <doc-number>20050107162</doc-number>
            <kind>A1</kind>
            <name>KILBY BARRY C [GB], et al</name>
            <date>20050519</date>
          </document-id>
          <application-date>
            <date>20031022</date>
          </application-date>
        </patcit>
      </citation>
      <citation>
        <patcit num="5" dnum="US2005144633A1" dnum-type="publication number">
          <document-id>
            <country>US</country>
            <doc-number>20050144633</doc-number>
            <kind>A1</kind>
            <name>BABAYAN YURI A [US]</name>
            <date>20050630</date>
          </document-id>
          <application-date>
            <date>20031231</date>
          </application-date>
        </patcit>
      </citation>
      <citation>
        <patcit num="6" dnum="US6935945B2" dnum-type="publication number">
          <document-id>
            <country>US</country>
            <doc-number>6935945</doc-number>
            <kind>B2</kind>
            <name>ORAK ZEKI [US]</name>
            <date>20050830</date>
          </document-id>
          <application-date>
            <date>20010507</date>
          </application-date>
        </patcit>
      </citation>
      <citation>
        <patcit num="7" dnum="US2012284090A1" dnum-type="publication number">
          <document-id>
            <country>US</country>
            <doc-number>20120284090</doc-number>
            <kind>A1</kind>
            <name>MARINS SERGEJS [CA], et al</name>
            <date>20121108</date>
          </document-id>
          <application-date>
            <date>20120502</date>
          </application-date>
        </patcit>
      </citation>
      <citation>
        <patcit num="8" dnum="US2014095460A1" dnum-type="publication number">
          <document-id>
            <country>US</country>
            <doc-number>20140095460</doc-number>
            <kind>A1</kind>
            <name>ROMANOWSKI TIMOTHY [US]</name>
            <date>20140403</date>
          </document-id>
          <application-date>
            <date>20121002</date>
          </application-date>
        </patcit>
      </citation>
    </references-cited>
    <parties date-changed="20150917">
      <applicants>
        <applicant sequence="1" app-type="applicant">
          <addressbook lang="eng">
            <orgname>Disney Enterprises, Inc.</orgname>
            <role>02</role>
            <address>
              <city>Burbank</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
        </applicant>
      </applicants>
      <inventors>
        <inventor sequence="1" designation="us-only">
          <addressbook lang="eng">
            <last-name>ZHANG</last-name>
            <first-name>Yuecheng</first-name>
            <address>
              <city>Burbank</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
        </inventor>
      </inventors>
    </parties>
    <patent-family date-changed="20150917">
      <main-family family-id="173672874">
        <family-member>
          <document-id>
            <country>US</country>
            <doc-number>20150258457</doc-number>
            <kind>A1</kind>
            <date>20150917</date>
          </document-id>
          <application-date>
            <date>20140311</date>
          </application-date>
        </family-member>
      </main-family>
      <complete-family family-id="173672873">
        <family-member>
          <document-id>
            <country>US</country>
            <doc-number>20150258457</doc-number>
            <kind>A1</kind>
            <date>20150917</date>
          </document-id>
          <application-date>
            <date>20140311</date>
          </application-date>
        </family-member>
      </complete-family>
    </patent-family>
  </bibliographic-data>
  <abstract id="abstr_eng" date-changed="20150917" lang="eng" format="original">
    <p id="p-a-00001-en" num="0000">A method including receiving a broadcast of an event comprising a plurality of frames; receiving, from a plurality of users, a corresponding plurality of inputs, each of the inputs relating to a characteristic of an object depicted in one of the frames of the broadcast; and analyzing the plurality of inputs to determine a best guess of the characteristic of the object in the frame.</p>
  </abstract>
  <legal-data date-changed="20151002">
    <legal-event sequence="1">
      <publication-date>
        <date>20140311</date>
      </publication-date>
      <event-code-1>AS</event-code-1>
      <legal-description>ASSIGNMENT</legal-description>
      <status-identifier>N</status-identifier>
      <docdb-publication-number> US  2015258457A1</docdb-publication-number>
      <docdb-application-id>444512550</docdb-application-id>
      <new-owner>DISNEY ENTERPRISES, INC., CALIFORNIA</new-owner>
      <free-text-description>ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:ZHANG, YUECHENG;REEL/FRAME:032406/0879</free-text-description>
      <effective-date>
        <date>20140310</date>
      </effective-date>
    </legal-event>
  </legal-data>
  <description id="descr_eng" lang="eng" format="original" date-changed="20150917">
    <summary>
      <heading id="h-00001-en" level="1">BACKGROUND</heading>
      <p id="p-00001-en" num="0001">Viewers of sporting events increasingly wish to view events accompanied by event data. Some types of event data may feasibly be collected automatically, but other types of data require manual input. Manual input of event data by professional operators can be labor-intensive and time-consuming.</p>
    </summary>
    <description-of-drawings>
      <heading id="h-00002-en" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
      <p id="p-00002-en" num="0002">
        <figref>FIG. 1</figref> shows a schematic view of a system for data collection according to an exemplary embodiment.</p>
      <p id="p-00003-en" num="0003">
        <figref>FIG. 2</figref> shows an exemplary method for data collection to be performed by a system such as the exemplary system of <figref>FIG. 1</figref>.</p>
    </description-of-drawings>
    <detailed-desc>
      <heading id="h-00003-en" level="1">DETAILED DESCRIPTION</heading>
      <p id="p-00004-en" num="0004">The exemplary embodiments may be further understood with reference to the following description and the related appended drawings, wherein like elements are provided with the same reference numerals. Specifically, the exemplary embodiments relate to methods and systems for using large-scale interactive user input to collect data about sporting events.</p>
      <p id="p-00005-en" num="0005">Viewers of broadcasts of sporting events often wish to have the broadcasts accompanied by enhanced displays of data. Data provided to the viewers may range from simple, such as a game score, count of balls and strikes, or time remaining, to complex, such as pitch location, player location, etc. Improvements in measurement technology have made it possible to reliably automatically collect some types of data, such as the speed or location of a tennis ball. However, existing technology is not capable of automatically collecting other types of data, such as player locations, location or timing of special events (e.g., goals, shots, touchdowns, strikes, etc.), changes in formation or strategy, performance or behavior of individual players, etc., in order to provide them to viewers in real time.</p>
      <p id="p-00006-en" num="0006">Prior techniques for gathering this data have involved collection of manual input by experienced operators to record these other types of data such as player positions. However, while this may provide accurate information, it is a labor-intensive and non-trivial task that may require days of work to process a single game. Automatic or semiautomatic data collection systems with the help of experienced operators may improve the operation time, but the results may drop below acceptable accuracy levels; refining this data to reach an acceptable level may take a significant amount of time. Therefore, there is a need for a solution that generates acceptable results in a reasonable amount of time.</p>
      <p id="p-00007-en" num="0007">The exemplary embodiments use crowdsourcing to obtain user input from a large number (e.g., in the hundreds or more) of viewers of a sporting event. The user input may be, for example, an identification of a position in a video frame for a selected player, and user input received from multiple users may be analyzed to determine the player's position in three-dimensional space. The exemplary embodiments may solicit user input by offering a reward (e.g., a monetary payout) for the prompt submission of accurate input. The requests for user input and subsequent rewards may be presented to users as an interactive game in which the users are participating. It will be apparent to those of skill in the art that, although the exemplary embodiments are described with specific reference to a system for obtaining player locations, the broader principles embodied therein are equally applicable to a system for obtaining other types of data, as described above.</p>
      <p id="p-00008-en" num="0008">
        <figref>FIG. 1</figref> schematically illustrates a system <b>100</b> for collecting and analyzing crowd sourced data according to an exemplary embodiment. It will be apparent to those of skill in the art that, while the system <b>100</b> will be described with specific reference to a solution for collecting data relating to player positions during a sporting event, the broader principles exemplified therein may be equally applicable to a system for collection and analysis of any other type of data. The system <b>100</b> includes a data source <b>110</b> providing the source data from which further data is to be extracted. In the exemplary embodiment, the data source <b>110</b> is a video capture array (e.g., one or more video cameras) at the site of a sporting event. It will be apparent to those of skill in the art that the data source <b>110</b> may collect other data (e.g., audio data) in addition to the data to video data to be discussed hereinafter.</p>
      <p id="p-00009-en" num="0009">For each of the one or more cameras that comprise data source <b>110</b>, a camera model may be known. Based on this camera model, two-dimensional data relating to an image taken by the camera may be converted to three-dimensional data relating to an object in the field of view of the camera and shown in the image. Such a camera model may be determined using known techniques based on, for example, the camera position, the angle of the camera, the dimensions of the playing field being captured by the camera, etc.</p>
      <p id="p-00010-en" num="0010">The system <b>100</b> also includes a production facility <b>120</b>. The production facility <b>120</b> may be, for example, a facility maintained by an event broadcaster that also operates data source <b>110</b>, and may be a facility that produces finalized broadcasts based on raw data collected at the data source <b>110</b>. The production facility <b>120</b> may be centralized or may be a remote facility.</p>
      <p id="p-00011-en" num="0011">The system <b>100</b> also includes a user device <b>130</b>. The user device <b>130</b> may be any type of device capable of displaying video data to the user and receiving subsequent input from the user. In one embodiment, the user device <b>130</b> may be a tablet device or other mobile device with a touch screen. In another embodiment, the user device <b>130</b> may be a wearable device, such as smart glasses. In some embodiments, the user device <b>130</b> may encompass a plurality of devices in association with one another, such as a television or other display displaying video to the user and a tablet or other handheld device for receiving user input. Video displayed by the user device <b>130</b> may be received directly from the data source <b>110</b> or via the production facility <b>120</b>. The user device <b>130</b> may also send user input to the production facility in accordance with the method <b>200</b> that will be described hereinafter. The user device <b>130</b> may receive video data and send user input over any appropriate communication channel, such as a cable or satellite television connection, an IP data connection, etc. Those skilled in the art will understand that there may be hundred, thousand or millions of user devices <b>130</b> that are receiving any particular broadcast and that this description is describing the operation of one of these user devices, but the production facility <b>120</b> may, in fact, be interacting with all the user devices <b>130</b> that are tuned to a particular broadcast and the users have opted to provide information for the broadcast.</p>
      <p id="p-00012-en" num="0012">
        <figref>FIG. 2</figref> illustrates an exemplary method <b>200</b> for collecting data using interactive user responses. The method <b>200</b> will be described with reference to the elements of the exemplary system <b>100</b> of <figref>FIG. 1</figref>, but those of skill in the art will understand that the broader concepts of method <b>200</b> may alternately be performed by other arrangements of hardware. Further, though the exemplary method <b>200</b> will be described specifically with reference to collecting user responses relating to the position of players in a sporting event and using such information to derive a best estimate of the players' actual positions, the broader principles are equally applicable to any other type of input that may be made by a viewer and subsequently synthesized with the input of other viewers. It will be assumed that, prior to the performance of method <b>200</b>, the user device <b>130</b> has already been provided with any software or configuration required to perform the tasks that will be described below.</p>
      <p id="p-00013-en" num="0013">In step <b>210</b>, the data source <b>110</b> captures video of an event. As noted above, this may involve video capture from one or more cameras having various perspectives of the event. In some embodiments, the video that is output by the data source <b>110</b> may be edited so that it changes among different cameras capturing the event depending on which camera provides the best view of the event or on other factors, such as following notable players. Video captured may be in any format, any aspect ratio, any frame rate, etc., without departing from the general concepts described herein.</p>
      <p id="p-00014-en" num="0014">In step <b>220</b>, the video captured by the data source <b>110</b> is provided to the production facility <b>120</b> and the user device <b>130</b>. As noted above, video may be provided to the user device via the production facility <b>120</b> (e.g., after the addition of enhancements such as graphics) or directly from the data source <b>110</b>. Provision of the video may be via any appropriate type of channel, such as a satellite connection, a cable television connection, an IP data connection, etc.</p>
      <p id="p-00015-en" num="0015">In step <b>230</b>, a user of the user device <b>130</b> selects a player to monitor and for whom input will be provided by the user. This may be accomplished using a user interface provided on the user device <b>130</b>. The user may be provided with the option to return to this step and select a different player during the course of the event. In one embodiment, the user may be prompted to select a particular player (e.g., a player that few other users have selected), such as by preventing the user from selecting other players or by providing the user with an incentive (e.g., an enhanced reward) to select the desired player. In another embodiment, a player may be assigned to a user based on need (e.g., a player that few other users have selected) rather than giving the user an option to select a player.</p>
      <p id="p-00016-en" num="0016">Steps <b>240</b>-<b>260</b>, described below, relate to the process by which a single item of user input is generated by a user of user device <b>130</b> and provided to production facility <b>120</b> (e.g., as noted above, a facility operated, by a broadcaster of the event) for subsequent processing in conjunction with input from other users. Steps <b>270</b> and <b>280</b> relate to the process by which the user input is acted upon at the production facility <b>120</b> to generate final results (e.g., in the exemplary embodiment, a best estimate for the position of the player whom the user has selected in step <b>230</b>). It will be apparent to those of skill in the art that the user of user device <b>130</b> may provide multiple input items through the repetition of steps <b>240</b>-<b>260</b> during one time interval (e.g., in real time during a live event broadcast, a time frame approximating real time, or during another time frame selected by the user), and that the analysis of those input items in steps <b>270</b> and <b>280</b> may be performed during some other time interval (e.g., after the event broadcast, during the preparation of a highlights package, during the preparation of an enhanced rebroadcast, etc.). However, for clarity, the exemplary method will be described sequentially herein as illustrated in <figref>FIG. 2</figref>.</p>
      <p id="p-00017-en" num="0017">In step <b>240</b>, the user of user device <b>130</b> provides a location of the player selected in step <b>230</b>. The location may be provided by a physical input by the user that is appropriate to the nature of the user device <b>130</b>. For example, where the user device <b>130</b> is a tablet device, the location may be input by tapping a touch screen at the desired location, which may be interpreted to be x and y coordinates of the selected player in the display. In another embodiment, the user may trace a path on a touch screen following the path of the selected player. In such an embodiment, the user device <b>130</b> may convert the path into a plurality of discrete inputs, such as by recording a location along the path as an input at periodic time intervals, such as one per second; these time intervals may be preconfigured or user-configurable, such as based on the input or transmission capabilities of the user device <b>130</b>. Where the user device <b>130</b> is a smart glasses device or other wearable device, the location may be input by aligning the player with a graphical representation of the player or by aligning a lens center with the player; in such an embodiment, knowledge of the user's location, pose, etc., determined by sensors in the device or other appropriate methods or devices, may enable such an input to provide a location (e.g., x and y coordinates) of the player in the display image. Where the user device <b>130</b> is a desktop, notebook, or other conventional type of computing device, the location may be input by placing a cursor at the desired location and making an input (e.g., clicking a mouse or touchpad button).</p>
      <p id="p-00018-en" num="0018">In step <b>250</b>, the user device <b>130</b> generates a record of the user's input. The record may include various individual data items. In the exemplary embodiment, the record may include the x and y coordinates of the input made by the user as recorded by the user device <b>130</b>. The record may also include a user identifier for the user (e.g., a user login ID, an account number, an IP address, or any other appropriate identifier). The record may also include a message time code; the value used for the message time code may vary in different implementations, depending on factors such as processing or transmission delay, and may be, for example, a frame identifier from the input video or a global time value. The record may also include a frame identifier enabling the production facility <b>120</b> to determine the precise point in the video for which the input was made. This may encompass an identification of both the video (e.g., a unique identifier of the event being broadcast) and the frame (e.g., the specific point in time the input was made), which may be identified using the time code from the generating device. The record may also include an identification of the player for whom the input was made (e.g., using one of a plurality of unique player identifiers defined by a broadcaster of the event to designate each of the players involved in the event).</p>
      <p id="p-00019-en" num="0019">In some embodiments, the record may also include a blob identifier. As used herein, a “blob” may be defined as a as a group of pixels (or other discrete areas) in an image that are assigned to a single identifiable visible unit; typically, a blob may be a single player or a group of players in close proximity to one another who are not visibly separable. Images may be processed for blob identification either before they are provided to users or after input has been received from users to identify various blobs contained therein. A user input made anywhere within the region designated as a given blob will be labeled with a corresponding blob identifier, and all inputs within the blob may be deemed to have the same location; the purpose of this convention is to improve the quality of user input from devices with limited input accuracy, such as mobile phones. Any inputs received that have (x, y) coordinates within the area of a given blob (and, thus, with a given blob identifier) will be deemed to be equivalent to one another and will have their coordinates updated to a value (x′, y′) representing the blob collectively. The collective value (x′, y′) may be determined algorithmically, and may, for example, simply be located at the geometric center of the blob. In another embodiment, the value (x′, y′) may be placed at a point that coincides with a player's feet (e.g., at the bottom of a bounding box defining the blob), or at a point that coincides with a player's head (e.g., at the top of a bounding box defining the blob).</p>
      <p id="p-00020-en" num="0020">Each of the specific elements of the record may be used by the production facility as will be described hereinafter. It will be apparent to those of skill in the art that the specific elements of the record may vary among differing embodiments, particularly those relating to some type of data other than player position, which may include other elements not mentioned herein or may lack one or more of the elements described herein.</p>
      <p id="p-00021-en" num="0021">In step <b>260</b>, the user device <b>130</b> sends the record of the user's input, generated in step <b>250</b>, to the production facility <b>120</b>. This transmission may be accomplished by any appropriate means for such transmission, including but not limited to transmission via an IP network. As noted above, steps <b>240</b>-<b>260</b> may be repeated for each user input, while the subsequent steps may be performed at a later point in time. As an alternative, steps <b>240</b> and <b>250</b> may be repeated for each user input, while step <b>260</b> may be performed once (e.g., after the user stops viewing the broadcast) with the transmission including all records generated through the repeated performance of steps <b>240</b> and <b>250</b>.</p>
      <p id="p-00022-en" num="0022">As described above, steps <b>240</b>-<b>260</b> relate to the process by which an item of user input is captured at the user device <b>130</b> and transmitted. Steps <b>270</b> and <b>280</b> occur after the user input has been transmitted to the production facility <b>120</b>, and relate to the process by which the user input is processed. As noted above, while <figref>FIG. 2</figref> illustrates a method whereby step <b>270</b> follows in sequence directly after step <b>260</b>, a number of user input items may be generated by a single user and provided one at a time or in bulk, and the processing at the production facility <b>120</b> may be delayed until another point in time, such as after a sufficient amount of input from various users has been received for a given event. The processing may be triggered manually, such as by an operator monitoring the receipt of user input, or automatically, such as once the production facility <b>120</b> determines that a sufficient amount of input has been received for a given player-frame pair, a given frame, a given event broadcast, etc.</p>
      <p id="p-00023-en" num="0023">In step <b>270</b>, the production facility combines the user input from steps <b>240</b>-<b>260</b> with similar input received from other users to generate output. It will be apparent to those of skill in the art that a given input sample relating to a position of a given athlete at a given point in time (with the point in time represented by the specific frame of video) will be evaluated in conjunction with other samples relating to the same athlete and point in time, and not, for example, samples related to other athletes. It will be further apparent to those of skill in the art that the (X, Y) coordinates of inputs received from different users may be with respect to different scales depending on the format of the displays being used by the various users; therefore, prior to evaluating the inputs in conjunction with one another, the inputs may be normalized so that they are all scaled to a standardized format (e.g., 1920 pixels by 1080 pixels).</p>
      <p id="p-00024-en" num="0024">A specific evaluation technique is disclosed hereinafter, but those of skill in the art will understand that other techniques may be possible without departing from the broader principles outlined herein. Generally speaking, the exemplary evaluation technique may be understood as an iterative technique whereby position inputs are weighted according to past accuracy of the user who made the input, and are then used in an iterative technique to converge on a best guess for the player's position in the frame under consideration.</p>
      <p id="p-00025-en" num="0025">The production facility <b>120</b> may include a database storing an accuracy value P<sub>i </sub>for each of a plurality of users i, including the user who generated the input discussed above in steps <b>240</b>-<b>260</b>. The accuracy value P<sub>i </sub>for each user may be based on the accuracy of prior inputs received from the user, such as for previous games, and may take any format, such as an integer value, a decimal value, or any other type of value desired by an operator of the production facility <b>120</b>. For the frame j under consideration, a plurality of inputs are received at the production facility <b>120</b>; the quantity of inputs is designated as K<sub>0</sub>. The input from each user i may take the form (X<sub>i</sub>, Y<sub>i</sub>) corresponding to the point in the two-dimensional view displayed to each user that the user indicated as the position of the selected player. An initial guess for the position (X, Y) of the player, based on the K<sub>0 </sub>inputs, may be that the position of the player is:</p>
      <p id="p-00026-en" num="0000">
        <maths id="maths-00001-en" num="00001">
          <math overflow="scroll">
            <mrow>
              <mfrac>
                <mrow>
                  <munderover>
                    <mo>∑</mo>
                    <mrow>
                      <mi>i</mi>
                      <mo>=</mo>
                      <mn>1</mn>
                    </mrow>
                    <msub>
                      <mi>K</mi>
                      <mn>0</mn>
                    </msub>
                  </munderover>
                  <mo></mo>
                  <mrow>
                    <msub>
                      <mi>P</mi>
                      <mi>i</mi>
                    </msub>
                    <mo></mo>
                    <msub>
                      <mi>X</mi>
                      <mi>i</mi>
                    </msub>
                  </mrow>
                </mrow>
                <mrow>
                  <munderover>
                    <mo>∑</mo>
                    <mrow>
                      <mi>i</mi>
                      <mo>=</mo>
                      <mn>1</mn>
                    </mrow>
                    <msub>
                      <mi>K</mi>
                      <mn>0</mn>
                    </msub>
                  </munderover>
                  <mo></mo>
                  <msub>
                    <mi>P</mi>
                    <mi>i</mi>
                  </msub>
                </mrow>
              </mfrac>
              <mo>,</mo>
              <mfrac>
                <mrow>
                  <munderover>
                    <mo>∑</mo>
                    <mrow>
                      <mi>i</mi>
                      <mo>=</mo>
                      <mn>1</mn>
                    </mrow>
                    <msub>
                      <mi>K</mi>
                      <mn>0</mn>
                    </msub>
                  </munderover>
                  <mo></mo>
                  <mrow>
                    <msub>
                      <mi>P</mi>
                      <mi>i</mi>
                    </msub>
                    <mo></mo>
                    <msub>
                      <mi>Y</mi>
                      <mi>i</mi>
                    </msub>
                  </mrow>
                </mrow>
                <mrow>
                  <munderover>
                    <mo>∑</mo>
                    <mrow>
                      <mi>i</mi>
                      <mo>=</mo>
                      <mn>1</mn>
                    </mrow>
                    <msub>
                      <mi>K</mi>
                      <mn>0</mn>
                    </msub>
                  </munderover>
                  <mo></mo>
                  <msub>
                    <mi>P</mi>
                    <mi>i</mi>
                  </msub>
                </mrow>
              </mfrac>
            </mrow>
          </math>
          <img id="img-00001-en" wi="N/A" he="N/A" file="US20150258457A1_00004.PNG" alt="embedded image" img-content="math" img-format="png" inline="yes" original="US20150258457A1-20150917-M00001.TIF" />
        </maths>
      </p>
      <p id="p-00027-en" num="0026">Once the initial guess has been determined, one or more inputs that are too far from the initial guess are eliminated from consideration. Distance from a given input (X<sub>i</sub>, Y<sub>i</sub>) to the guess (X, Y) may be determined by a linear distance, by a sum of the horizontal and vertical distances (X<sub>i</sub>−X)+(Y<sub>i</sub>−Y), or in any other appropriate manner. The inputs that are eliminated may or may not include the input discussed above with reference to steps <b>240</b>-<b>260</b>. In one embodiment, a single input that is furthest away from the guess may be eliminated. In another embodiment, two or more inputs that are furthest away may be eliminated. In another embodiment, all inputs greater than a threshold distance away from the guess may be eliminated; such a threshold may be predetermined or user-determined, and may, in one embodiment, grow gradually smaller as more guesses have been made. It will be apparent to those of skill in the art that which and how many inputs to eliminate at this, or any, stage of the process may vary among differing embodiments, and that this determination may be made in any number of manners.</p>
      <p id="p-00028-en" num="0027">Once one or more guesses have been eliminated, the previously-existing K<sub>0 </sub>inputs will be reduced to a smaller quantity K<sub>1</sub>. The same calculation described above may be repeated to yield a second guess for the position (X, Y) of the player that may be expressed as:</p>
      <p id="p-00029-en" num="0000">
        <maths id="maths-00002-en" num="00002">
          <math overflow="scroll">
            <mrow>
              <mfrac>
                <mrow>
                  <munderover>
                    <mo>∑</mo>
                    <mrow>
                      <mi>i</mi>
                      <mo>=</mo>
                      <mn>1</mn>
                    </mrow>
                    <msub>
                      <mi>K</mi>
                      <mn>1</mn>
                    </msub>
                  </munderover>
                  <mo></mo>
                  <mrow>
                    <msub>
                      <mi>P</mi>
                      <mi>i</mi>
                    </msub>
                    <mo></mo>
                    <msub>
                      <mi>X</mi>
                      <mi>i</mi>
                    </msub>
                  </mrow>
                </mrow>
                <mrow>
                  <munderover>
                    <mo>∑</mo>
                    <mrow>
                      <mi>i</mi>
                      <mo>=</mo>
                      <mn>1</mn>
                    </mrow>
                    <msub>
                      <mi>K</mi>
                      <mn>1</mn>
                    </msub>
                  </munderover>
                  <mo></mo>
                  <msub>
                    <mi>P</mi>
                    <mi>i</mi>
                  </msub>
                </mrow>
              </mfrac>
              <mo>,</mo>
              <mfrac>
                <mrow>
                  <munderover>
                    <mo>∑</mo>
                    <mrow>
                      <mi>i</mi>
                      <mo>=</mo>
                      <mn>1</mn>
                    </mrow>
                    <msub>
                      <mi>K</mi>
                      <mn>1</mn>
                    </msub>
                  </munderover>
                  <mo></mo>
                  <mrow>
                    <msub>
                      <mi>P</mi>
                      <mi>i</mi>
                    </msub>
                    <mo></mo>
                    <msub>
                      <mi>Y</mi>
                      <mi>i</mi>
                    </msub>
                  </mrow>
                </mrow>
                <mrow>
                  <munderover>
                    <mo>∑</mo>
                    <mrow>
                      <mi>i</mi>
                      <mo>=</mo>
                      <mn>1</mn>
                    </mrow>
                    <msub>
                      <mi>K</mi>
                      <mn>1</mn>
                    </msub>
                  </munderover>
                  <mo></mo>
                  <msub>
                    <mi>P</mi>
                    <mi>i</mi>
                  </msub>
                </mrow>
              </mfrac>
            </mrow>
          </math>
          <img id="img-00002-en" wi="N/A" he="N/A" file="US20150258457A1_00005.PNG" alt="embedded image" img-content="math" img-format="png" inline="yes" original="US20150258457A1-20150917-M00002.TIF" />
        </maths>
      </p>
      <p id="p-00030-en" num="0028">The steps of eliminating one or more inputs from consideration to yield a reduced set of inputs, and recalculating the guess based on the reduced set of inputs, may be repeated until a final result is reached. This may involve performing a predetermined number of iterations (e.g., until a guess has been determined based on a set of K<sub>5 </sub>inputs), until a predetermined number of inputs remain, or until a convergence point is reached. In one exemplary embodiment, a convergence point may be defined as the point where:</p>
      <p id="p-00031-en" num="0000">
        <maths id="maths-00003-en" num="00003">
          <math overflow="scroll">
            <mrow>
              <msub>
                <mi>P</mi>
                <mrow>
                  <mi>i</mi>
                  <mo>,</mo>
                  <mi>k</mi>
                </mrow>
              </msub>
              <mo>=</mo>
              <mrow>
                <mo>{</mo>
                <mrow>
                  <mrow>
                    <mtable>
                      <mtr>
                        <mtd>
                          <mn>1</mn>
                        </mtd>
                        <mtd>
                          <mrow>
                            <mrow>
                              <mi>if</mi>
                              <mo></mo>
                              <mstyle>
                                <mspace width="0.8em" height="0.8ex" />
                              </mstyle>
                              <mo></mo>
                              <msqrt>
                                <mrow>
                                  <msup>
                                    <mrow>
                                      <mo>(</mo>
                                      <mrow>
                                        <msub>
                                          <mi>X</mi>
                                          <mi>i</mi>
                                        </msub>
                                        <mo>-</mo>
                                        <mover>
                                          <msub>
                                            <mi>X</mi>
                                            <mi>k</mi>
                                          </msub>
                                          <mi>_</mi>
                                        </mover>
                                      </mrow>
                                      <mo>)</mo>
                                    </mrow>
                                    <mn>2</mn>
                                  </msup>
                                  <mo>+</mo>
                                  <msup>
                                    <mrow>
                                      <mo>(</mo>
                                      <mrow>
                                        <msub>
                                          <mi>Y</mi>
                                          <mi>i</mi>
                                        </msub>
                                        <mo>-</mo>
                                        <mover>
                                          <msub>
                                            <mi>Y</mi>
                                            <mi>k</mi>
                                          </msub>
                                          <mi>_</mi>
                                        </mover>
                                      </mrow>
                                      <mo>)</mo>
                                    </mrow>
                                    <mn>2</mn>
                                  </msup>
                                </mrow>
                              </msqrt>
                            </mrow>
                            <mo>&lt;</mo>
                            <msub>
                              <mi>D</mi>
                              <mi>k</mi>
                            </msub>
                          </mrow>
                        </mtd>
                      </mtr>
                      <mtr>
                        <mtd>
                          <mn>0</mn>
                        </mtd>
                        <mtd>
                          <mi>otherwise</mi>
                        </mtd>
                      </mtr>
                    </mtable>
                    <mo></mo>
                    <mstyle>
                      <mtext />
                    </mstyle>
                    <mo></mo>
                    <mover>
                      <msub>
                        <mi>X</mi>
                        <mrow>
                          <mi>k</mi>
                          <mo>+</mo>
                          <mn>1</mn>
                        </mrow>
                      </msub>
                      <mi>_</mi>
                    </mover>
                  </mrow>
                  <mo>=</mo>
                  <mrow>
                    <mrow>
                      <mfrac>
                        <mrow>
                          <munderover>
                            <mo>∑</mo>
                            <mrow>
                              <mi>i</mi>
                              <mo>=</mo>
                              <mn>1</mn>
                            </mrow>
                            <mi>N</mi>
                          </munderover>
                          <mo></mo>
                          <mrow>
                            <msub>
                              <mi>X</mi>
                              <mi>i</mi>
                            </msub>
                            <mo>×</mo>
                            <msub>
                              <mi>P</mi>
                              <mrow>
                                <mi>i</mi>
                                <mo>,</mo>
                                <mi>k</mi>
                              </mrow>
                            </msub>
                          </mrow>
                        </mrow>
                        <mrow>
                          <munderover>
                            <mo>∑</mo>
                            <mrow>
                              <mi>i</mi>
                              <mo>=</mo>
                              <mn>1</mn>
                            </mrow>
                            <mi>N</mi>
                          </munderover>
                          <mo></mo>
                          <msub>
                            <mi>P</mi>
                            <mrow>
                              <mi>i</mi>
                              <mo>,</mo>
                              <mi>k</mi>
                            </mrow>
                          </msub>
                        </mrow>
                      </mfrac>
                      <mo></mo>
                      <mstyle>
                        <mtext />
                      </mstyle>
                      <mo></mo>
                      <mover>
                        <msub>
                          <mi>X</mi>
                          <mrow>
                            <mi>k</mi>
                            <mo>+</mo>
                            <mn>1</mn>
                          </mrow>
                        </msub>
                        <mi>_</mi>
                      </mover>
                    </mrow>
                    <mo>=</mo>
                    <mrow>
                      <mfrac>
                        <mrow>
                          <munderover>
                            <mo>∑</mo>
                            <mrow>
                              <mi>i</mi>
                              <mo>=</mo>
                              <mn>1</mn>
                            </mrow>
                            <mi>N</mi>
                          </munderover>
                          <mo></mo>
                          <mrow>
                            <msub>
                              <mi>Y</mi>
                              <mi>i</mi>
                            </msub>
                            <mo>×</mo>
                            <msub>
                              <mi>P</mi>
                              <mrow>
                                <mi>i</mi>
                                <mo>,</mo>
                                <mi>k</mi>
                              </mrow>
                            </msub>
                          </mrow>
                        </mrow>
                        <mrow>
                          <munderover>
                            <mo>∑</mo>
                            <mrow>
                              <mi>i</mi>
                              <mo>=</mo>
                              <mn>1</mn>
                            </mrow>
                            <mi>N</mi>
                          </munderover>
                          <mo></mo>
                          <msub>
                            <mi>P</mi>
                            <mrow>
                              <mi>i</mi>
                              <mo>,</mo>
                              <mi>k</mi>
                            </mrow>
                          </msub>
                        </mrow>
                      </mfrac>
                      <mo></mo>
                      <mstyle>
                        <mtext />
                      </mstyle>
                      <mo></mo>
                      <mi>stop</mi>
                      <mo></mo>
                      <mstyle>
                        <mspace width="0.8em" height="0.8ex" />
                      </mstyle>
                      <mo></mo>
                      <mi>when</mi>
                      <mo></mo>
                      <mstyle>
                        <mspace width="0.8em" height="0.8ex" />
                      </mstyle>
                      <mo></mo>
                      <mrow>
                        <mo>{</mo>
                        <mtable>
                          <mtr>
                            <mtd>
                              <mrow>
                                <mover>
                                  <msub>
                                    <mi>X</mi>
                                    <mrow>
                                      <mi>k</mi>
                                      <mo>+</mo>
                                      <mn>1</mn>
                                    </mrow>
                                  </msub>
                                  <mi>_</mi>
                                </mover>
                                <mo>=</mo>
                                <mover>
                                  <msub>
                                    <mi>X</mi>
                                    <mi>k</mi>
                                  </msub>
                                  <mi>_</mi>
                                </mover>
                              </mrow>
                            </mtd>
                          </mtr>
                          <mtr>
                            <mtd>
                              <mrow>
                                <mover>
                                  <msub>
                                    <mi>Y</mi>
                                    <mrow>
                                      <mi>k</mi>
                                      <mo>+</mo>
                                      <mn>1</mn>
                                    </mrow>
                                  </msub>
                                  <mi>_</mi>
                                </mover>
                                <mo>=</mo>
                                <mover>
                                  <msub>
                                    <mi>Y</mi>
                                    <mi>k</mi>
                                  </msub>
                                  <mi>_</mi>
                                </mover>
                              </mrow>
                            </mtd>
                          </mtr>
                        </mtable>
                      </mrow>
                    </mrow>
                  </mrow>
                </mrow>
              </mrow>
            </mrow>
          </math>
          <img id="img-00003-en" wi="N/A" he="N/A" file="US20150258457A1_00006.PNG" alt="embedded image" img-content="math" img-format="png" inline="yes" original="US20150258457A1-20150917-M00003.TIF" />
        </maths>
      </p>
      <p id="p-00032-en" num="0029">The converged value, or other final result, is then used as the optimal guess for the position of the selected player in the frame at hand. It will be apparent to those of skill in the art that, once the position has been determined in this manner, it can then be used for any number of purposes, such as for generating enhanced graphics or for player tracking. The position may be converted from two-dimensional coordinates as shown on the screen to corresponding three-dimensional coordinates using a camera model based on known techniques, or may be used in the two-dimensional version (e.g., for generating features to be inserted into the two two-dimensional display). The result may be used in conjunction with results for the same player for other frames to determine further data about the player, in conjunction with results for other players for the same or other frames to determine further data about the game as a whole, or on its own to provide data about the single frame for which the result was determined. The subsequent use of the result is beyond the scope of the exemplary embodiments and will not be discussed further.</p>
      <p id="p-00033-en" num="0030">In step <b>280</b>, the P<sub>i </sub>values used for weighting various user inputs in step <b>270</b> are updated based on the accuracy of the various user inputs that were evaluated in step <b>270</b>. This may involve improving a user's P<sub>i </sub>value for a high-quality input (e.g., an input located close to the final result of step <b>270</b>), degrading a user's P<sub>i </sub>value for a low-quality input (e.g., an input located far from the final result of step <b>270</b>), or leaving a user's P<sub>i </sub>value changed for a medium-quality input (e.g., an input located an intermediate distance from the final result of step <b>270</b>). For example, in an embodiment where the P<sub>i </sub>values are integers, the production facility <b>120</b> may add one to a user's P<sub>i </sub>value for an input within a small radius (e.g., 30 pixels) of the final result, may leave the user's P<sub>i </sub>value unchanged for an input within a large radius (e.g., 60 pixels) of the final result but not within the small radius, and subtract one from the user's P<sub>i </sub>value for an input not within the large radius. Thus, it will be apparent that the P<sub>i </sub>values as used in the weighting described above may give more weight to the inputs of users that have historically provided useful data than to the inputs of users that have not done so. It will be further apparent to those of skill in the art that the specific P<sub>i </sub>value type (e.g., integer values) and adjustments described above are only exemplary and that other schemes of P<sub>i </sub>values that provide adjustable weighting as described above are also possible without departing from the broader principles outlined herein.</p>
      <p id="p-00034-en" num="0031">In step <b>290</b>, the production facility <b>120</b> determines whether the user of user device <b>130</b> who made the input described above with reference to steps <b>240</b>-<b>260</b> is entitled to a reward due to the input. As described above, the exemplary embodiments may provide users with a reward in exchange for high-quality input in order to encourage large numbers of users to make such input. It may further be a goal of the exemplary embodiments to encourage the users to provide such input in a rapid manner (e.g., as soon as possible after a live broadcast of the event). Thus, the exemplary embodiments may consider a combination of the accuracy and the timeliness of the user input to determine one or more users to receive a reward. In one exemplary embodiment, a reward may be given to a predetermined number of users (e.g., ten users) who are the first to provide a high-quality (e.g., within 30 pixels of a final result) input for a given player and frame. Those of skill in the art will understand that the precise criteria used may vary among differing embodiments; however, reward criteria recognizing solely speed of response without regard to accuracy may be undesirable because users may opt to provide rapid random inputs in order to qualify for a reward.</p>
      <p id="p-00035-en" num="0032">The specific reward provided to qualifying users may also vary among differing embodiments. In one exemplary embodiment, users who are entitled to a reward may simply receive a cash payment (e.g., one cent, one hundredth of one cent, etc.). Cash payments provided as rewards in this manner may be aggregated and paid to users after completion of one event broadcast, a predetermined number of event broadcasts, at the end of each month, or at any other appropriate interval. Payment may be made by electronic funds transfer or any other appropriate method of transfer. Alternately, the reward may take the form of a merchandise credit redeemable for a discount on purchases made from a broadcaster, or of a period of enhanced services provided by the broadcaster. It will be apparent to those of skill in the art that the specific nature and value of the reward may vary without departing from the broader principles of the exemplary embodiments.</p>
      <p id="p-00036-en" num="0033">Following the determination of rewards in step <b>290</b>, the method <b>200</b> terminates. However, as noted above, it will be apparent to those of skill in the art that the method <b>200</b> may not proceed in a strictly linear manner, and that the user of the user device <b>130</b> may continue to provide further inputs for further frames even after the rewards for prior frames have already been determined.</p>
      <p id="p-00037-en" num="0034">The exemplary embodiments may enable a provider of video programming, such as sporting events, to employ crowdsourcing of input to generate data about such events in a more achievable and efficient manner than possible using prior techniques. In contrast to employing a professional operator to track more than one player at the same time, tracking is divided into achievable tasks such as tracking a single player every few seconds; with many viewers sharing the divided tracking, each player may still be tracked by multiple fans in every frame, yielding high-quality results in a timely manner.</p>
      <p id="p-00038-en" num="0035">Additionally, providing the request for input to viewers as a game may boost user engagement. Because a viewer may earn rewards by providing reliable input in a timely manner, viewer engagement may be improved. Although the total cost may be non-trivial (for example, if a reward is 0.01 cents per qualifying input, the total payout may be several thousand dollars per event), it may also be worthwhile due to the generation of valuable event data and viewer attraction.</p>
      <p id="p-00039-en" num="0036">Further, the data generated by the crowdsourcing system of the exemplary embodiment may be used to improve automatic data-gathering systems. For example, the data gathered by the exemplary embodiments may be used as a point of comparison against which an automated data-gathering system operated by the event broadcaster may be judged. Further, if the broadcaster does not wish to develop its own in-house data-gathering system, a third-party wishing to develop a data-gathering system may use such a system to provide input to the crowdsourcing system as a way to generate revenue using the data-gathering system. If such a third-party data-gathering system becomes sufficiently efficient, the broadcaster may even collaborate with the owner of the third-party data-gathering system.</p>
      <p id="p-00040-en" num="0037">Those of skill in the art will understand that the above-described exemplary embodiments may be implemented in any number of matters, including as a software module, as a combination of hardware and software, etc. For example, the exemplary method <b>200</b> may be embodied in a program stored in a non-transitory storage medium and containing lines of code that, when compiled, may be executed by a processor.</p>
      <p id="p-00041-en" num="0038">It will be apparent to those skilled in the art that various modifications may be made to the exemplary embodiments, without departing from the spirit or the scope of the invention. Thus, it is intended that the present invention cover modifications and variations of this invention provided they come within the scope of the appended claims and their equivalents.</p>
    </detailed-desc>
  </description>
  <us-claim-statement>What is claimed is:</us-claim-statement>
  <claims id="claims_eng" lang="eng" format="original" date-changed="20150917">
    <claim num="1" id="clm-00001-en" independent="true">
      <claim-text>
        <b>1</b>. A method, comprising:
<claim-text>receiving a broadcast of an event comprising a plurality of frames;</claim-text><claim-text>receiving, from a plurality of users, a corresponding plurality of inputs, each of the inputs relating to a characteristic of an object depicted in one of the frames of the broadcast; and</claim-text><claim-text>analyzing the plurality of inputs to determine a best guess of the characteristic of the object in the frame.</claim-text></claim-text>
    </claim>
    <claim num="2" id="clm-00002-en">
      <claim-text>
        <b>2</b>. The method of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, further comprising:
<claim-text>selecting one of the plurality of users to receive a reward in exchange for the corresponding one of the inputs.</claim-text></claim-text>
    </claim>
    <claim num="3" id="clm-00003-en">
      <claim-text>
        <b>3</b>. The method of <claim-ref idref="clm-00002-en">claim 2</claim-ref>, wherein the one of the users is selected based on one of an accuracy of the one of the inputs and a speed of the one of the inputs.</claim-text>
    </claim>
    <claim num="4" id="clm-00004-en">
      <claim-text>
        <b>4</b>. The method of <claim-ref idref="clm-00002-en">claim 2</claim-ref>, wherein the reward is a cash payment.</claim-text>
    </claim>
    <claim num="5" id="clm-00005-en">
      <claim-text>
        <b>5</b>. The method of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, wherein the analyzing comprises determining a weighted average of the plurality of inputs.</claim-text>
    </claim>
    <claim num="6" id="clm-00006-en">
      <claim-text>
        <b>6</b>. The method of <claim-ref idref="clm-00005-en">claim 5</claim-ref>, wherein each of the inputs is weighted based on previous inputs made by the corresponding one of the users.</claim-text>
    </claim>
    <claim num="7" id="clm-00007-en">
      <claim-text>
        <b>7</b>. The method of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, wherein the characteristic is a location of the object.</claim-text>
    </claim>
    <claim num="8" id="clm-00008-en">
      <claim-text>
        <b>8</b>. The method of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, wherein the object is a human being.</claim-text>
    </claim>
    <claim num="9" id="clm-00009-en">
      <claim-text>
        <b>9</b>. The method of <claim-ref idref="clm-00001-en">claim 1</claim-ref>, wherein the plurality of inputs are analyzed using an iterative process.</claim-text>
    </claim>
    <claim num="10" id="clm-00010-en">
      <claim-text>
        <b>10</b>. The method of <claim-ref idref="clm-00009-en">claim 9</claim-ref>, wherein the iterative process comprises removing one of the plurality of inputs from the analyzing at each iteration, the removing being based on a predefined threshold related to the characteristic.</claim-text>
    </claim>
    <claim num="11" id="clm-00011-en" independent="true">
      <claim-text>
        <b>11</b>. A system, comprising:
<claim-text>a video capture apparatus capturing video of an event;</claim-text><claim-text>a broadcast apparatus broadcasting the video to a plurality of users; and</claim-text><claim-text>an analysis apparatus receiving, from the plurality of users, a corresponding plurality of inputs, each of the inputs relating to a characteristic of an object depicted in a same frame of the broadcast, and analyzing the plurality of inputs to determine a best guess of the characteristic of the object in the frame.</claim-text></claim-text>
    </claim>
    <claim num="12" id="clm-00012-en">
      <claim-text>
        <b>12</b>. The system of <claim-ref idref="clm-00011-en">claim 11</claim-ref>, wherein the analysis apparatus selects one of the plurality of users to receive a reward in exchange for the corresponding one of the inputs.</claim-text>
    </claim>
    <claim num="13" id="clm-00013-en">
      <claim-text>
        <b>13</b>. The system of <claim-ref idref="clm-00012-en">claim 12</claim-ref>, wherein the one of the users is selected based on one of an accuracy of the one of the inputs and a speed of the one of the inputs.</claim-text>
    </claim>
    <claim num="14" id="clm-00014-en">
      <claim-text>
        <b>14</b>. The system of <claim-ref idref="clm-00012-en">claim 12</claim-ref>, wherein the reward is a cash payment.</claim-text>
    </claim>
    <claim num="15" id="clm-00015-en">
      <claim-text>
        <b>15</b>. The system of <claim-ref idref="clm-00011-en">claim 11</claim-ref>, wherein the analyzing comprises determining a weighted average of the plurality of inputs.</claim-text>
    </claim>
    <claim num="16" id="clm-00016-en">
      <claim-text>
        <b>16</b>. The system of <claim-ref idref="clm-00015-en">claim 15</claim-ref>, wherein each of the inputs is weighted based on previous inputs made by the corresponding one of the users.</claim-text>
    </claim>
    <claim num="17" id="clm-00017-en">
      <claim-text>
        <b>17</b>. The system of <claim-ref idref="clm-00011-en">claim 11</claim-ref>, wherein the characteristic is a location.</claim-text>
    </claim>
    <claim num="18" id="clm-00018-en">
      <claim-text>
        <b>18</b>. The system of <claim-ref idref="clm-00011-en">claim 11</claim-ref>, wherein the analysis apparatus analyzes the plurality of inputs using an iterative process.</claim-text>
    </claim>
    <claim num="19" id="clm-00019-en">
      <claim-text>
        <b>19</b>. The system of <claim-ref idref="clm-00018-en">claim 18</claim-ref>, wherein the iterative process comprises removing one of the plurality of inputs from the analyzing at each iteration.</claim-text>
    </claim>
    <claim num="20" id="clm-00020-en" independent="true">
      <claim-text>
        <b>20</b>. A non-transitory computer-readable storage medium storing a set of instructions that is executable by a processor, the set of instructions, when executed by the processor, causing the processor to perform operations comprising:
<claim-text>receiving a broadcast of an event comprising a plurality of frames;</claim-text><claim-text>receiving, from a plurality of users, a corresponding plurality of inputs, each of the inputs relating to a characteristic of an object depicted in one of the frames of the broadcast; and</claim-text><claim-text>analyzing the plurality of inputs to determine a best guess of the characteristic of the object in the frame. </claim-text></claim-text>
    </claim>
  </claims>
  <drawings id="drawings" format="original">
    <figure num="1">
      <img he="N/A" wi="N/A" file="US20150258457A1_00001.PNG" alt="clipped image" img-content="drawing" img-format="png" original="US20150258457A1-20150917-D00000.TIF" />
    </figure>
    <figure num="2">
      <img he="N/A" wi="N/A" file="US20150258457A1_00002.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150258457A1-20150917-D00001.TIF" />
    </figure>
    <figure num="3">
      <img he="N/A" wi="N/A" file="US20150258457A1_00003.PNG" alt="drawing sheet" img-content="drawing" img-format="png" original="US20150258457A1-20150917-D00002.TIF" />
    </figure>
    <figure num="4">
      <img he="N/A" wi="N/A" file="US20150258457A1_00004.PNG" alt="mathematical image" img-content="math" img-format="png" original="US20150258457A1-20150917-M00001.TIF" inline="yes" />
    </figure>
    <figure num="5">
      <img he="N/A" wi="N/A" file="US20150258457A1_00005.PNG" alt="mathematical image" img-content="math" img-format="png" original="US20150258457A1-20150917-M00002.TIF" inline="yes" />
    </figure>
    <figure num="6">
      <img he="N/A" wi="N/A" file="US20150258457A1_00006.PNG" alt="mathematical image" img-content="math" img-format="png" original="US20150258457A1-20150917-M00003.TIF" inline="yes" />
    </figure>
    <figure num="7">
      <img he="N/A" wi="N/A" file="US20150258457A1_00007.PNG" alt="thumbnail image" img-content="drawing" img-format="png" original="US20150258457A1-20150917-D00000.TIF" />
    </figure>
  </drawings>
  <image file="US20150258457A1.PDF" type="pdf" size="387599" pages="8" />
</lexisnexis-patent-document>